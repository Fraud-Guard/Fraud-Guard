services:
  # ---------------------------------------------------------------------------
  # Core Infrastructure: Kafka, Zookeeper (None), Redis, MySQL
  # ---------------------------------------------------------------------------
  kafka:
    image: apache/kafka:4.1.1
    hostname: kafka
    container_name: kafka
    networks:
      - backend-network
    environment:
      # KRaft settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk" # Random UUID for KRaft
    volumes:
      - kafka_data:/var/lib/kafka/data

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080" # kafka UI ëª¨ë‹ˆí„°ë§ìš©
    networks:
      - backend-network
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      - kafka
  
  # Kafka Topic Initializer (ì¼íšŒìš© ì»¨í…Œì´ë„ˆ)
  kafka-init:
    image: apache/kafka:4.1.1
    container_name: kafka-init
    networks:
      - backend-network
    depends_on:
      - kafka
    # [1] .envì˜ ê°’ì„ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í™˜ê²½ë³€ìˆ˜ë¡œ ì£¼ìž…
    environment:
      KAFKA_PARTITIONS_RAW: ${KAFKA_PARTITIONS_RAW:-5}
      KAFKA_PARTITIONS_ERR: ${KAFKA_PARTITIONS_RAW:-3}
      KAFKA_PARTITIONS_PROCESSED: ${KAFKA_PARTITIONS_PROCESSED:-3}
    command: |
      bash -c "
      echo 'Waiting for Kafka to be ready...'
      
      # [Smart Wait] Kafkaê°€ ì‘ë‹µí•  ë•Œê¹Œì§€ ëŒ€ê¸°
      while ! /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list > /dev/null 2>&1; do
        echo 'Kafka is not ready yet... retrying in 2s'
        sleep 2
      done
      
      echo 'âœ… Kafka is Ready! Creating topics...'

      # [2] ì£¼ìž…ëœ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© (${VAR_NAME})
      echo 'Creating raw-topic (Partitions: ${KAFKA_PARTITIONS_RAW})...' &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic raw-topic --partitions ${KAFKA_PARTITIONS_RAW} --replication-factor 1 &&
      
      echo 'Creating raw-topic (Partitions: ${KAFKA_PARTITIONS_ERR})...' &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic err-topic --partitions ${KAFKA_PARTITIONS_ERR} --replication-factor 1 &&
      
      echo 'Creating 2nd-topic (Partitions: ${KAFKA_PARTITIONS_PROCESSED})...' &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic 2nd-topic --partitions ${KAFKA_PARTITIONS_PROCESSED} --replication-factor 1 &&
      
      echo 'Listing topics to verify:' &&
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list
      "

  redis:
    image: redis:latest
    container_name: redis
    networks:
      - backend-network
    command: redis-server --requirepass ${REDIS_PASSWORD}

  mysql:
    image: mysql:8.0
    container_name: mysql
    networks:
      - backend-network
    ports:
      - "127.0.0.1:3306:3306" # MySQL workbench ë¡œì»¬ ì ‘ì†ìš© í¬íŠ¸
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 10s
    volumes:
      - mysql_data:/var/lib/mysql
      
  # DB Initializer Service (init_db.py)
  db-initializer:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.python
    container_name: db-initializer
    networks:
      - backend-network
    command: bash -lc "python /app/src/init_db.py && python /app/src/init_geo.py && python /app/src/init_views.py"
    volumes:
      - ../:/app        # ì†ŒìŠ¤ ì½”ë“œ ë§ˆìš´íŠ¸
      - ../data:/app/data # CSV íŒŒì¼ ë§ˆìš´íŠ¸ (ì¤‘ìš”!)
    depends_on:
      mysql:
        condition: service_healthy
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}

  # ---------------------------------------------------------------------------
  # Python Applications: Producer, redis_warmer, ML Worker, Dev Env
  # ---------------------------------------------------------------------------
  flask-producer:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.python
    container_name: flask-producer
    networks:
      - backend-network
    # command: python /app/src/terminal.py # --csv /app/data/transactions_data.csv --mode rate --rate 50
    command: python /app/src/terminal.py --csv /app/data/transactions_data.csv --mode rate --rate 10000
    volumes:
      - ../:/app
    depends_on:
      kafka:
        condition: service_started
      redis:
        condition: service_started
      kafka-init:
        condition: service_completed_successfully
    ports:
      - "5000:5000" # ì™¸ë¶€ íŠ¸ëž˜í”½ ì£¼ìž…ìš© í¬íŠ¸
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      
  ml-worker:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.python  
    command: python /app/src/worker.py
    networks:
      - backend-network
    volumes:
      - ../:/app
    depends_on:
      - kafka
      - mysql
    environment:
      PYTHONUNBUFFERED: 1
    deploy:
      mode: replicated
      replicas: 5

  python-dev:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.python
    container_name: python-dev
    networks:
      - backend-network
    # Keeps running as per Dockerfile CMD
    volumes:
      - ../:/app
    ports:
      - "8888:8888" # ê°œë°œìš© Jupyter ë“± ì ‘ê·¼ í•„ìš” ì‹œ
    environment:
      PYTHONUNBUFFERED: 1

  # ---------------------------------------------------------------------------
  # Spark Cluster
  # ---------------------------------------------------------------------------
  spark-master:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.spark
    container_name: spark-master
    networks:
      - backend-network
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8081:8080" # Spark Master Web UI (ëª¨ë‹ˆí„°ë§ìš©)

  spark-worker:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.spark
    container_name: spark-worker
    networks:
      - backend-network
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    ports:
      - "8082:8081" # Spark Worker Web UI (ëª¨ë‹ˆí„°ë§ìš©)
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 1g

  # ---------------------------------------------------------------------------
  # Spark Consumers
  # ---------------------------------------------------------------------------
  consumer-group-1:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.spark
    # container_name: consumer-group-1
    networks:
      - backend-network
    # Example command to submit spark job. User will replace with actual script path.
    # Using 'tail -f' placeholder if script doesn't exist yet, or actual command
    command: bash -c "sleep 20 && /opt/spark/bin/spark-submit --master spark://spark-master:7077 /app/src/consumer1.py"
    # command: /opt/spark/bin/spark-submit --master spark://spark-master:7077 /app/src/consumer1.py
    volumes:
      - ../:/app
    depends_on:
      mysql:
        condition: service_healthy  # MySQL í—¬ìŠ¤ì²´í¬ í†µê³¼ ì‹œê¹Œì§€ ëŒ€ê¸°
      kafka:
        condition: service_started
      spark-master:
        condition: service_started
      # ðŸ’¡ ì—°ê²° ê±°ë¶€ ë“±ìœ¼ë¡œ êº¼ì§€ë©´ ì„±ê³µí•  ë•Œê¹Œì§€ ê³„ì† ìž¬ì‹œìž‘
    restart: on-failure  
      # - spark-master
      # - kafka
      # - mysql
    environment:
      SPARK_MASTER: spark://spark-master:7077

  consumer-group-2:
    build:
      context: ..
      dockerfile: Docker/Dockerfile.spark
    container_name: consumer-group-2
    networks:
      - backend-network
    command: >
      /opt/spark/bin/spark-submit
      --master spark://spark-master:7077
      --conf spark.jars.ivy=/tmp/.ivy2
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.8
      /app/src/consumer2.py
    volumes:
      - ../:/app
    depends_on:
      mysql:
          condition: service_healthy
      kafka:
        condition: service_started
    restart: on-failure
      # - spark-master
      # - kafka
      # - mysql
    environment:
      SPARK_MASTER: spark://spark-master:7077
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}

  # ---------------------------------------------------------------------------
  # Monitoring
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana
    container_name: grafana
    networks:
      - backend-network
    ports:
      - "3000:3000" # ëŒ€ì‹œë³´ë“œ ì ‘ê·¼ìš©

networks:
  backend-network:
    driver: bridge

volumes:
  kafka_data:
  mysql_data: