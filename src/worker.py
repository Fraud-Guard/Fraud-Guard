import os
import json
import time
import datetime
import numpy as np
import pandas as pd
import pymysql
import redis
from confluent_kafka import Consumer, Producer
from catboost import CatBoostClassifier, Pool
from dotenv import load_dotenv
from pathlib import Path

# ---------------------------------------------------------------------------
# 0. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜
# ---------------------------------------------------------------------------
BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR.parent / 'Docker' / '.env'
if ENV_PATH.exists():
    load_dotenv(dotenv_path=ENV_PATH)

# Kafka & DB Config
KAFKA_BROKER = 'kafka:9092'
SOURCE_TOPIC = 'raw-topic'
TARGET_TOPIC = '2nd-topic'
CONSUMER_GROUP = 'fraud-core-group'

DB_HOST = 'mysql'
DB_USER = 'root'
DB_PASSWORD = os.environ.get('MYSQL_ROOT_PASSWORD', 'root')
DB_NAME = os.environ.get('MYSQL_DATABASE', 'fraud_detection')

REDIS_HOST = 'redis'
REDIS_PORT = 6379

# Model Paths
MODEL_PATH_TIER1 = '/app/data/ML/tier1model.cbm'
MODEL_PATH_TIER2 = '/app/data/ML/tier2model.cbm'

# Thresholds (ì‚¬ìš©ìê°€ ì°¾ì€ ìµœì ê°’ ì ìš©)
TH_TIER1 = 0.99816559  # Severe Fraud
TH_TIER2 = 0.56802705  # Probable Fraud (Recall 90% íƒ€ê²Ÿê°’ìœ¼ë¡œ êµì²´ ê¶Œì¥)
# DW ìˆ˜ì •ì™„ë£Œ : ì°¾ì•˜ë˜ ì˜¬ë°”ë¥¸ thresholdê°’ì„ ì…ë ¥í•˜ì˜€ìŠµë‹ˆë‹¤.

# ---------------------------------------------------------------------------
# 1. Feature Store (Redis + MySQL Handler)
# ---------------------------------------------------------------------------
class FeatureStore:
    def __init__(self):
        self.r = redis.StrictRedis(host=REDIS_HOST, port=REDIS_PORT, db=0, decode_responses=True)
        self.db_conn = None

    def get_db_connection(self):
        # ë§¤ë²ˆ ì—°ê²°/í•´ì œí•˜ì§€ ì•Šê³  ì¬ì‚¬ìš© (Productionì—ì„œëŠ” Connection Pool ê¶Œì¥)
        if self.db_conn is None or not self.db_conn.open:
            self.db_conn = pymysql.connect(
                host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db=DB_NAME,
                charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor,
                autocommit=True
            )
        return self.db_conn

    def _fetch_from_mysql(self, table, record_id):
        """Cache Miss ë°œìƒ ì‹œ MySQLì—ì„œ ì¡°íšŒ"""
        conn = self.get_db_connection()
        with conn.cursor() as cursor:
            cursor.execute(f"SELECT * FROM {table} WHERE id = %s", (record_id,))
            return cursor.fetchone()

    def get_static_features(self, user_id, card_id, merchant_id):
        """User, Card, Merchantì˜ ì •ì  ì •ë³´ë¥¼ Redis/DBì—ì„œ ì¡°íšŒ"""
        features = {}

        # 1. User Data
        user_key = f"info:user:{user_id}"
        user_data = self.r.get(user_key)
        if not user_data:
            user_data_db = self._fetch_from_mysql("users_data", user_id)
            if user_data_db:
                # [ë¡œê·¸ ì¶”ê°€] ìºì‹œ ë¯¸ìŠ¤ ìƒí™© ì•Œë¦¼
                print(f"ğŸ” [Miss] User {user_id} not in Redis. Checking MySQL...")
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ JSONìœ¼ë¡œ ì €ì¥
                # yearly_income ì „ì²˜ë¦¬ ('$24,000' -> 24000.0)
                income = str(user_data_db.get('yearly_income', '0')).replace('$','').replace(',','')
                user_info = {
                    'yearly_income': float(income),
                    'current_age': user_data_db.get('current_age', 0),
                    'credit_score': user_data_db.get('credit_score', 0)
                }
                # [ë¡œê·¸ ì¶”ê°€] ì‹¤ì‹œê°„ ì ì¬ ì„±ê³µ ì•Œë¦¼
                print(f"âœ¨ [Real-time Sync] User {user_id} features added to Redis.")
                self.r.set(user_key, json.dumps(user_info))
                features.update(user_info)
            else:
                print(f"âŒ [FAIL] User {user_id} not found in DB.")
                return None # User ì—†ìŒ (ë¬´ê²°ì„± ì‹¤íŒ¨)
        else:
            features.update(json.loads(user_data))

        # 2. Card Data
        card_key = f"info:card:{card_id}"
        card_data = self.r.get(card_key)
        if not card_data:
            print(f"ğŸ” [Miss] Card {card_id} not in Redis. Checking MySQL...")
            card_data_db = self._fetch_from_mysql("cards_data", card_id)
            if card_data_db:
                limit = str(card_data_db.get('credit_limit', '0')).replace('$','').replace(',','')
                card_info = {
                    'credit_limit': float(limit),
                    'has_chip': card_data_db.get('has_chip', 'NO'),
                    'year_pin_last_changed': card_data_db.get('year_pin_last_changed', 2020),
                    'num_credit_cards': card_data_db.get('num_cards_issued', 1), # ëŒ€ì²´ ì»¬ëŸ¼
                    'card_brand': card_data_db.get('card_brand', 'Unknown'),
                    'client_id': card_data_db.get('client_id') # ì†Œìœ ì£¼ í™•ì¸ìš©
                }
                self.r.set(card_key, json.dumps(card_info))
                print(f"âœ¨ [Real-time Sync] Card {card_id} features added to Redis.")
                features.update(card_info)
            else:
                return None
        else:
            features.update(json.loads(card_data))

        # 3. Merchant Data
        merch_key = f"merchant:{merchant_id}" # redis_warmer ì–‘ì‹ì— ë§ì¶¤
        merch_data = self.r.get(merch_key)
        if not merch_data:
            merch_data_db = self._fetch_from_mysql("merchants_data", merchant_id)
            if merch_data_db:
                # redis_warmerëŠ” í†µì§¸ë¡œ ë„£ì—ˆìœ¼ë¯€ë¡œ parsing
                self.r.set(merch_key, json.dumps(merch_data_db, default=str))
                features['mcc'] = str(merch_data_db.get('mcc', '0'))
                features['merchant_state'] = merch_data_db.get('merchant_state', 'Online')
                features['zip'] = str(merch_data_db.get('zip', '00000'))
            else:
                return None
        else:
            m_json = json.loads(merch_data)
            features['mcc'] = str(m_json.get('mcc', '0'))
            features['merchant_state'] = m_json.get('merchant_state', 'Online')
            features['zip'] = str(m_json.get('zip', '00000'))

        return features

    def calculate_velocity(self, client_id, amount, timestamp, card_id):
        """
        Redis ZSETì„ ì´ìš©í•œ ì‹¤ì‹œê°„ Velocity ê³„ì‚°
        Key: history:client:{client_id}
        Score: timestamp
        Member: amount (ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ timestamp:amount ì¡°í•© ì‚¬ìš©)
        """
        key = f"history:client:{client_id}"
        member = f"{timestamp}:{amount}" # Unique Member
        
        pipeline = self.r.pipeline()
        
        # 1. í˜„ì¬ ê±°ë˜ ì¶”ê°€
        pipeline.zadd(key, {member: timestamp})
        
        # 2. 24ì‹œê°„ ì§€ë‚œ ë°ì´í„° ì‚­ì œ (Retention)
        cutoff_24h = timestamp - (24 * 3600)
        pipeline.zremrangebyscore(key, 0, cutoff_24h)
        
        # 3. 24ì‹œê°„ ì¹´ìš´íŠ¸ ì¡°íšŒ
        pipeline.zcard(key)
        
        # 4. 1ì‹œê°„ ë°ì´í„° ì¡°íšŒ (Sum ê³„ì‚°ìš©)
        cutoff_1h = timestamp - 3600
        pipeline.zrangebyscore(key, cutoff_1h, '+inf')

        # 5. Last Transaction Time ì¡°íšŒ ë° ê°±ì‹ 
        last_time_key = f"last_tx:{card_id}"
        pipeline.get(last_time_key)
        pipeline.set(last_time_key, timestamp)
        
        results = pipeline.execute()
        
        # ê²°ê³¼ íŒŒì‹±
        count_24h = results[2] # zcard ê²°ê³¼
        one_hour_txs = results[3] # list of members "ts:amt"
        last_tx_ts = results[4] # get ê²°ê³¼
        
        # Sum 1h ê³„ì‚°
        sum_amt_1h = 0.0
        for m in one_hour_txs:
            try:
                _, amt = m.split(':')
                sum_amt_1h += float(amt)
            except: pass
            
        # Time Diff ê³„ì‚°
        time_diff = 999999.0
        if last_tx_ts:
            time_diff = float(timestamp) - float(last_tx_ts)
            if time_diff < 0: time_diff = 0.0

        return time_diff, float(count_24h), sum_amt_1h

# ---------------------------------------------------------------------------
# 2. ML Handler (Model Loading & Prediction)
# ---------------------------------------------------------------------------
class ModelHandler:
    def __init__(self):
        print("[INFO] Loading Tier 1 Model...")
        self.tier1 = CatBoostClassifier()
        self.tier1.load_model(MODEL_PATH_TIER1)
        
        print("[INFO] Loading Tier 2 Model...")
        self.tier2 = CatBoostClassifier()
        self.tier2.load_model(MODEL_PATH_TIER2)
        
        # ëª¨ë¸ì´ í•™ìŠµëœ ì»¬ëŸ¼ ìˆœì„œ (ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•¨!)
        self.feature_order = [
            'amount', 'utilization_ratio', 'amount_income_ratio', 
            'tech_mismatch', 'pin_years_gap', 'num_credit_cards', 
            'hour', 'is_night', 
            'time_diff_seconds', 'count_24h', 'sum_amt_1h',
            'current_age', 'credit_score',
            'mcc', 'merchant_state', 'zip', 'use_chip', 'card_brand'
        ]

    def predict(self, feature_dict):
        # Dict -> List (ìˆœì„œ ë³´ì¥)
        # ë²”ì£¼í˜• ë°ì´í„°ëŠ” Stringìœ¼ë¡œ, ê²°ì¸¡ì¹˜ëŠ” ì ì ˆí•œ ê°’ìœ¼ë¡œ
        row = []
        for col in self.feature_order:
            val = feature_dict.get(col)
            if col in ['mcc', 'merchant_state', 'zip', 'use_chip', 'card_brand']:
                row.append(str(val) if val is not None else "Unknown")
            else:
                row.append(float(val) if val is not None else 0.0)
        
        # CatBoost Pool ìƒì„± (1ê±´ì´ë¼ë„ Pool ê¶Œì¥)
        # cat_features ì¸ë±ìŠ¤ ì§€ì • (ë’¤ì—ì„œ 5ê°œ)
        cat_indices = [13, 14, 15, 16, 17]
        
        # Tier 1 Prediction
        prob_t1 = self.tier1.predict_proba(row)[1]
        
        is_severe = 1 if prob_t1 >= TH_TIER1 else 0
        is_fraud = 0
        
        if is_severe:
            is_fraud = 1
        else:
            # Tier 2 Prediction
            prob_t2 = self.tier2.predict_proba(row)[1]
            if prob_t2 >= TH_TIER2:
                is_fraud = 1
        
        return is_severe, is_fraud

# ---------------------------------------------------------------------------
# 3. Main Logic
# ---------------------------------------------------------------------------
def main():
    store = FeatureStore()
    model_handler = ModelHandler()
    
    # Kafka Setup
    consumer = Consumer({
        'bootstrap.servers': KAFKA_BROKER,
        'group.id': CONSUMER_GROUP,
        'auto.offset.reset': 'latest'
    })
    consumer.subscribe([SOURCE_TOPIC])
    producer = Producer({'bootstrap.servers': KAFKA_BROKER})
    
    print("[INFO] Worker Ready. Waiting for messages...")

    try:
        while True:
            msg = consumer.poll(1.0)
            if msg is None: continue
            if msg.error():
                print(f"[ERROR] Kafka: {msg.error()}")
                continue

            try:
                # [ë¡œê·¸ ì¶”ê°€] ì‹œì‘ ì‹œê°„ ê¸°ë¡
                start_time = time.time()
                raw = json.loads(msg.value().decode('utf-8'))
                
                # 1. Integrity & Static Feature Fetching
                # user_id, card_id, merchant_idë¡œ Redis ì¡°íšŒ
                # í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ DB ì¡°íšŒ í›„ ìºì‹± (Fail-over)
                static_feats = store.get_static_features(
                    raw['client_id'], raw['card_id'], raw['merchant_id']
                )
                
                # ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨ ì‹œ (DBì—ë„ ì—†ìŒ)
                if (static_feats is None) or (raw['error'] != '-'):
                    raw['is_valid'] = 1
                    raw['is_fraud'] = 0
                    raw['is_severe_fraud'] = 0
                    # ë°”ë¡œ ì „ì†¡
                    producer.produce(TARGET_TOPIC, json.dumps(raw).encode('utf-8'))
                    continue

                # 2. Dynamic Feature Engineering
                # ì‹œê°„ íŒŒì‹±
                dt_obj = pd.to_datetime(raw['order_time'])
                timestamp = dt_obj.timestamp()
                
                # Velocity ê³„ì‚° (Redis ZSET)
                amount = float(raw['amount'])
                time_diff, count_24h, sum_1h = store.calculate_velocity(
                    raw['client_id'], amount, timestamp, raw['card_id']
                )
                
                # íŒŒìƒ ë³€ìˆ˜ ê³„ì‚°
                # utilization_ratio
                util_ratio = amount / static_feats['credit_limit'] if static_feats['credit_limit'] > 0 else 0
                
                # amount_income_ratio
                income_ratio = amount / static_feats['yearly_income'] if static_feats['yearly_income'] > 0 else 0.0
                
                # tech_mismatch
                # use_chipì€ raw dataì—ëŠ” ì—†ìœ¼ë¯€ë¡œ(ê°€ì •), ë§Œì•½ rawì— ìˆë‹¤ë©´ ê·¸ê²ƒ ì‚¬ìš©.
                # ì˜ˆì‹œ ë°ì´í„°ì—ëŠ” rawì— use_chipì´ ì—†ì—ˆìŒ. (ë³´í†µ transactionì— í¬í•¨ë¨)
                # ì—¬ê¸°ì„œëŠ” rawì— 'use_chip'ì´ ìˆë‹¤ê³  ê°€ì • (ì—†ìœ¼ë©´ Unknown)
                # DW ìˆ˜ì •ì™„ë£Œ use_chipë„ rawì— ë“¤ì–´ì˜¤ë„ë¡ ìˆ˜ì •í•¨.
                use_chip = raw.get('use_chip', 'Unknown') # Rawì— ìˆì–´ì•¼ í•¨!
                has_chip = static_feats['has_chip']
                tech_mismatch = 1 if (has_chip == 'YES' and use_chip == 'Swipe Transaction') else 0
                
                # pin_years_gap
                pin_gap = 2020 - static_feats['year_pin_last_changed'] # 2020ë…„ ê¸°ì¤€
                
                # 3. Final Feature Vector Construction
                features = {
                    'amount': amount,
                    'utilization_ratio': util_ratio,
                    'amount_income_ratio': income_ratio,
                    'tech_mismatch': tech_mismatch,
                    'pin_years_gap': pin_gap,
                    'num_credit_cards': static_feats['num_credit_cards'],
                    'hour': dt_obj.hour,
                    'is_night': 1 if 0 <= dt_obj.hour < 6 else 0,
                    'time_diff_seconds': time_diff,
                    'count_24h': count_24h,
                    'sum_amt_1h': sum_1h,
                    'current_age': static_feats['current_age'],
                    'credit_score': static_feats['credit_score'],
                    'mcc': static_feats['mcc'],
                    'merchant_state': static_feats['merchant_state'],
                    'zip': static_feats['zip'],
                    'use_chip': use_chip,
                    'card_brand': static_feats['card_brand']
                }
                
                # 4. Inference
                is_severe, is_fraud = model_handler.predict(features)
                
                # 5. Send Result
                raw['is_valid'] = 0
                raw['is_fraud'] = is_fraud
                raw['is_severe_fraud'] = is_severe
                
                producer.produce(TARGET_TOPIC, json.dumps(raw).encode('utf-8'))

                # [ë¡œê·¸ ì¶”ê°€] ì¢…ë£Œ ì‹œê°„ ê¸°ë¡ ë° ì²˜ë¦¬ ì‹œê°„ ì¶œë ¥
                duration = (time.time() - start_time) * 1000  # ms ë‹¨ìœ„ ë³€í™˜
                print(f"âœ… [Processed] Client: {raw['client_id']} | Latency: {duration:.4f}ms")
                
                producer.poll(0)

            except Exception as e:
                print(f"[ERROR] Processing Failed: {e}")
                import traceback
                traceback.print_exc()

    except KeyboardInterrupt:
        print("Worker stopping...")
    finally:
        consumer.close()
        producer.flush()

if __name__ == "__main__":
    main()