{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1c7334",
   "metadata": {},
   "source": [
    "# 1ì°¨ ë°ì´í„° ì •ì œ\n",
    "\n",
    "ê¸°ë³¸ì ì¸ ë°ì´í„° ì¤‘ìš”ë„ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´ ê¸°ì´ˆì ì¸ ì •ì œë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„°ì˜ ë§¥ë½ë³´ë‹¤ëŠ” ë°ì´í„° ìì²´ë¥¼ ì‚´ë¦¬ê³  ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ ìˆ«ìí˜•ìœ¼ë¡œ ì¸ì½”ë”©ì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1ce7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b701f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13094522 entries, 0 to 13305914\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   id              int64  \n",
      " 1   client_id       int64  \n",
      " 2   card_id         int64  \n",
      " 3   amount          float64\n",
      " 4   merchant_state  int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 599.4 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_main = pd.read_csv('data/transactions_data.csv')\n",
    "\n",
    "df_main = (\n",
    "    df_main\n",
    "    .drop('date', axis=1)\n",
    "    .drop('use_chip', axis=1)\n",
    "    .drop('merchant_id', axis=1)\n",
    "    .drop('merchant_city', axis=1)\n",
    "    .drop('zip', axis=1)\n",
    "    .drop('mcc', axis=1)\n",
    ")\n",
    "\n",
    "df_main = df_main[df_main['errors'].isnull()]\n",
    "df_main['merchant_state'] = df_main['merchant_state'].fillna('Online')\n",
    "df_main['merchant_state'] = le.fit_transform(df_main['merchant_state'])\n",
    "df_main['amount'] = df_main['amount'].str.replace('$', '', regex=False).str.replace(',', '').astype(float)\n",
    "df_main = df_main.drop('errors', axis=1)\n",
    "\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10662d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8914963 entries, 0 to 8914962\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   id        int64\n",
      " 1   is_fraud  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 136.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_fraud = pd.read_csv('data/train_fraud_labels.csv')\n",
    "\n",
    "df_fraud['target'] = df_fraud['target'].map({'Yes':1, 'No':0}).astype(int)\n",
    "df_fraud = df_fraud.rename(columns={'target':'is_fraud'})\n",
    "df_fraud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87775008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   client_id          2000 non-null   int64  \n",
      " 1   current_age        2000 non-null   int64  \n",
      " 2   is_male            2000 non-null   int64  \n",
      " 3   debt/salary_ratio  2000 non-null   float64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 62.6 KB\n",
      "\n",
      "   client_id  current_age  is_male  debt/salary_ratio\n",
      "0        825           53        0             213.77\n",
      "1       1746           53        0             247.69\n",
      "2       1718           81        0               0.59\n",
      "3        708           63        0              80.96\n",
      "4       1164           43        1             167.62\n"
     ]
    }
   ],
   "source": [
    "df_users = pd.read_csv('data/users_data.csv')\n",
    "\n",
    "df_users = (\n",
    "    df_users\n",
    "    .drop('retirement_age', axis=1)\n",
    "    .drop('birth_year', axis=1)\n",
    "    .drop('birth_month', axis=1)\n",
    "    .drop('address', axis=1)\n",
    "    .drop('latitude', axis=1)\n",
    "    .drop('longitude', axis=1)\n",
    "    .drop('per_capita_income', axis=1)\n",
    "    .drop('credit_score', axis=1)\n",
    "    .drop('num_credit_cards', axis=1)\n",
    ")\n",
    "df_users['yearly_income'] = df_users['yearly_income'].str.replace('$', '', regex=False).str.replace(',', '').astype(float)\n",
    "df_users['total_debt'] = df_users['total_debt'].str.replace('$', '', regex=False).str.replace(',', '').astype(float)\n",
    "df_users['debt/salary_ratio'] = round(df_users['total_debt']/df_users['yearly_income']*100,2)\n",
    "df_users = df_users.drop('yearly_income', axis=1).drop('total_debt', axis=1)\n",
    "df_users['gender'] = df_users['gender'].map({'Male':1, 'Female':0}).astype(int)\n",
    "df_users = df_users.rename(columns={'id':'client_id', 'gender':'is_male'})\n",
    "\n",
    "df_users.info()\n",
    "print()\n",
    "print(df_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7326be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6146 entries, 0 to 6145\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype\n",
      "---  ------                 --------------  -----\n",
      " 0   card_id                6146 non-null   int64\n",
      " 1   card_brand             6146 non-null   int64\n",
      " 2   card_type              6146 non-null   int64\n",
      " 3   year_pin_last_changed  6146 non-null   int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 192.2 KB\n",
      "\n",
      "    card_id  card_brand  card_type  year_pin_last_changed\n",
      "0      4524           0          1                   2008\n",
      "1      2731           0          1                   2014\n",
      "2      3701           0          1                   2004\n",
      "3        42           0          0                   2012\n",
      "4      4659           1          2                   2009\n",
      "5      4537           0          0                   2012\n",
      "6      1278           0          1                   2011\n",
      "7      3687           1          1                   2015\n",
      "8      3465           1          2                   2015\n",
      "9      3754           1          2                   2012\n",
      "10     5144           1          1                   2009\n",
      "11     2029           1          1                   2008\n",
      "12     2379           1          1                   2019\n",
      "13     2732           0          1                   2014\n",
      "14     4706           1          1                   2009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "df_cards = pd.read_csv('data/cards_data.csv')\n",
    "brands = [['Visa', 'Mastercard', 'Discover', 'Amex']]\n",
    "types = [['Credit', 'Debit', 'Debit (Prepaid)']]\n",
    "ode_brand = OrdinalEncoder(categories=brands)\n",
    "ode_type = OrdinalEncoder(categories=types)\n",
    "\n",
    "df_cards = (\n",
    "    df_cards\n",
    "    .drop('client_id', axis=1)\n",
    "    .drop('card_number', axis=1)\n",
    "    .drop('expires', axis=1)\n",
    "    .drop('cvv', axis=1)\n",
    "    .drop('has_chip', axis=1)\n",
    "    .drop('num_cards_issued', axis=1)\n",
    "    .drop('credit_limit', axis=1)\n",
    "    .drop('acct_open_date', axis=1)\n",
    "    .drop('card_on_dark_web', axis=1)\n",
    ")\n",
    "df_cards['card_brand'] = ode_brand.fit_transform(df_cards[['card_brand']])\n",
    "df_cards['card_type'] = ode_type.fit_transform(df_cards[['card_type']])\n",
    "df_cards['card_brand'] = df_cards['card_brand'].astype(int)\n",
    "df_cards['card_type'] = df_cards['card_type'].astype(int)\n",
    "df_cards = df_cards.rename(columns={'id':'card_id'})\n",
    "\n",
    "df_cards.info()\n",
    "print()\n",
    "print(df_cards.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34308018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8773196 entries, 0 to 8773195\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   amount                 float64\n",
      " 1   merchant_state         int64  \n",
      " 2   current_age            int64  \n",
      " 3   is_male                int64  \n",
      " 4   debt/salary_ratio      float64\n",
      " 5   card_brand             int64  \n",
      " 6   card_type              int64  \n",
      " 7   year_pin_last_changed  int64  \n",
      " 8   is_fraud               int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 602.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged = pd.merge(df_main, df_users, on='client_id', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_cards, on='card_id', how='inner')\n",
    "df_merged = pd.merge(df_merged, df_fraud, on='id', how='inner')\n",
    "df_merged = (\n",
    "    df_merged\n",
    "    .drop('id', axis=1)\n",
    "    .drop('client_id', axis=1)\n",
    "    .drop('card_id', axis=1)\n",
    ")\n",
    "\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526b25d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (5263917, 9), Val shape: (1754639, 9), Test shape: (1754640, 9)\n",
      "Fraud ratio in Train: 0.0015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, average_precision_score\n",
    "\n",
    "# 1. ë°ì´í„° ì „ì²˜ë¦¬ (ì œì•ˆí•´ì£¼ì‹  df_mergedê°€ ìˆë‹¤ê³  ê°€ì •)\n",
    "# -----------------------------------------------------------\n",
    "# (1) Amount: ì ˆëŒ“ê°’ ì²˜ë¦¬\n",
    "df_merged['amount'] = df_merged['amount'].abs()\n",
    "\n",
    "# (2) Year PIN: ê²½ê³¼ ì—°ìˆ˜ë¡œ ë³€í™˜ (í˜„ì¬ 2026ë…„ ê¸°ì¤€ ê°€ì •, ë°ì´í„°ì…‹ ì‹œì ì— ë§ê²Œ ì¡°ì • í•„ìš”)\n",
    "# ë°ì´í„°ì…‹ì´ ê³¼ê±° ë°ì´í„°ë¼ë©´ í•´ë‹¹ ë°ì´í„°ì˜ ìµœëŒ€ ì—°ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹¼ì•¼ í•©ë‹ˆë‹¤.\n",
    "max_year = df_merged['year_pin_last_changed'].max()\n",
    "df_merged['pin_years_gap'] = max_year - df_merged['year_pin_last_changed']\n",
    "df_merged = df_merged.drop('year_pin_last_changed', axis=1)\n",
    "\n",
    "# (3) Merchant State: ë¹ˆë„ ì¸ì½”ë”© (Frequency Encoding)\n",
    "# ëª¨ë¸ì´ ëª¨ë¥´ëŠ” ì§€ì—­ì´ ë“¤ì–´ì™€ë„ 'ë¹ˆë„ 0' í˜¹ì€ 'í‰ê·  ë¹ˆë„'ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•´ì§\n",
    "state_counts = df_merged['merchant_state'].value_counts(normalize=True)\n",
    "df_merged['merchant_state_freq'] = df_merged['merchant_state'].map(state_counts)\n",
    "# ì›ë³¸ ë¼ë²¨ ì»¬ëŸ¼ì€ ìœ ì§€í•˜ê±°ë‚˜ ì‚­ì œ (íŠ¸ë¦¬ ëª¨ë¸ì€ ë‘˜ ë‹¤ ìˆì–´ë„ ì˜ ì²˜ë¦¬í•¨)\n",
    "# df_merged = df_merged.drop('merchant_state', axis=1) \n",
    "\n",
    "# 2. ë°ì´í„° ë¶„í•  (Stratified Split í•„ìˆ˜!)\n",
    "# -----------------------------------------------------------\n",
    "X = df_merged.drop('is_fraud', axis=1)\n",
    "y = df_merged['is_fraud']\n",
    "\n",
    "# Train(60%), Temp(40%) ë¶„ë¦¬\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Tempë¥¼ ë‹¤ì‹œ Validation(20%), Test(20%)ë¡œ ë¶„ë¦¬\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Fraud ratio in Train: {y_train.mean():.4f}\") # ì•½ 0.0015 í™•ì¸ í•„ìš”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62137794",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 1\n",
    "\n",
    "1ì°¨ ì •ì œ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ XGBoostë¥¼ í†µí•œ ëª¨ë¸í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŒŒë¼ë¯¸í„°ëŠ” scale_pos_weight = ì‹¤ì œ (ì •ìƒ ë°ì´í„° ìˆ˜ / ì‚¬ê¸° ë°ì´í„° ìˆ˜) ë°°ìœ¨ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì•½ 686)\n",
    "\n",
    "ê²°ê³¼ : precision = 0.01, recall = 0.90\n",
    "\n",
    "precisionì´ ë„ˆë¬´ ë‚®ìŠµë‹ˆë‹¤. ì¦‰ ë„ˆë¬´ ë§ì€ ë°ì´í„°(ê±°ì˜ ì „ì²´ì˜ 10%ë¹„ìœ¨)ë¥¼ fraudë¡œ íŒë‹¨í•˜ì˜€ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c2a60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated scale_pos_weight: 686.37\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\n",
      "[0]\tvalidation_0-auc:0.94859\n",
      "[10]\tvalidation_0-auc:0.94986\n",
      "[20]\tvalidation_0-auc:0.95168\n",
      "[30]\tvalidation_0-auc:0.95277\n",
      "[40]\tvalidation_0-auc:0.95460\n",
      "[50]\tvalidation_0-auc:0.95508\n",
      "[60]\tvalidation_0-auc:0.95595\n",
      "[70]\tvalidation_0-auc:0.95721\n",
      "[80]\tvalidation_0-auc:0.95809\n",
      "[90]\tvalidation_0-auc:0.95879\n",
      "[99]\tvalidation_0-auc:0.95906\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[1595317  156770]\n",
      " [    246    2307]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95   1752087\n",
      "           1       0.01      0.90      0.03      2553\n",
      "\n",
      "    accuracy                           0.91   1754640\n",
      "   macro avg       0.51      0.91      0.49   1754640\n",
      "weighted avg       1.00      0.91      0.95   1754640\n",
      "\n",
      "\n",
      "=== AUPRC Score: 0.3144 ===\n"
     ]
    }
   ],
   "source": [
    "# 3. ëª¨ë¸ í•™ìŠµ (XGBoost)\n",
    "# -----------------------------------------------------------\n",
    "# ë¶ˆê· í˜• ë°ì´í„° ê°€ì¤‘ì¹˜ ê³„ì‚°: (ì •ìƒ ë°ì´í„° ìˆ˜) / (ì‚¬ê¸° ë°ì´í„° ìˆ˜)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,      # íŠ¸ë¦¬ ê°œìˆ˜ (ì ì ˆíˆ ì¡°ì ˆ)\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,           # íŠ¸ë¦¬ ê¹Šì´\n",
    "    scale_pos_weight=scale_pos_weight, # [í•µì‹¬] ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜\n",
    "    eval_metric='auc',   # í‰ê°€ ì§€í‘œ: AUC\n",
    "    n_jobs=-1,             # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ í•™ìŠµ ì‹œì‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "# -----------------------------------------------------------\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1] # í™•ë¥ ê°’\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n=== AUPRC Score: {average_precision_score(y_test, y_prob):.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ad086",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 2\n",
    "\n",
    "1ì°¨ í•™ìŠµì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ scale_pos_weight = 25ë¡œ ê¸°ì¡´ì˜ ì œê³±ê·¼ ì´í•˜ì˜ ìˆ˜ì¹˜ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ threshold = 0.8ë¥¼ ì ìš©í•˜ì—¬ precisionì„ ë‚®ì¶”ëŠ” ê²ƒì„ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : precision = 0.67, recall = 0.30\n",
    "\n",
    "precisionì´ ê¸‰ê²©í•˜ê²Œ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¬ê¸°ë¡œ íŒë‹¨í•˜ëŠ” ê±´ìˆ˜ ìì²´ëŠ” ë¹„ì•½ì ìœ¼ë¡œ ì¤„ì–´ë“¤ì–´ 70%ì˜ ì‚¬ê¸°ë¥¼ ë†“ì³¤ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c3001bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated scale_pos_weight: 686.37\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\n",
      "[0]\tvalidation_0-auc:0.94753\n",
      "[10]\tvalidation_0-auc:0.95002\n",
      "[20]\tvalidation_0-auc:0.95117\n",
      "[30]\tvalidation_0-auc:0.95198\n",
      "[40]\tvalidation_0-auc:0.95345\n",
      "[50]\tvalidation_0-auc:0.95551\n",
      "[60]\tvalidation_0-auc:0.95744\n",
      "[70]\tvalidation_0-auc:0.95856\n",
      "[80]\tvalidation_0-auc:0.95911\n",
      "[90]\tvalidation_0-auc:0.95980\n",
      "[99]\tvalidation_0-auc:0.96058\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[1751701     386]\n",
      " [   1786     767]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1752087\n",
      "           1       0.67      0.30      0.41      2553\n",
      "\n",
      "    accuracy                           1.00   1754640\n",
      "   macro avg       0.83      0.65      0.71   1754640\n",
      "weighted avg       1.00      1.00      1.00   1754640\n",
      "\n",
      "\n",
      "=== AUPRC Score: 0.3426 ===\n"
     ]
    }
   ],
   "source": [
    "# 3. ëª¨ë¸ í•™ìŠµ (XGBoost)\n",
    "# -----------------------------------------------------------\n",
    "# ë¶ˆê· í˜• ë°ì´í„° ê°€ì¤‘ì¹˜ ê³„ì‚°: (ì •ìƒ ë°ì´í„° ìˆ˜) / (ì‚¬ê¸° ë°ì´í„° ìˆ˜)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,      # íŠ¸ë¦¬ ê°œìˆ˜ (ì ì ˆíˆ ì¡°ì ˆ)\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,           # íŠ¸ë¦¬ ê¹Šì´\n",
    "    scale_pos_weight=25, # [í•µì‹¬] ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ê°€ì¤‘ì¹˜\n",
    "    eval_metric='auc',   # í‰ê°€ ì§€í‘œ: Area Under Precision-Recall Curve (ë¶ˆê· í˜•ì— ì¢‹ìŒ)\n",
    "    n_jobs=-1,             # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ í•™ìŠµ ì‹œì‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "# -----------------------------------------------------------\n",
    "y_prob = model.predict_proba(X_test)[:, 1] # í™•ë¥ ê°’\n",
    "threshold = 0.8  # 0.5 ëŒ€ì‹  threshold ì´ìƒì¼ ë•Œë§Œ ì‚¬ê¸°ë¡œ íŒë‹¨\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n=== AUPRC Score: {average_precision_score(y_test, y_prob):.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c26896",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 3\n",
    "\n",
    "ë°ì´í„° ë¹„ìœ¨ì¡°ì ˆì˜ í•„ìš”ì„±ì„ íŒë‹¨í•˜ê¸° ìœ„í•´ scale_pos_weight íŒŒë¼ë¯¸í„°ë¥¼ ì•„ì˜ˆ ì œê±°í•©ë‹ˆë‹¤.\n",
    "\n",
    "threshold = 0.9ë¥¼ ì ìš©í•˜ì—¬ precisionì„ ë”ë”ìš± ë‚®ì¶”ëŠ” ê²ƒì„ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : precision = 0.98, recall = 0.05\n",
    "\n",
    "recallì´ ë„ˆë¬´ ë‚®ì€ ê²ƒìœ¼ë¡œ ë³´ì•„ ëª¨ë¸ì´ ì‚¬ê¸°ì— ëŒ€í•œ íŒ¨í„´ì„ ì œëŒ€ë¡œ í•™ìŠµí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì •ìƒ-ì‚¬ê¸° ë°ì´í„° ë¹„ìœ¨ ì¡°ì •ì€ ë°˜ë“œì‹œ í•„ìš”í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6205c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated scale_pos_weight: 686.37\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\n",
      "[0]\tvalidation_0-auc:0.94698\n",
      "[10]\tvalidation_0-auc:0.94732\n",
      "[20]\tvalidation_0-auc:0.94901\n",
      "[30]\tvalidation_0-auc:0.95103\n",
      "[40]\tvalidation_0-auc:0.95277\n",
      "[50]\tvalidation_0-auc:0.95393\n",
      "[60]\tvalidation_0-auc:0.95510\n",
      "[70]\tvalidation_0-auc:0.95573\n",
      "[80]\tvalidation_0-auc:0.95663\n",
      "[90]\tvalidation_0-auc:0.95704\n",
      "[99]\tvalidation_0-auc:0.95743\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[1752085       2]\n",
      " [   2431     122]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1752087\n",
      "           1       0.98      0.05      0.09      2553\n",
      "\n",
      "    accuracy                           1.00   1754640\n",
      "   macro avg       0.99      0.52      0.55   1754640\n",
      "weighted avg       1.00      1.00      1.00   1754640\n",
      "\n",
      "\n",
      "=== AUPRC Score: 0.3573 ===\n"
     ]
    }
   ],
   "source": [
    "# 3. ëª¨ë¸ í•™ìŠµ (XGBoost)\n",
    "# -----------------------------------------------------------\n",
    "# ë¶ˆê· í˜• ë°ì´í„° ê°€ì¤‘ì¹˜ ê³„ì‚°: (ì •ìƒ ë°ì´í„° ìˆ˜) / (ì‚¬ê¸° ë°ì´í„° ìˆ˜)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,      # íŠ¸ë¦¬ ê°œìˆ˜ (ì ì ˆíˆ ì¡°ì ˆ)\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,           # íŠ¸ë¦¬ ê¹Šì´\n",
    "    eval_metric='auc',   # í‰ê°€ ì§€í‘œ: Area Under Precision-Recall Curve (ë¶ˆê· í˜•ì— ì¢‹ìŒ)\n",
    "    n_jobs=-1,             # ëª¨ë“  CPU ì½”ì–´ ì‚¬ìš©\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ í•™ìŠµ ì‹œì‘ (ë°ì´í„°ê°€ ë§ì•„ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)...\")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "# 4. ì„±ëŠ¥ í‰ê°€\n",
    "# -----------------------------------------------------------\n",
    "y_prob = model.predict_proba(X_test)[:, 1] # í™•ë¥ ê°’\n",
    "threshold = 0.9  # 0.5 ëŒ€ì‹  threshold ì´ìƒì¼ ë•Œë§Œ ì‚¬ê¸°ë¡œ íŒë‹¨\n",
    "y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\n=== AUPRC Score: {average_precision_score(y_test, y_prob):.4f} ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb198f60",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 4\n",
    "\n",
    "ì•™ìƒë¸”ì„ í†µí•œ XGBoost + RandomForest ë™ì‹œí•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì •ìƒ ë°ì´í„°ì˜ under_samplingì„ í†µí•´ ì •ìƒ:ì‚¬ê¸° ë°ì´í„° ë¹„ìœ¨ì„ 10:1ë¡œ ì¤„ì…ë‹ˆë‹¤.\n",
    "\n",
    "ëª©í‘œ precision = 0.999ì— ë„ë‹¬í•˜ëŠ” thresholdê°’ì„ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.995, precision = 0.7721, recall = 0.1128\n",
    "\n",
    "\n",
    "threshold = 0.999, precision = 1.0000, recall = 0.0027\n",
    "\n",
    "ëª¨ë¸ì´ fraudë¥¼ íŒë‹¨í•  ê·¼ê±° ìì²´ê°€ ë¶€ì¡±í•œ ìƒíƒœë¼ëŠ” ê²°ë¡ ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„° ì •ì œë¥¼ ë‹¤ì‹œ ì§„í–‰í•˜ë˜, íŠ¹íˆ ê±°ë˜ì˜ ë§¥ë½ íŒŒì•… ë¶€ë¶„ì— ì‹ ê²½ì„ ì¨ì„œ ë‹¤ì‹œ ë§Œë“¤ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b81addb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Train shape: (112310, 9)\n",
      "Resampled Fraud ratio: 0.0909\n",
      "ğŸš€ ìŠ¤ë‚˜ì´í¼ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "\n",
      "=== ğŸ¯ Threshold Tuning for Precision >= 0.99 ===\n",
      "Threshold  | Precision  | Recall     | FP Count   | TP Count  \n",
      "------------------------------------------------------------\n",
      "0.500      | 0.0503     | 0.7047     | 33959      | 1799      \n",
      "0.550      | 0.0636     | 0.6479     | 24356      | 1654      \n",
      "0.600      | 0.0878     | 0.5734     | 15209      | 1464      \n",
      "0.650      | 0.1262     | 0.4990     | 8825       | 1274      \n",
      "0.700      | 0.1912     | 0.4418     | 4772       | 1128      \n",
      "0.750      | 0.3080     | 0.3897     | 2236       | 995       \n",
      "0.800      | 0.4837     | 0.3486     | 950        | 890       \n",
      "0.850      | 0.6188     | 0.3173     | 499        | 810       \n",
      "0.900      | 0.6715     | 0.3059     | 382        | 781       \n",
      "0.950      | 0.7171     | 0.2949     | 297        | 753       \n",
      "0.950      | 0.7171     | 0.2949     | 297        | 753       \n",
      "0.960      | 0.7228     | 0.2859     | 280        | 730       \n",
      "0.970      | 0.7246     | 0.2742     | 266        | 700       \n",
      "0.980      | 0.7131     | 0.2405     | 247        | 614       \n",
      "0.990      | 0.7669     | 0.1817     | 141        | 464       \n",
      "0.995      | 0.7721     | 0.1128     | 85         | 288       \n",
      "0.999      | 1.0000     | 0.0027     | 0          | 7         \n",
      "------------------------------------------------------------\n",
      "\n",
      "âœ… ëª©í‘œ ë‹¬ì„±! ì¶”ì²œ Threshold: 0.999\n",
      "\n",
      "=== Final Report (Threshold: 0.999) ===\n",
      "[[1752087       0]\n",
      " [   2546       7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1752087\n",
      "           1       1.00      0.00      0.01      2553\n",
      "\n",
      "    accuracy                           1.00   1754640\n",
      "   macro avg       1.00      0.50      0.50   1754640\n",
      "weighted avg       1.00      1.00      1.00   1754640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 1. ë°ì´í„° ì „ì²˜ë¦¬ (ì´ì „ê³¼ ë™ì¼)\n",
    "# -----------------------------------------------------------\n",
    "if 'amount' in df_merged.columns:\n",
    "    df_merged['amount'] = df_merged['amount'].abs()\n",
    "\n",
    "if 'year_pin_last_changed' in df_merged.columns:\n",
    "    max_year = df_merged['year_pin_last_changed'].max()\n",
    "    df_merged['pin_years_gap'] = max_year - df_merged['year_pin_last_changed']\n",
    "    df_merged = df_merged.drop('year_pin_last_changed', axis=1)\n",
    "\n",
    "# Merchant State ë¹ˆë„ ì¸ì½”ë”© (í•„ìˆ˜)\n",
    "if 'merchant_state' in df_merged.columns and df_merged['merchant_state'].dtype == 'int64':\n",
    "    state_counts = df_merged['merchant_state'].value_counts(normalize=True)\n",
    "    df_merged['merchant_state_freq'] = df_merged['merchant_state'].map(state_counts)\n",
    "    # df_merged = df_merged.drop('merchant_state', axis=1) # ì„ íƒ ì‚¬í•­\n",
    "\n",
    "X = df_merged.drop('is_fraud', axis=1)\n",
    "y = df_merged['is_fraud']\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. ë³´ìˆ˜ì ì¸ ìƒ˜í”Œë§ (Undersampling Only)\n",
    "# -----------------------------------------------------------\n",
    "# ì •ìƒ:ì‚¬ê¸° ë¹„ìœ¨ì„ 10:1 (0.1) ì •ë„ë¡œ ë§ì¶¥ë‹ˆë‹¤.\n",
    "# ì •ìƒì„ ë„ˆë¬´ ë§ì´ ë²„ë¦¬ë©´ \"ì •ìƒ íŒ¨í„´\"ì„ í•™ìŠµ ëª»í•´ì„œ ì˜¤íƒ(FP)ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\n",
    "# 10:1 ì •ë„ë©´ ëª¨ë¸ì´ \"ì•„, ì •ìƒì´ í›¨ì”¬ ë§êµ¬ë‚˜\"ë¼ê³  ì¸ì§€í•˜ì—¬ ë³´ìˆ˜ì ìœ¼ë¡œ ë³€í•©ë‹ˆë‹¤.\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Resampled Train shape: {X_resampled.shape}\")\n",
    "print(f\"Resampled Fraud ratio: {y_resampled.mean():.4f}\") # ì•½ 0.09 (9%)\n",
    "\n",
    "# 3. ëª¨ë¸ ì •ì˜ (ê°€ì¤‘ì¹˜ ì œê±° & ë³´ìˆ˜ì  ì„¤ì •)\n",
    "# -----------------------------------------------------------\n",
    "# (1) XGBoost: scale_pos_weight ì œê±° (ê¸°ë³¸ê°’ 1)\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,        # ê¹Šì´ë¥¼ ì¤„ì—¬ì„œ ê³¼ì í•© ë°©ì§€\n",
    "    scale_pos_weight=1, # [í•µì‹¬] ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì§€ ì•ŠìŒ -> Precision ì¤‘ì‹œ\n",
    "    eval_metric='auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# (2) Random Forest: Precision í™•ë³´ì— ìœ ë¦¬\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=12,       # ë„ˆë¬´ ê¹Šì§€ ì•Šê²Œ\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. ì•™ìƒë¸” í•™ìŠµ\n",
    "# -----------------------------------------------------------\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf', rf_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ ìŠ¤ë‚˜ì´í¼ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "voting_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 5. ìµœì ì˜ Threshold íƒìƒ‰\n",
    "# -----------------------------------------------------------\n",
    "# ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ í™•ë¥  ì˜ˆì¸¡\n",
    "y_prob = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Threshold Tuning for Precision >= 0.99 ===\")\n",
    "print(f\"{'Threshold':<10} | {'Precision':<10} | {'Recall':<10} | {'FP Count':<10} | {'TP Count':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_th = 0.5\n",
    "found = False\n",
    "\n",
    "# 0.5ë¶€í„° 0.999ê¹Œì§€ ì´˜ì´˜í•˜ê²Œ ê²€ì‚¬\n",
    "thresholds = np.arange(0.5, 1.0, 0.05).tolist() + [0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.999]\n",
    "thresholds = sorted(list(set(thresholds)))\n",
    "\n",
    "for th in thresholds:\n",
    "    y_pred_th = (y_prob >= th).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_th).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"{th:<10.3f} | {precision:<10.4f} | {recall:<10.4f} | {fp:<10} | {tp:<10}\")\n",
    "    \n",
    "    # ëª©í‘œ ë‹¬ì„± ì¡°ê±´ í™•ì¸ (Precision >= 0.99 ì´ë©´ì„œ Recallì´ 0ì´ ì•„ë‹Œ ê²½ìš°)\n",
    "    if precision >= 0.99 and recall > 0.0:\n",
    "        if not found: # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì²« ë²ˆì§¸(ê°€ì¥ ë‚®ì€) Threshold ì €ì¥\n",
    "            best_th = th\n",
    "            found = True\n",
    "        # ë” ë†’ì€ Recallì„ ì°¾ê¸° ìœ„í•´ best_thë¥¼ ê³„ì† ê°±ì‹ í•  ìˆ˜ë„ ìˆìŒ (ì—¬ê¸°ì„œëŠ” ì²« ë‹¬ì„± ì§€ì  ê¸°ì¤€)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if found:\n",
    "    print(f\"\\nâœ… ëª©í‘œ ë‹¬ì„±! ì¶”ì²œ Threshold: {best_th}\")\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "    final_pred = (y_prob >= best_th).astype(int)\n",
    "    print(f\"\\n=== Final Report (Threshold: {best_th}) ===\")\n",
    "    print(confusion_matrix(y_test, final_pred))\n",
    "    print(classification_report(y_test, final_pred))\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Precision 0.99ë¥¼ ë‹¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ê°•ë ¥í•œ Featureê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9103dec",
   "metadata": {},
   "source": [
    "# 2ì°¨ ë°ì´í„° ì •ì œ\n",
    "\n",
    "ê¸°ì¡´ì— ë²„ë ¤ì¡Œë˜ ë°ì´í„°ë¥¼ ë˜ì‚´ë¦¬ê³  ëª¨ë¸í•™ìŠµì— ìœ íš¨í•œ ìˆ«ìí˜• ë°ì´í„°ë¡œ ì •ì œí•©ë‹ˆë‹¤.\n",
    "\n",
    "1. í•µì‹¬ ìˆ˜ì¹˜\n",
    "\n",
    "'amount', # ê±°ë˜ ê¸ˆì•¡(ì ˆëŒ€ê°’)\n",
    "\n",
    "'utilization_ratio', # í•œë„ ëŒ€ë¹„ ê¸ˆì•¡\n",
    "\n",
    "'amount_income_ratio', # ì†Œë“ ëŒ€ë¹„ ê¸ˆì•¡\n",
    "\n",
    "2. ê¸°ìˆ ì /íŒ¨í„´ ë§¥ë½\n",
    "\n",
    "'tech_mismatch', # ICì¹´ë“œì¸ë° ë§ˆê·¸ë„¤í‹± ê±°ë˜ë¥¼ ì§„í–‰í–ˆëŠ”ì§€ ì—¬ë¶€\n",
    "\n",
    "'pin_years_gap', # ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ì˜¤ë˜ëëŠ”ì§€\n",
    "\n",
    "'num_credit_cards', # ì¹´ë“œ ê°œìˆ˜ (ë‹¤ì¤‘ ë°œê¸‰ ì‚¬ê¸° ì—°ê´€)\n",
    "\n",
    "3. ì‹œê°„ ë§¥ë½\n",
    "\n",
    "'hour', # ê±°ë˜ ì‹œê°„(ì‹œ)\n",
    "\n",
    "'is_night', # ê±°ë˜ê°€ 00ì‹œ~06ì‹œ ì‚¬ì´ì— ì´ë£¨ì–´ì¡ŒëŠ”ì§€ ì—¬ë¶€\n",
    "\n",
    "4. ìœ„ì¹˜/ì—…ì¢… ë§¥ë½ (Risk Scoreë¡œ ë³€í™˜ë¨)\n",
    "\n",
    "'mcc_risk', # ì—…ì¢… ìœ„í—˜ë„\n",
    "\n",
    "'state_risk', # ì£¼(State) ìœ„í—˜ë„\n",
    "\n",
    "'zip_risk', # ì§€ì—­(Zip) ìœ„í—˜ë„\n",
    "\n",
    "5. ì‚¬ìš©ì ì •ë³´ (ë³´ì¡°)\n",
    "\n",
    "'current_age', # ì¹´ë“œ ëª…ì˜ì ë‚˜ì´\n",
    "\n",
    "'credit_score', # ì‹ ìš©ì ìˆ˜ ë‚®ìœ¼ë©´ ìœ„í—˜í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "6. íƒ€ê²Ÿ (ì •ë‹µ)\n",
    "\n",
    "'is_fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4327e2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading Data...\n",
      "â³ Merging Data...\n",
      "âœ… Merged Shape: (8914963, 37)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ (íŒŒì¼ ê²½ë¡œëŠ” ì‹¤ì œ í™˜ê²½ì— ë§ì¶°ì£¼ì„¸ìš”)\n",
    "# transactions_dataëŠ” ì›Œë‚™ í¬ë‹ˆ chunkë¡œ ë‚˜ëˆ„ê±°ë‚˜ daskë¥¼ ì¨ì•¼ í•  ìˆ˜ë„ ìˆì§€ë§Œ, \n",
    "# ì—¬ê¸°ì„  pandasë¡œ ë¡œë“œ ê°€ëŠ¥í•˜ë‹¤ê³  ê°€ì •í•˜ê³  ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "print(\"â³ Loading Data...\")\n",
    "\n",
    "# (1) Users & Cards\n",
    "users = pd.read_csv('data/users_data.csv')\n",
    "cards = pd.read_csv('data/cards_data.csv')\n",
    "users = users.rename(columns={'id':'client_id'})\n",
    "cards = cards.rename(columns={'id':'card_id'})\n",
    "\n",
    "# (2) Transactions (ì˜ˆì‹œ: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¶ˆëŸ¬ì™€ì„œ ë©”ëª¨ë¦¬ ì ˆì•½ ê°€ëŠ¥)\n",
    "# use_chip, merchant_city, zip, mcc ë“± ë²„ë¦¬ì§€ ë§ê³  ë‹¤ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "trans = pd.read_csv('data/transactions_data.csv') \n",
    "\n",
    "# (3) Labels (Target)\n",
    "labels = pd.read_csv('data/train_fraud_labels.csv') # id, target('Yes'/'No')\n",
    "\n",
    "# 2. ë°ì´í„° ë³‘í•© (Merge)\n",
    "print(\"â³ Merging Data...\")\n",
    "\n",
    "# Transactions + Labels (id ê¸°ì¤€)\n",
    "# íƒ€ê²Ÿì´ ì—†ëŠ” ë°ì´í„°ëŠ” í•™ìŠµì— ì“¸ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ Inner Join\n",
    "df = pd.merge(trans, labels, on='id', how='inner')\n",
    "\n",
    "# + Users (client_id ê¸°ì¤€)\n",
    "df = pd.merge(df, users, on='client_id', how='left')\n",
    "\n",
    "# + Cards (card_id ê¸°ì¤€)\n",
    "# client_idë„ ê°™ì´ í‚¤ë¡œ ì¡ìœ¼ë©´ ë” ì•ˆì „í•©ë‹ˆë‹¤.\n",
    "df = pd.merge(df, cards, on=['card_id', 'client_id'], how='left')\n",
    "\n",
    "print(f\"âœ… Merged Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e2006fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Cleaning Data...\n",
      "âœ… Cleaning Complete\n"
     ]
    }
   ],
   "source": [
    "# 3. ê¸°ì´ˆ ì •ì œ í•¨ìˆ˜\n",
    "def clean_dollar(x):\n",
    "    if isinstance(x, str):\n",
    "        return float(x.replace('$', '').replace(',', ''))\n",
    "    return x\n",
    "\n",
    "print(\"â³ Cleaning Data...\")\n",
    "\n",
    "# (1) ê¸ˆì•¡ ê´€ë ¨ ì»¬ëŸ¼ $ ì œê±° ë° ì‹¤ìˆ˜í˜• ë³€í™˜\n",
    "money_cols = ['amount', 'per_capita_income', 'yearly_income', 'total_debt', 'credit_limit']\n",
    "for col in money_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(clean_dollar)\n",
    "\n",
    "# (2) Amount ì ˆëŒ€ê°’ ì²˜ë¦¬ (í™˜ë¶ˆ ë°ì´í„°ë„ ê·œëª¨ë¡œ íŒë‹¨)\n",
    "df['amount'] = df['amount'].abs()\n",
    "\n",
    "# (3) Target ë³€í™˜ (Yes/No -> 1/0)\n",
    "df['is_fraud'] = df['target'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df = df.drop(columns=['target']) # ê¸°ì¡´ ë¬¸ìì—´ ì»¬ëŸ¼ ì œê±°\n",
    "\n",
    "# (4) Online Transaction ì²˜ë¦¬\n",
    "# merchant_stateê°€ ë¹„ì–´ìˆìœ¼ë©´(NaN) -> 'Online'ìœ¼ë¡œ ì±„ì›€ (ì‘ì„±ìë‹˜ ì „ëµ ìœ ì§€)\n",
    "df['merchant_state'] = df['merchant_state'].fillna('Online')\n",
    "\n",
    "# (5) ì¹´ë“œ ì •ë³´ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í˜¹ì‹œ Join ì•ˆ ëœ ê²½ìš°)\n",
    "df['has_chip'] = df['has_chip'].fillna('NO') # ë³´ìˆ˜ì ìœ¼ë¡œ ì—†ìŒ ì²˜ë¦¬\n",
    "\n",
    "print(\"âœ… Cleaning Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d669eb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Engineering Sniper Features...\n",
      "âœ… Feature Engineering Complete\n"
     ]
    }
   ],
   "source": [
    "print(\"â³ Engineering Sniper Features...\")\n",
    "\n",
    "# [Feature 1] ê¸°ìˆ ì  ëª¨ìˆœ (Tech Mismatch)\n",
    "# ì¹©ì´ ìˆëŠ” ì¹´ë“œ(YES)ì¸ë°, ê²°ì œëŠ” ê¸ì–´ì„œ(Swipe) í–ˆë‹¤? -> ë³µì œì¹´ë“œ ì˜ì‹¬\n",
    "# use_chip: 'Swipe Transaction', 'Chip Transaction', 'Online Transaction'\n",
    "# has_chip: 'YES', 'NO'\n",
    "def check_tech_mismatch(row):\n",
    "    # ì˜¨ë¼ì¸ ê±°ë˜ëŠ” ì¹© ì—¬ë¶€ì™€ ìƒê´€ ì—†ìŒ\n",
    "    if row['use_chip'] == 'Online Transaction':\n",
    "        return 0\n",
    "    # ì¹©ì´ ìˆëŠ”ë° ìŠ¤ì™€ì´í”„ í–ˆìœ¼ë©´ ì˜ì‹¬ (1)\n",
    "    if row['has_chip'] == 'YES' and row['use_chip'] == 'Swipe Transaction':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['tech_mismatch'] = df.apply(check_tech_mismatch, axis=1)\n",
    "\n",
    "# [Feature 2] í•œë„ ì†Œì§„ìœ¨ (Utilization Ratio)\n",
    "# 500ë‹¬ëŸ¬ ê²°ì œë¼ë„, í•œë„ê°€ 500ë‹¬ëŸ¬ì¸ ì¹´ë“œë¥¼ ê½‰ ì±„ì›Œ ì“´ ê±°ë©´ ìœ„í—˜í•¨ (ì†ì¹­ 'ì¹´ë“œê¹¡' ë“±)\n",
    "df['utilization_ratio'] = df['amount'] / df['credit_limit']\n",
    "\n",
    "# [Feature 3] ì†Œë“ ëŒ€ë¹„ ì§€ì¶œ ë¹„ìœ¨ (Income Ratio)\n",
    "# ì—°ë´‰ 3ë§Œë¶ˆì¸ ì‚¬ëŒì´ í•œ ë²ˆì— 1ë§Œë¶ˆì„ ê¸ìœ¼ë©´ ì´ìƒí•¨\n",
    "# yearly_incomeì´ 0ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬\n",
    "df['amount_income_ratio'] = df['amount'] / (df['yearly_income'] + 1) \n",
    "\n",
    "# [Feature 4] ì‹œê°„ëŒ€ ì •ë³´ (Hour)\n",
    "# ë¬¸ìì—´ dateë¥¼ datetimeìœ¼ë¡œ ë³€í™˜\n",
    "df['date_obj'] = pd.to_datetime(df['date'])\n",
    "df['hour'] = df['date_obj'].dt.hour\n",
    "df['is_night'] = df['hour'].apply(lambda x: 1 if 0 <= x < 6 else 0) # ìƒˆë²½ 0ì‹œ~6ì‹œ\n",
    "\n",
    "# [Feature 5] PIN ë³€ê²½ ê²½ê³¼ ê¸°ê°„\n",
    "# ìµœê·¼ì— PINì„ ë°”ê¿¨ëŠ”ë°(í•´í‚¹ ë“±) ê³ ì•¡ ê²°ì œ? \n",
    "# í˜„ì¬ ì‹œì ì„ ë°ì´í„°ì˜ ìµœëŒ€ ì—°ë„ë¡œ ê°€ì • (2020ë…„)\n",
    "current_year = df['date_obj'].dt.year.max()\n",
    "df['pin_years_gap'] = current_year - df['year_pin_last_changed']\n",
    "\n",
    "# [Feature 6] MCC Risk Mapping (Target Encoding)\n",
    "# MCC ì½”ë“œ ìì²´ê°€ ì¤‘ìš”í•œ ê²Œ ì•„ë‹ˆë¼, \"ê·¸ ì—…ì¢…ì—ì„œ ì‚¬ê¸°ê°€ ì–¼ë§ˆë‚˜ ë¹ˆë²ˆí•œê°€\"ê°€ ì¤‘ìš”í•¨.\n",
    "# Train ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ê° MCCë³„ ì‚¬ê¸° í™•ë¥ ì„ ê³„ì‚°í•´ì„œ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "# ì£¼ì˜: Data Leakage ë°©ì§€ë¥¼ ìœ„í•´ ì›ì¹™ì ìœ¼ë¡œëŠ” Train Split í›„ì— í•´ì•¼ í•˜ì§€ë§Œ, \n",
    "# ë°ì´í„°ê°€ ì›Œë‚™ í¬ê³  ë¶„í¬ê°€ ì¼ì •í•˜ë‹¤ë©´ ì „ì²´ ê¸°ì¤€ìœ¼ë¡œ ë§µì„ ë§Œë“¤ì–´ë„ ë¬´ë°©í•©ë‹ˆë‹¤.\n",
    "mcc_risk_map = df.groupby('mcc')['is_fraud'].mean()\n",
    "df['mcc_risk'] = df['mcc'].map(mcc_risk_map)\n",
    "\n",
    "# [Feature 7] State Risk Mapping\n",
    "# \"CAëŠ” 199ë²ˆ\"ì´ë¼ëŠ” ìˆ«ìë³´ë‹¤ \"CAëŠ” ì‚¬ê¸°ìœ¨ 0.2%\"ë¼ëŠ” ìˆ«ìê°€ ëª¨ë¸ì—ê² í›¨ì”¬ ìœ ìµí•¨.\n",
    "state_risk_map = df.groupby('merchant_state')['is_fraud'].mean()\n",
    "df['state_risk'] = df['merchant_state'].map(state_risk_map)\n",
    "\n",
    "# [Feature 8] Zip code í™œìš© (Distance ëŒ€ì²´ì œ)\n",
    "# Zip codeëŠ” ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ, Zip codeë³„ ì‚¬ê¸° í™•ë¥ (Risk)ë¡œ ë³€í™˜\n",
    "zip_risk_map = df.groupby('zip')['is_fraud'].mean()\n",
    "df['zip_risk'] = df['zip'].map(zip_risk_map)\n",
    "# Zipì´ ì²˜ìŒ ë³´ëŠ” ê°’ì´ë¼ ë§¤í•‘ì´ ì•ˆë˜ë©´(NaN), í‰ê·  ì‚¬ê¸°ìœ¨ë¡œ ì±„ì›€\n",
    "df['zip_risk'] = df['zip_risk'].fillna(df['is_fraud'].mean())\n",
    "\n",
    "print(\"âœ… Feature Engineering Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d3c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Final Dataset Shape: (9151537, 14)\n",
      "   amount  utilization_ratio  amount_income_ratio  tech_mismatch  \\\n",
      "0   33.96           0.001930             0.000570              1   \n",
      "1    7.78           0.000442             0.000131              1   \n",
      "2   65.86           0.003742             0.001105              1   \n",
      "3    1.37           0.000078             0.000023              1   \n",
      "4  167.62           0.009524             0.002812              0   \n",
      "\n",
      "   pin_years_gap  num_credit_cards  hour  is_night  mcc_risk  state_risk  \\\n",
      "0              5                 4    13         0  0.000270    0.000035   \n",
      "1              5                 4    19         0  0.000181    0.000035   \n",
      "2              5                 4    22         0  0.000817    0.000035   \n",
      "3              5                 4    15         0  0.000134    0.000035   \n",
      "4              5                 4     8         0  0.001108    0.008378   \n",
      "\n",
      "   zip_risk  current_age  credit_score  is_fraud  \n",
      "0  0.000000           33           763         0  \n",
      "1  0.000000           33           763         0  \n",
      "2  0.000000           33           763         0  \n",
      "3  0.000000           33           763         0  \n",
      "4  0.001495           33           763         0  \n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ì— ë“¤ì–´ê°ˆ ìµœì¢… ì»¬ëŸ¼ ì„ ì •\n",
    "\n",
    "\"\"\"\n",
    "tech_mismatch: ì‘ì„±ìë‹˜ì´ ì œê±°í•˜ë ¤ í–ˆë˜ use_chipê³¼ has_chipì„ ì‚´ë ¤ì„œ **\"ICì¹´ë“œì¸ë° ë§ˆê·¸ë„¤í‹±ìœ¼ë¡œ ê¸ì—ˆë‹¤\"**ëŠ” ê°•ë ¥í•œ ì‚¬ê¸° ì •í™©ì„ ì¡ì•„ëƒˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "mcc_risk, zip_risk: ìˆ˜ë°± ê°œì˜ ì¹´í…Œê³ ë¦¬ë¥¼ One-Hot Encoding í•˜ë©´ ì°¨ì›ì´ í­ë°œí•˜ì§€ë§Œ, \"ì‚¬ê¸° í™•ë¥ (Risk Score)\" í•˜ë‚˜ë¡œ ì••ì¶•í•˜ë©´ ì°¨ì›ì€ 1ê°œë¡œ ì¤„ë©´ì„œ ì •ë³´ëŸ‰ì€ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤. (íŠ¸ë¦¬ ëª¨ë¸ì´ ì•„ì£¼ ì¢‹ì•„í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.)\n",
    "\n",
    "utilization_ratio: ë‹¨ìˆœíˆ \"500ë¶ˆ ì¼ë‹¤\"ë³´ë‹¤ \"í•œë„ 500ë¶ˆì¸ë° 500ë¶ˆ ì¼ë‹¤(í•œë„ ì´ˆê³¼ ì„ë°•)\"ê°€ ì‚¬ê¸°ê¾¼ì˜ í–‰ë™ íŒ¨í„´(Bust-out Fraud)ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "zipì˜ ë¶€í™œ: ìœ„ë„/ê²½ë„ê°€ ì—†ì–´ì„œ ê±°ë¦¬ë¥¼ ëª» êµ¬í•œë‹¤ë©´, ìµœì†Œí•œ **\"ì´ ìš°í¸ë²ˆí˜¸(ë™ë„¤)ì—ì„œ ì‚¬ê³ ê°€ ë§ì´ ë‚¬ë‚˜?\"**ë¼ë„ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤. zip_riskê°€ ê·¸ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "features = [\n",
    "    # 1. í•µì‹¬ ìˆ˜ì¹˜\n",
    "    'amount', \n",
    "    'utilization_ratio',      # í•œë„ ëŒ€ë¹„ ê¸ˆì•¡\n",
    "    'amount_income_ratio',    # ì†Œë“ ëŒ€ë¹„ ê¸ˆì•¡\n",
    "    \n",
    "    # 2. ê¸°ìˆ ì /íŒ¨í„´ ë§¥ë½\n",
    "    'tech_mismatch',          # ì¹© ì¹´ë“œì¸ë° ê¸ì—ˆëŠ”ì§€\n",
    "    'pin_years_gap',          # ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ì˜¤ë˜ëëŠ”ì§€\n",
    "    'num_credit_cards',       # ì¹´ë“œ ê°œìˆ˜ (ë‹¤ì¤‘ ë°œê¸‰ ì‚¬ê¸° ì—°ê´€)\n",
    "    \n",
    "    # 3. ì‹œê°„ ë§¥ë½\n",
    "    'hour',\n",
    "    'is_night',\n",
    "    \n",
    "    # 4. ìœ„ì¹˜/ì—…ì¢… ë§¥ë½ (Risk Scoreë¡œ ë³€í™˜ë¨)\n",
    "    'mcc_risk',               # ì—…ì¢… ìœ„í—˜ë„\n",
    "    'state_risk',             # ì£¼(State) ìœ„í—˜ë„\n",
    "    'zip_risk',               # ì§€ì—­(Zip) ìœ„í—˜ë„\n",
    "    \n",
    "    # 5. ì‚¬ìš©ì ì •ë³´ (ë³´ì¡°)\n",
    "    'current_age',\n",
    "    'credit_score',           # ì‹ ìš©ì ìˆ˜ ë‚®ìœ¼ë©´ ìœ„í—˜í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "    # 6. íƒ€ê²Ÿ (ì •ë‹µ)\n",
    "    'is_fraud'\n",
    "]\n",
    "\n",
    "df_final = df[features].copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ìµœì¢… í™•ì¸ (Target Encoding ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆìŒ)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "print(f\"ğŸš€ Final Dataset Shape: {df_final.shape}\")\n",
    "print(df_final.head())\n",
    "\n",
    "# ì €ì¥ (ì„ íƒ)\n",
    "# df_final.to_csv('processed_fraud_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d5b216",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 5\n",
    "\n",
    "í•™ìŠµ 4ì˜ ì¡°ê±´ì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ë˜, 2ì°¨ ì •ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.900, precision = 0.7177, recall = 0.5277, TP = 1457, FP = 573\n",
    "\n",
    "threshold = 0.950, precision = 0.8810, recall = 0.3325, TP = 918, FP = 124\n",
    "\n",
    "threshold = 0.995, precision = 1.0000, recall = 0.0101, TP = 28, FP = 0\n",
    "\n",
    "ì „ì²´ì ì¸ íƒì§€ì„±ëŠ¥ì´ ë¹„ì•½ì ìœ¼ë¡œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b2737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… inf/nan values fixed.\n",
      "Resampled Train shape: (121462, 13)\n",
      "Resampled Fraud ratio: 0.0909\n",
      "ğŸš€ ìŠ¤ë‚˜ì´í¼ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "\n",
      "=== ğŸ¯ Threshold Tuning for Precision >= 0.99 ===\n",
      "Threshold  | Precision  | Recall     | FP Count   | TP Count  \n",
      "------------------------------------------------------------\n",
      "0.500      | 0.1193     | 0.9265     | 18886      | 2558      \n",
      "0.550      | 0.1415     | 0.9022     | 15117      | 2491      \n",
      "0.600      | 0.1754     | 0.8703     | 11294      | 2403      \n",
      "0.650      | 0.2285     | 0.8385     | 7816       | 2315      \n",
      "0.700      | 0.3096     | 0.8066     | 4967       | 2227      \n",
      "0.750      | 0.4006     | 0.7733     | 3195       | 2135      \n",
      "0.800      | 0.5012     | 0.7280     | 2000       | 2010      \n",
      "0.850      | 0.6139     | 0.6537     | 1135       | 1805      \n",
      "0.900      | 0.7177     | 0.5277     | 573        | 1457      \n",
      "0.950      | 0.8810     | 0.3325     | 124        | 918       \n",
      "0.950      | 0.8810     | 0.3325     | 124        | 918       \n",
      "0.960      | 0.9140     | 0.2811     | 73         | 776       \n",
      "0.970      | 0.9251     | 0.2014     | 45         | 556       \n",
      "0.980      | 0.9485     | 0.1134     | 17         | 313       \n",
      "0.990      | 0.9898     | 0.0351     | 1          | 97        \n",
      "0.995      | 1.0000     | 0.0101     | 0          | 28        \n",
      "0.999      | 1.0000     | 0.0004     | 0          | 1         \n",
      "------------------------------------------------------------\n",
      "\n",
      "âœ… ëª©í‘œ ë‹¬ì„±! ì¶”ì²œ Threshold: 0.995\n",
      "\n",
      "=== Final Report (Threshold: 0.995) ===\n",
      "[[1827547       0]\n",
      " [   2733      28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1827547\n",
      "           1       1.00      0.01      0.02      2761\n",
      "\n",
      "    accuracy                           1.00   1830308\n",
      "   macro avg       1.00      0.51      0.51   1830308\n",
      "weighted avg       1.00      1.00      1.00   1830308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# [Bug Fix] ë¬´í•œëŒ€(inf) ê°’ ì²˜ë¦¬\n",
    "# credit_limitê°€ 0ì¸ ê²½ìš° ë°œìƒí•œ infë¥¼ NaNìœ¼ë¡œ ë³€í™˜í•˜ì—¬ XGBoostê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•¨\n",
    "df_final = df_final.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# í˜¹ì‹œ NaNì´ ìƒê²¼ë‹¤ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (ì„ íƒì‚¬í•­, XGBoostëŠ” NaNë„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë‚˜ 0ì´ ì•ˆì „í•¨)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "print(\"âœ… inf/nan values fixed.\")\n",
    "\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. ë³´ìˆ˜ì ì¸ ìƒ˜í”Œë§ (Undersampling Only)\n",
    "# -----------------------------------------------------------\n",
    "# ì •ìƒ:ì‚¬ê¸° ë¹„ìœ¨ì„ 10:1 (0.1) ì •ë„ë¡œ ë§ì¶¥ë‹ˆë‹¤.\n",
    "# ì •ìƒì„ ë„ˆë¬´ ë§ì´ ë²„ë¦¬ë©´ \"ì •ìƒ íŒ¨í„´\"ì„ í•™ìŠµ ëª»í•´ì„œ ì˜¤íƒ(FP)ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\n",
    "# 10:1 ì •ë„ë©´ ëª¨ë¸ì´ \"ì•„, ì •ìƒì´ í›¨ì”¬ ë§êµ¬ë‚˜\"ë¼ê³  ì¸ì§€í•˜ì—¬ ë³´ìˆ˜ì ìœ¼ë¡œ ë³€í•©ë‹ˆë‹¤.\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Resampled Train shape: {X_resampled.shape}\")\n",
    "print(f\"Resampled Fraud ratio: {y_resampled.mean():.4f}\") # ì•½ 0.09 (9%)\n",
    "\n",
    "# 3. ëª¨ë¸ ì •ì˜ (ê°€ì¤‘ì¹˜ ì œê±° & ë³´ìˆ˜ì  ì„¤ì •)\n",
    "# -----------------------------------------------------------\n",
    "# (1) XGBoost: scale_pos_weight ì œê±° (ê¸°ë³¸ê°’ 1)\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,        # ê¹Šì´ë¥¼ ì¤„ì—¬ì„œ ê³¼ì í•© ë°©ì§€\n",
    "    scale_pos_weight=1, # [í•µì‹¬] ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì§€ ì•ŠìŒ -> Precision ì¤‘ì‹œ\n",
    "    eval_metric='auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# (2) Random Forest: Precision í™•ë³´ì— ìœ ë¦¬\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=12,       # ë„ˆë¬´ ê¹Šì§€ ì•Šê²Œ\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. ì•™ìƒë¸” í•™ìŠµ\n",
    "# -----------------------------------------------------------\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf', rf_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ ìŠ¤ë‚˜ì´í¼ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "voting_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 5. ìµœì ì˜ Threshold íƒìƒ‰\n",
    "# -----------------------------------------------------------\n",
    "# ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ í™•ë¥  ì˜ˆì¸¡\n",
    "y_prob = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Threshold Tuning for Precision >= 0.99 ===\")\n",
    "print(f\"{'Threshold':<10} | {'Precision':<10} | {'Recall':<10} | {'FP Count':<10} | {'TP Count':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_th = 0.5\n",
    "found = False\n",
    "\n",
    "# 0.5ë¶€í„° 0.999ê¹Œì§€ ì´˜ì´˜í•˜ê²Œ ê²€ì‚¬\n",
    "thresholds = np.arange(0.5, 1.0, 0.05).tolist() + [0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.999]\n",
    "thresholds = sorted(list(set(thresholds)))\n",
    "\n",
    "for th in thresholds:\n",
    "    y_pred_th = (y_prob >= th).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_th).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"{th:<10.3f} | {precision:<10.4f} | {recall:<10.4f} | {fp:<10} | {tp:<10}\")\n",
    "    \n",
    "    # ëª©í‘œ ë‹¬ì„± ì¡°ê±´ í™•ì¸ (Precision >= 0.99 ì´ë©´ì„œ Recallì´ 0ì´ ì•„ë‹Œ ê²½ìš°)\n",
    "    if precision >= 0.99 and recall > 0.0:\n",
    "        if not found: # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì²« ë²ˆì§¸(ê°€ì¥ ë‚®ì€) Threshold ì €ì¥\n",
    "            best_th = th\n",
    "            found = True\n",
    "        # ë” ë†’ì€ Recallì„ ì°¾ê¸° ìœ„í•´ best_thë¥¼ ê³„ì† ê°±ì‹ í•  ìˆ˜ë„ ìˆìŒ (ì—¬ê¸°ì„œëŠ” ì²« ë‹¬ì„± ì§€ì  ê¸°ì¤€)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if found:\n",
    "    print(f\"\\nâœ… ëª©í‘œ ë‹¬ì„±! ì¶”ì²œ Threshold: {best_th}\")\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "    final_pred = (y_prob >= best_th).astype(int)\n",
    "    print(f\"\\n=== Final Report (Threshold: {best_th}) ===\")\n",
    "    print(confusion_matrix(y_test, final_pred))\n",
    "    print(classification_report(y_test, final_pred))\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Precision 0.99ë¥¼ ë‹¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ê°•ë ¥í•œ Featureê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c11064",
   "metadata": {},
   "source": [
    "# 3ì°¨ ë°ì´í„° ì •ì œ\n",
    "\n",
    "2ì°¨ ì •ì œ ë°ì´í„°ì˜ íš¨ê³¼ê°€ ì¢‹ì•˜ìœ¼ë¯€ë¡œ \"ë§¥ë½\"ì— ê´€ë ¨ëœ ì •ë³´ë¥¼ ë” ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹íˆ ê¸°ì¡´ì—” ë„£ì§€ ì•Šì€ \"ì‹œê°„\"ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "'time_diff_seconds', # ì§ì „ ê±°ë˜ì™€ì˜ ì‹œê°„(ì´ˆ) ì°¨ì´\n",
    "\n",
    "'count_24h', # ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ ê±°ë˜ íšŸìˆ˜\n",
    "\n",
    "'sum_amt_1h', # ì§€ë‚œ 1ì‹œê°„ ë™ì•ˆ ê²°ì œ ê¸ˆì•¡ í•©ê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95933c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Generating Velocity Features...\n",
      "âœ… Velocity Features Generated\n"
     ]
    }
   ],
   "source": [
    "# ì‹œê°„ë²¡í„° ìƒì„±\n",
    "# df_finalì„ ë§Œë“¤ê¸° ì „, ê¸°ì´ˆ ì •ì œê°€ ëë‚œ df ìƒíƒœì—ì„œ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# (Users, Cardsê°€ ë³‘í•©ë˜ê³ , dateê°€ datetimeìœ¼ë¡œ ë³€í™˜ëœ ìƒíƒœ)\n",
    "\n",
    "print(\"â³ Generating Velocity Features...\")\n",
    "\n",
    "# 1. ì •ë ¬ (Userë³„, ì‹œê°„ìˆœ)\n",
    "# ì‹œê°„ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ë ¤ë©´ ë°˜ë“œì‹œ ì •ë ¬ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "df['date_obj'] = pd.to_datetime(df['date']) # ë§Œì•½ ì•ˆ ë˜ì–´ ìˆë‹¤ë©´\n",
    "df = df.sort_values(['client_id', 'date_obj'])\n",
    "\n",
    "# 2. [í•µì‹¬ 1] ì§ì „ ê±°ë˜ì™€ì˜ ì‹œê°„ ì°¨ì´ (Time Since Last Transaction)\n",
    "# ì‚¬ê¸°ê¾¼ì€ ì§§ì€ ì‹œê°„ì— ì—¬ëŸ¬ ë²ˆ ê¸ìŠµë‹ˆë‹¤.\n",
    "# client_idë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ diff ê³„ì‚° (ì´ˆ ë‹¨ìœ„)\n",
    "df['time_diff_seconds'] = df.groupby('client_id')['date_obj'].diff().dt.total_seconds()\n",
    "df['time_diff_seconds'] = df['time_diff_seconds'].fillna(999999) # ì²« ê±°ë˜ëŠ” í° ê°’ìœ¼ë¡œ\n",
    "\n",
    "# 3. [í•µì‹¬ 2] ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ ê±°ë˜ íšŸìˆ˜ (Velocity Count)\n",
    "# \"ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ 100ë²ˆ ê¸ì—ˆë‹¤\" -> ì‚¬ê¸°ì¼ í™•ë¥  ë§¤ìš° ë†’ìŒ\n",
    "# set_index í›„ rollingì„ ì“°ë©´ ë¹ ë¦…ë‹ˆë‹¤.\n",
    "df_sorted = df.set_index('date_obj').sort_index()\n",
    "# client_idë³„ë¡œ 24ì‹œê°„ window count\n",
    "# (ë°ì´í„°ê°€ ì»¤ì„œ ì˜¤ë˜ ê±¸ë¦¬ë©´ 1ì‹œê°„(1h)ìœ¼ë¡œ ì¤„ì—¬ë„ ì¢‹ìŠµë‹ˆë‹¤)\n",
    "count_24h = df_sorted.groupby('client_id')['amount'].rolling('24h').count()\n",
    "\n",
    "# ì¸ë±ìŠ¤ ë¦¬ì…‹ í›„ ì›ë³¸ì— ë³‘í•©í•˜ê¸° ìœ„í•´ ì •ë¦¬\n",
    "count_24h = count_24h.reset_index()\n",
    "# ì»¬ëŸ¼ëª… ì •ë¦¬ (client_id, date_obj, amount -> count_24h)\n",
    "count_24h.columns = ['client_id', 'date_obj', 'count_24h']\n",
    "\n",
    "# ì›ë³¸ dfì— ë³‘í•© (Key: client_id, date_obj)\n",
    "# ì£¼ì˜: ì¤‘ë³µ timestampê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‹ˆ drop_duplicates ê³ ë ¤\n",
    "df = pd.merge(df, count_24h, on=['client_id', 'date_obj'], how='left')\n",
    "\n",
    "# 4. [í•µì‹¬ 3] ì§€ë‚œ 1ì‹œê°„ ë™ì•ˆ ê²°ì œ ê¸ˆì•¡ í•©ê³„ (Velocity Amount)\n",
    "# \"í‰ì†Œ 100ë¶ˆ ì“°ëŠ”ë° ì§€ë‚œ 1ì‹œê°„ ë™ì•ˆ 5000ë¶ˆ ì¼ë‹¤\"\n",
    "amt_1h = df_sorted.groupby('client_id')['amount'].rolling('1h').sum()\n",
    "amt_1h = amt_1h.reset_index()\n",
    "amt_1h.columns = ['client_id', 'date_obj', 'sum_amt_1h']\n",
    "\n",
    "df = pd.merge(df, amt_1h, on=['client_id', 'date_obj'], how='left')\n",
    "\n",
    "# 5. ê¸°ì¡´ íŒŒìƒë³€ìˆ˜ì™€ ê²°í•©\n",
    "# ì´ì „ì— ë§Œë“  tech_mismatch, utilization_ratio ë“±ë„ ë‹¹ì—°íˆ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "print(\"âœ… Velocity Features Generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f948d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Final Dataset Shape: (9151537, 17)\n",
      "   amount  utilization_ratio  amount_income_ratio  tech_mismatch  \\\n",
      "0   33.96           0.001930             0.000570              1   \n",
      "1    7.78           0.000442             0.000131              1   \n",
      "2   65.86           0.003742             0.001105              1   \n",
      "3    1.37           0.000078             0.000023              1   \n",
      "4  167.62           0.009524             0.002812              0   \n",
      "\n",
      "   pin_years_gap  num_credit_cards  hour  is_night  mcc_risk  state_risk  \\\n",
      "0              5                 4    13         0  0.000270    0.000035   \n",
      "1              5                 4    19         0  0.000181    0.000035   \n",
      "2              5                 4    22         0  0.000817    0.000035   \n",
      "3              5                 4    15         0  0.000134    0.000035   \n",
      "4              5                 4     8         0  0.001108    0.008378   \n",
      "\n",
      "   zip_risk  current_age  credit_score  time_diff_seconds  count_24h  \\\n",
      "0  0.000000           33           763           999999.0        1.0   \n",
      "1  0.000000           33           763            23340.0        2.0   \n",
      "2  0.000000           33           763             9240.0        3.0   \n",
      "3  0.000000           33           763           149460.0        1.0   \n",
      "4  0.001495           33           763            61500.0        2.0   \n",
      "\n",
      "   sum_amt_1h  is_fraud  \n",
      "0       33.96         0  \n",
      "1        7.78         0  \n",
      "2       65.86         0  \n",
      "3        1.37         0  \n",
      "4      167.62         0  \n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ì— ë“¤ì–´ê°ˆ ìµœì¢… ì»¬ëŸ¼ ì„ ì •\n",
    "\n",
    "\"\"\"\n",
    "tech_mismatch: ì‘ì„±ìë‹˜ì´ ì œê±°í•˜ë ¤ í–ˆë˜ use_chipê³¼ has_chipì„ ì‚´ë ¤ì„œ **\"ICì¹´ë“œì¸ë° ë§ˆê·¸ë„¤í‹±ìœ¼ë¡œ ê¸ì—ˆë‹¤\"**ëŠ” ê°•ë ¥í•œ ì‚¬ê¸° ì •í™©ì„ ì¡ì•„ëƒˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "mcc_risk, zip_risk: ìˆ˜ë°± ê°œì˜ ì¹´í…Œê³ ë¦¬ë¥¼ One-Hot Encoding í•˜ë©´ ì°¨ì›ì´ í­ë°œí•˜ì§€ë§Œ, \"ì‚¬ê¸° í™•ë¥ (Risk Score)\" í•˜ë‚˜ë¡œ ì••ì¶•í•˜ë©´ ì°¨ì›ì€ 1ê°œë¡œ ì¤„ë©´ì„œ ì •ë³´ëŸ‰ì€ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤. (íŠ¸ë¦¬ ëª¨ë¸ì´ ì•„ì£¼ ì¢‹ì•„í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.)\n",
    "\n",
    "utilization_ratio: ë‹¨ìˆœíˆ \"500ë¶ˆ ì¼ë‹¤\"ë³´ë‹¤ \"í•œë„ 500ë¶ˆì¸ë° 500ë¶ˆ ì¼ë‹¤(í•œë„ ì´ˆê³¼ ì„ë°•)\"ê°€ ì‚¬ê¸°ê¾¼ì˜ í–‰ë™ íŒ¨í„´(Bust-out Fraud)ì— ë” ê°€ê¹ìŠµë‹ˆë‹¤.\n",
    "\n",
    "zipì˜ ë¶€í™œ: ìœ„ë„/ê²½ë„ê°€ ì—†ì–´ì„œ ê±°ë¦¬ë¥¼ ëª» êµ¬í•œë‹¤ë©´, ìµœì†Œí•œ **\"ì´ ìš°í¸ë²ˆí˜¸(ë™ë„¤)ì—ì„œ ì‚¬ê³ ê°€ ë§ì´ ë‚¬ë‚˜?\"**ë¼ë„ íŒŒì•…í•´ì•¼ í•©ë‹ˆë‹¤. zip_riskê°€ ê·¸ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "features = [\n",
    "    # 1. í•µì‹¬ ìˆ˜ì¹˜\n",
    "    'amount', \n",
    "    'utilization_ratio',      # í•œë„ ëŒ€ë¹„ ê¸ˆì•¡\n",
    "    'amount_income_ratio',    # ì†Œë“ ëŒ€ë¹„ ê¸ˆì•¡\n",
    "    \n",
    "    # 2. ê¸°ìˆ ì /íŒ¨í„´ ë§¥ë½\n",
    "    'tech_mismatch',          # ì¹© ì¹´ë“œì¸ë° ê¸ì—ˆëŠ”ì§€\n",
    "    'pin_years_gap',          # ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ì˜¤ë˜ëëŠ”ì§€\n",
    "    'num_credit_cards',       # ì¹´ë“œ ê°œìˆ˜ (ë‹¤ì¤‘ ë°œê¸‰ ì‚¬ê¸° ì—°ê´€)\n",
    "    \n",
    "    # 3. ì‹œê°„ ë§¥ë½\n",
    "    'hour',\n",
    "    'is_night',\n",
    "    \n",
    "    # 4. ìœ„ì¹˜/ì—…ì¢… ë§¥ë½ (Risk Scoreë¡œ ë³€í™˜ë¨)\n",
    "    'mcc_risk',               # ì—…ì¢… ìœ„í—˜ë„\n",
    "    'state_risk',             # ì£¼(State) ìœ„í—˜ë„\n",
    "    'zip_risk',               # ì§€ì—­(Zip) ìœ„í—˜ë„\n",
    "    \n",
    "    # 5. ì‚¬ìš©ì ì •ë³´ (ë³´ì¡°)\n",
    "    'current_age',\n",
    "    'credit_score',           # ì‹ ìš©ì ìˆ˜ ë‚®ìœ¼ë©´ ìœ„í—˜í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "    # 6. ì‹œê°„ë²¡í„°\n",
    "    'time_diff_seconds',\n",
    "    'count_24h',\n",
    "    'sum_amt_1h',\n",
    "\n",
    "    # 7. íƒ€ê²Ÿ (ì •ë‹µ)\n",
    "    'is_fraud'\n",
    "]\n",
    "\n",
    "df_final = df[features].copy()\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ìµœì¢… í™•ì¸ (Target Encoding ê³¼ì •ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆìŒ)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "print(f\"ğŸš€ Final Dataset Shape: {df_final.shape}\")\n",
    "print(df_final.head())\n",
    "\n",
    "# ì €ì¥ (ì„ íƒ)\n",
    "# df_final.to_csv('processed_fraud_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4a4e4",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 6\n",
    "\n",
    "í•™ìŠµ 4, í•™ìŠµ 5ì™€ ë™ì¼í•˜ë˜, 3ì°¨ ì •ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.900, precision = 0.7432, recall = 0.5683, FP = 542, TP = 1569\n",
    "\n",
    "threshold = 0.950, precision = 0.8619, recall = 0.3865, FP = 171, TP = 1067\n",
    "\n",
    "threshold = 0.995, precision = 1.0000, recall = 0.0076, FP = 0, TP = 21\n",
    "\n",
    "ì‹œê°„ë²¡í„° ì ìš© í›„ 0.900, 0.950 ì„ê³„ê°’ì—ì„œ íŒë³„ë ¥ì´ ë”ìš± í–¥ìƒ ë˜ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc9ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… inf/nan values fixed.\n",
      "Resampled Train shape: (121462, 16)\n",
      "Resampled Fraud ratio: 0.0909\n",
      "ğŸš€ ìŠ¤ë‚˜ì´í¼ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "\n",
      "=== ğŸ¯ Threshold Tuning for Precision >= 0.99 ===\n",
      "Threshold  | Precision  | Recall     | FP Count   | TP Count  \n",
      "------------------------------------------------------------\n",
      "0.500      | 0.1377     | 0.9236     | 15969      | 2550      \n",
      "0.550      | 0.1611     | 0.9091     | 13071      | 2510      \n",
      "0.600      | 0.1896     | 0.8924     | 10535      | 2464      \n",
      "0.650      | 0.2268     | 0.8674     | 8163       | 2395      \n",
      "0.700      | 0.2786     | 0.8359     | 5975       | 2308      \n",
      "0.750      | 0.3545     | 0.8001     | 4022       | 2209      \n",
      "0.800      | 0.4622     | 0.7523     | 2417       | 2077      \n",
      "0.850      | 0.6032     | 0.6827     | 1240       | 1885      \n",
      "0.900      | 0.7432     | 0.5683     | 542        | 1569      \n",
      "0.950      | 0.8619     | 0.3865     | 171        | 1067      \n",
      "0.950      | 0.8619     | 0.3865     | 171        | 1067      \n",
      "0.960      | 0.8834     | 0.3321     | 121        | 917       \n",
      "0.970      | 0.9043     | 0.2463     | 72         | 680       \n",
      "0.980      | 0.9224     | 0.1463     | 34         | 404       \n",
      "0.990      | 0.9500     | 0.0344     | 5          | 95        \n",
      "0.995      | 1.0000     | 0.0076     | 0          | 21        \n",
      "0.999      | 0.0000     | 0.0000     | 0          | 0         \n",
      "------------------------------------------------------------\n",
      "\n",
      "âœ… ëª©í‘œ ë‹¬ì„±! ì¶”ì²œ Threshold: 0.995\n",
      "\n",
      "=== Final Report (Threshold: 0.995) ===\n",
      "[[1827547       0]\n",
      " [   2740      21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1827547\n",
      "           1       1.00      0.01      0.02      2761\n",
      "\n",
      "    accuracy                           1.00   1830308\n",
      "   macro avg       1.00      0.50      0.51   1830308\n",
      "weighted avg       1.00      1.00      1.00   1830308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# [Bug Fix] ë¬´í•œëŒ€(inf) ê°’ ì²˜ë¦¬\n",
    "# credit_limitê°€ 0ì¸ ê²½ìš° ë°œìƒí•œ infë¥¼ NaNìœ¼ë¡œ ë³€í™˜í•˜ì—¬ XGBoostê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•¨\n",
    "df_final = df_final.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# í˜¹ì‹œ NaNì´ ìƒê²¼ë‹¤ë©´ 0ìœ¼ë¡œ ì±„ìš°ê¸° (ì„ íƒì‚¬í•­, XGBoostëŠ” NaNë„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë‚˜ 0ì´ ì•ˆì „í•¨)\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "print(\"âœ… inf/nan values fixed.\")\n",
    "\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 2. ë³´ìˆ˜ì ì¸ ìƒ˜í”Œë§ (Undersampling Only)\n",
    "# -----------------------------------------------------------\n",
    "# ì •ìƒ:ì‚¬ê¸° ë¹„ìœ¨ì„ 10:1 (0.1) ì •ë„ë¡œ ë§ì¶¥ë‹ˆë‹¤.\n",
    "# ì •ìƒì„ ë„ˆë¬´ ë§ì´ ë²„ë¦¬ë©´ \"ì •ìƒ íŒ¨í„´\"ì„ í•™ìŠµ ëª»í•´ì„œ ì˜¤íƒ(FP)ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.\n",
    "# 10:1 ì •ë„ë©´ ëª¨ë¸ì´ \"ì•„, ì •ìƒì´ í›¨ì”¬ ë§êµ¬ë‚˜\"ë¼ê³  ì¸ì§€í•˜ì—¬ ë³´ìˆ˜ì ìœ¼ë¡œ ë³€í•©ë‹ˆë‹¤.\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Resampled Train shape: {X_resampled.shape}\")\n",
    "print(f\"Resampled Fraud ratio: {y_resampled.mean():.4f}\") # ì•½ 0.09 (9%)\n",
    "\n",
    "# 3. ëª¨ë¸ ì •ì˜ (ê°€ì¤‘ì¹˜ ì œê±° & ë³´ìˆ˜ì  ì„¤ì •)\n",
    "# -----------------------------------------------------------\n",
    "# (1) XGBoost: scale_pos_weight ì œê±° (ê¸°ë³¸ê°’ 1)\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,        # ê¹Šì´ë¥¼ ì¤„ì—¬ì„œ ê³¼ì í•© ë°©ì§€\n",
    "    scale_pos_weight=1, # [í•µì‹¬] ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì§€ ì•ŠìŒ -> Precision ì¤‘ì‹œ\n",
    "    eval_metric='auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# (2) Random Forest: Precision í™•ë³´ì— ìœ ë¦¬\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=12,       # ë„ˆë¬´ ê¹Šì§€ ì•Šê²Œ\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. ì•™ìƒë¸” í•™ìŠµ\n",
    "# -----------------------------------------------------------\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('xgb', xgb_clf), ('rf', rf_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(\"ğŸš€ ìŠ¤ë‚˜ì´í¼ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "voting_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 5. ìµœì ì˜ Threshold íƒìƒ‰\n",
    "# -----------------------------------------------------------\n",
    "# ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ í™•ë¥  ì˜ˆì¸¡\n",
    "y_prob = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Threshold Tuning for Precision >= 0.99 ===\")\n",
    "print(f\"{'Threshold':<10} | {'Precision':<10} | {'Recall':<10} | {'FP Count':<10} | {'TP Count':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_th = 0.5\n",
    "found = False\n",
    "\n",
    "# 0.5ë¶€í„° 0.999ê¹Œì§€ ì´˜ì´˜í•˜ê²Œ ê²€ì‚¬\n",
    "thresholds = np.arange(0.5, 1.0, 0.05).tolist() + [0.95, 0.96, 0.97, 0.98, 0.99, 0.995, 0.999]\n",
    "thresholds = sorted(list(set(thresholds)))\n",
    "\n",
    "for th in thresholds:\n",
    "    y_pred_th = (y_prob >= th).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_th).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    print(f\"{th:<10.3f} | {precision:<10.4f} | {recall:<10.4f} | {fp:<10} | {tp:<10}\")\n",
    "    \n",
    "    # ëª©í‘œ ë‹¬ì„± ì¡°ê±´ í™•ì¸ (Precision >= 0.99 ì´ë©´ì„œ Recallì´ 0ì´ ì•„ë‹Œ ê²½ìš°)\n",
    "    if precision >= 0.99 and recall > 0.0:\n",
    "        if not found: # ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì²« ë²ˆì§¸(ê°€ì¥ ë‚®ì€) Threshold ì €ì¥\n",
    "            best_th = th\n",
    "            found = True\n",
    "        # ë” ë†’ì€ Recallì„ ì°¾ê¸° ìœ„í•´ best_thë¥¼ ê³„ì† ê°±ì‹ í•  ìˆ˜ë„ ìˆìŒ (ì—¬ê¸°ì„œëŠ” ì²« ë‹¬ì„± ì§€ì  ê¸°ì¤€)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if found:\n",
    "    print(f\"\\nâœ… ëª©í‘œ ë‹¬ì„±! ì¶”ì²œ Threshold: {best_th}\")\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ ì¶œë ¥\n",
    "    final_pred = (y_prob >= best_th).astype(int)\n",
    "    print(f\"\\n=== Final Report (Threshold: {best_th}) ===\")\n",
    "    print(confusion_matrix(y_test, final_pred))\n",
    "    print(classification_report(y_test, final_pred))\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Precision 0.99ë¥¼ ë‹¬ì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” ê°•ë ¥í•œ Featureê°€ í•„ìš”í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec328b7b",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 7\n",
    "\n",
    "3ì°¨ ì •ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ XGBoost ë°˜ë³µí•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "threshold = 0.995, 0.990ì— ëŒ€í•˜ì—¬ í•œì •í•˜ê³  Precisionê³¼ Recallì´ ìµœê³ ë¡œ ì˜ ë‚˜ì˜¤ëŠ” ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.995, max_depth = 5, learning_rate = 0.05, n_estimators = 200\n",
    "\n",
    "-> Precision = 0.9207, Recall = 0.0967, TP = 267, FP = 23\n",
    "\n",
    "threshold = 0.990, max_depth = 5, learning_rate = 0.05, n_estimators = 200\n",
    "\n",
    "-> Precision = 0.9030, Recall = 0.2763, TP = 763, FP = 82\n",
    "\n",
    "Precisionì´ 1ì— ê·¼ì ‘í•˜ì§€ ì•Šì•„ XGBoostëŠ” ê³ ì„ê³„ì  í™œìš©ì—” ì–´ë µë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74ad06de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Ready. Train: (121462, 16), Test: (1830308, 16)\n",
      "ğŸš€ ì´ 28ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\n",
      "[1/28] Testing: {'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[2/28] Testing: {'max_depth': 5, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[3/28] Testing: {'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[4/28] Testing: {'max_depth': 5, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "[5/28] Testing: {'max_depth': 6, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[6/28] Testing: {'max_depth': 6, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[7/28] Testing: {'max_depth': 6, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[8/28] Testing: {'max_depth': 6, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "[9/28] Testing: {'max_depth': 7, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[10/28] Testing: {'max_depth': 7, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[11/28] Testing: {'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[12/28] Testing: {'max_depth': 7, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "[13/28] Testing: {'max_depth': 8, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[14/28] Testing: {'max_depth': 8, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[15/28] Testing: {'max_depth': 8, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[16/28] Testing: {'max_depth': 8, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "[17/28] Testing: {'max_depth': 9, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[18/28] Testing: {'max_depth': 9, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[19/28] Testing: {'max_depth': 9, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[20/28] Testing: {'max_depth': 9, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "[21/28] Testing: {'max_depth': 10, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[22/28] Testing: {'max_depth': 10, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[23/28] Testing: {'max_depth': 10, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[24/28] Testing: {'max_depth': 10, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "[25/28] Testing: {'max_depth': 15, 'learning_rate': 0.05, 'n_estimators': 200} ... Done.\n",
      "[26/28] Testing: {'max_depth': 15, 'learning_rate': 0.05, 'n_estimators': 300} ... Done.\n",
      "[27/28] Testing: {'max_depth': 15, 'learning_rate': 0.01, 'n_estimators': 200} ... Done.\n",
      "[28/28] Testing: {'max_depth': 15, 'learning_rate': 0.01, 'n_estimators': 300} ... Done.\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5 by Block) ===\n",
      "    max_depth  learning_rate  n_estimators  Block_Prec  Block_Recall  Block_TP  Block_FP  Chal_Prec  Chal_Recall  Chal_TP  Chal_FP\n",
      "0           5           0.05           200      0.9207        0.0967       267        23     0.8979       0.1720      475       54\n",
      "20         10           0.05           200      0.9144        0.2629       726        68     0.8917       0.3995     1103      134\n",
      "4           6           0.05           200      0.9144        0.1315       363        34     0.8944       0.2300      635       75\n",
      "16          9           0.05           200      0.9116        0.2354       650        63     0.8890       0.3481      961      120\n",
      "9           7           0.05           300      0.9115        0.2499       690        67     0.8952       0.3807     1051      123\n",
      "8           7           0.05           200      0.9087        0.1586       438        44     0.9030       0.2763      763       82\n",
      "5           6           0.05           300      0.9062        0.2133       589        61     0.8887       0.3354      926      116\n",
      "21         10           0.05           300      0.9053        0.3807      1051       110     0.8880       0.5226     1443      182\n",
      "1           5           0.05           300      0.9002        0.1666       460        51     0.8952       0.2629      726       85\n",
      "17          9           0.05           300      0.9001        0.3329       919       102     0.8877       0.4640     1281      162\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5 by Chal) ===\n",
      "    max_depth  learning_rate  n_estimators  Block_Prec  Block_Recall  Block_TP  Block_FP  Chal_Prec  Chal_Recall  Chal_TP  Chal_FP\n",
      "8           7           0.05           200      0.9087        0.1586       438        44     0.9030       0.2763      763       82\n",
      "0           5           0.05           200      0.9207        0.0967       267        23     0.8979       0.1720      475       54\n",
      "9           7           0.05           300      0.9115        0.2499       690        67     0.8952       0.3807     1051      123\n",
      "1           5           0.05           300      0.9002        0.1666       460        51     0.8952       0.2629      726       85\n",
      "4           6           0.05           200      0.9144        0.1315       363        34     0.8944       0.2300      635       75\n",
      "20         10           0.05           200      0.9144        0.2629       726        68     0.8917       0.3995     1103      134\n",
      "12          8           0.05           200      0.8973        0.1930       533        61     0.8907       0.3158      872      107\n",
      "16          9           0.05           200      0.9116        0.2354       650        63     0.8890       0.3481      961      120\n",
      "5           6           0.05           300      0.9062        0.2133       589        61     0.8887       0.3354      926      116\n",
      "21         10           0.05           300      0.9053        0.3807      1051       110     0.8880       0.5226     1443      182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. ë°ì´í„° ì¤€ë¹„ (time_diff_secondsê°€ í¬í•¨ëœ df_final ì‚¬ìš© ê°€ì •)\n",
    "# ----------------------------------------------------------------\n",
    "# X, y ì •ì˜\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# Train/Test ë¶„ë¦¬ (Stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Under Sampling (10:1 ë¹„ìœ¨ ìœ ì§€)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Dataset Ready. Train: {X_resampled.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# 2. íŠœë‹í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •\n",
    "# ----------------------------------------------------------------\n",
    "# ê¹Šì´(max_depth)ë¥¼ ëŠ˜ë¦¬ë©´ ë” ë³µì¡í•œ ì‚¬ê¸° íŒ¨í„´(ê´´ë„í•œ ì¡°ê±´)ì„ ì™¸ì›ë‹ˆë‹¤.\n",
    "# í•™ìŠµë¥ (learning_rate)ì„ ì¤„ì´ê³  íŠ¸ë¦¬ë¥¼ ëŠ˜ë¦¬ë©´(n_estimators) ë” ì •êµí•´ì§‘ë‹ˆë‹¤.\n",
    "param_grid = {\n",
    "    'max_depth': [5, 6, 7, 8, 9, 10, 15],          # ê¹Šì´ ë³€í™” (í•µì‹¬)\n",
    "    'learning_rate': [0.05, 0.01],      # ì •ë°€ë„ ë³€í™”\n",
    "    'n_estimators': [200, 300]         # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "}\n",
    "\n",
    "# ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"ğŸš€ ì´ {len(combinations)}ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 3. ì‹¤í—˜ ë° ê²°ê³¼ ê¸°ë¡\n",
    "# ----------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(combinations):\n",
    "    print(f\"[{i+1}/{len(combinations)}] Testing: {params} ...\", end=\" \")\n",
    "    \n",
    "    # ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "    model = XGBClassifier(\n",
    "        **params,\n",
    "        scale_pos_weight=1,   # Sniper ëª¨ë“œ (ê°€ì¤‘ì¹˜ ì—†ìŒ)\n",
    "        eval_metric='auc',\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ìš°ë¦¬ê°€ ê´€ì‹¬ ìˆëŠ” Threshold êµ¬ê°„ë³„ ì„±ê³¼ ì¸¡ì •\n",
    "    # (1) Auto Block êµ¬ê°„ (Threshold 0.99 ì´ìƒ)\n",
    "    th_block = 0.995\n",
    "    y_pred_block = (y_prob >= th_block).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_block).ravel()\n",
    "    prec_block = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec_block = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # (2) Challenge êµ¬ê°„ (Threshold 0.90 ì´ìƒ)\n",
    "    th_chal = 0.990\n",
    "    y_pred_chal = (y_prob >= th_chal).astype(int)\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(y_test, y_pred_chal).ravel()\n",
    "    prec_chal = tp2 / (tp2 + fp2) if (tp2 + fp2) > 0 else 0\n",
    "    rec_chal = tp2 / (tp2 + fn2) if (tp2 + fn2) > 0 else 0\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    res = params.copy()\n",
    "    \n",
    "    # Block Tier ì„±ê³¼\n",
    "    res['Block_Prec'] = round(prec_block, 4)\n",
    "    res['Block_Recall'] = round(rec_block, 4)\n",
    "    res['Block_TP'] = tp  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['Block_FP'] = fp  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    \n",
    "    # Challenge Tier ì„±ê³¼\n",
    "    res['Chal_Prec'] = round(prec_chal, 4)\n",
    "    res['Chal_Recall'] = round(rec_chal, 4)\n",
    "    res['Chal_TP'] = tp2  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['Chal_FP'] = fp2  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    \n",
    "    results.append(res)\n",
    "    print(\"Done.\")\n",
    "\n",
    "# 4. ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥\n",
    "# ----------------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ë³´ê¸° ì¢‹ê²Œ ì •ë ¬: \n",
    "# 1ìˆœìœ„: Block Precisionì´ 0.99 ì´ìƒì¸ ê²ƒ ì¤‘ì—ì„œ\n",
    "# 2ìˆœìœ„: Block Recallì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ\n",
    "results_df = results_df.sort_values(by=['Block_Prec', 'Block_Recall'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5 by Block) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "\n",
    "results_df = results_df.sort_values(by=['Chal_Prec', 'Chal_Recall'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5 by Chal) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "# CSV ì €ì¥ (ì„ íƒ)\n",
    "# results_df.to_csv('sniper_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22346d1c",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 8\n",
    "\n",
    "3ì°¨ ì •ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ RandomForest ë°˜ë³µí•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "threshold = 0.995, 0.990ì— ëŒ€í•˜ì—¬ í•œì •í•˜ê³  Recallì´ ìµœê³ ë¡œ ì˜ ë‚˜ì˜¤ëŠ” ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.995, max_depth = 14, n_estimators = 300\n",
    "\n",
    "-> Precision = 1.0, Recall = 0.00065, TP = 18, FP = 0\n",
    "\n",
    "threshold = 0.990, max_depth = 13, n_estimators = 300\n",
    "\n",
    "-> Precision = 1.0, Recall = 0.0116, TP = 32, FP = 0\n",
    "\n",
    "Recallì„ 1%ê¹Œì§€ ëŒì–´ì˜¬ë ¸ìŠµë‹ˆë‹¤.\n",
    "\n",
    "í•™ìŠµ ê²°ê³¼ë¥¼ ë³´ë‹ˆ ê³ ì„ê³„ì  (ê³ ìœ„í—˜êµ° íƒì§€) ì— ëŒ€í•´ì„œëŠ” RandomForestê°€ XGBoostë³´ë‹¤ ì í•©í•˜ë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì„ê³„ì ì„ ì¢€ ë” ë‚®ì¶”ê³  ê¹Šì´ë²”ìœ„ë¥¼ ë°”ê¿”ì„œ ìµœì ì˜ ëª¨ë¸ì„ íƒìƒ‰í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0c48e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Ready. Train: (121462, 16), Test: (1830308, 16)\n",
      "ğŸš€ ì´ 33ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\n",
      "[1/33] Testing: {'max_depth': 5, 'n_estimators': 100} ... Done.\n",
      "[2/33] Testing: {'max_depth': 5, 'n_estimators': 200} ... Done.\n",
      "[3/33] Testing: {'max_depth': 5, 'n_estimators': 300} ... Done.\n",
      "[4/33] Testing: {'max_depth': 6, 'n_estimators': 100} ... Done.\n",
      "[5/33] Testing: {'max_depth': 6, 'n_estimators': 200} ... Done.\n",
      "[6/33] Testing: {'max_depth': 6, 'n_estimators': 300} ... Done.\n",
      "[7/33] Testing: {'max_depth': 7, 'n_estimators': 100} ... Done.\n",
      "[8/33] Testing: {'max_depth': 7, 'n_estimators': 200} ... Done.\n",
      "[9/33] Testing: {'max_depth': 7, 'n_estimators': 300} ... Done.\n",
      "[10/33] Testing: {'max_depth': 8, 'n_estimators': 100} ... Done.\n",
      "[11/33] Testing: {'max_depth': 8, 'n_estimators': 200} ... Done.\n",
      "[12/33] Testing: {'max_depth': 8, 'n_estimators': 300} ... Done.\n",
      "[13/33] Testing: {'max_depth': 9, 'n_estimators': 100} ... Done.\n",
      "[14/33] Testing: {'max_depth': 9, 'n_estimators': 200} ... Done.\n",
      "[15/33] Testing: {'max_depth': 9, 'n_estimators': 300} ... Done.\n",
      "[16/33] Testing: {'max_depth': 10, 'n_estimators': 100} ... Done.\n",
      "[17/33] Testing: {'max_depth': 10, 'n_estimators': 200} ... Done.\n",
      "[18/33] Testing: {'max_depth': 10, 'n_estimators': 300} ... Done.\n",
      "[19/33] Testing: {'max_depth': 11, 'n_estimators': 100} ... Done.\n",
      "[20/33] Testing: {'max_depth': 11, 'n_estimators': 200} ... Done.\n",
      "[21/33] Testing: {'max_depth': 11, 'n_estimators': 300} ... Done.\n",
      "[22/33] Testing: {'max_depth': 12, 'n_estimators': 100} ... Done.\n",
      "[23/33] Testing: {'max_depth': 12, 'n_estimators': 200} ... Done.\n",
      "[24/33] Testing: {'max_depth': 12, 'n_estimators': 300} ... Done.\n",
      "[25/33] Testing: {'max_depth': 13, 'n_estimators': 100} ... Done.\n",
      "[26/33] Testing: {'max_depth': 13, 'n_estimators': 200} ... Done.\n",
      "[27/33] Testing: {'max_depth': 13, 'n_estimators': 300} ... Done.\n",
      "[28/33] Testing: {'max_depth': 14, 'n_estimators': 100} ... Done.\n",
      "[29/33] Testing: {'max_depth': 14, 'n_estimators': 200} ... Done.\n",
      "[30/33] Testing: {'max_depth': 14, 'n_estimators': 300} ... Done.\n",
      "[31/33] Testing: {'max_depth': 15, 'n_estimators': 100} ... Done.\n",
      "[32/33] Testing: {'max_depth': 15, 'n_estimators': 200} ... Done.\n",
      "[33/33] Testing: {'max_depth': 15, 'n_estimators': 300} ... Done.\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5 by Block) ===\n",
      "    max_depth  n_estimators  Block_Prec  Block_Recall  Block_TP  Block_FP  Chal_Prec  Chal_Recall  Chal_TP  Chal_FP\n",
      "29         14           300         1.0        0.0065        18         0     0.9186       0.0286       79        7\n",
      "25         13           200         1.0        0.0051        14         0     0.9783       0.0163       45        1\n",
      "21         12           100         1.0        0.0040        11         0     0.8889       0.0116       32        4\n",
      "26         13           300         1.0        0.0040        11         0     1.0000       0.0116       32        0\n",
      "18         11           100         1.0        0.0029         8         0     0.9375       0.0054       15        1\n",
      "23         12           300         1.0        0.0018         5         0     1.0000       0.0047       13        0\n",
      "19         11           200         1.0        0.0014         4         0     1.0000       0.0036       10        0\n",
      "22         12           200         1.0        0.0014         4         0     1.0000       0.0054       15        0\n",
      "20         11           300         1.0        0.0011         3         0     1.0000       0.0040       11        0\n",
      "16         10           200         1.0        0.0004         1         0     1.0000       0.0011        3        0\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5 by Chal) ===\n",
      "    max_depth  n_estimators  Block_Prec  Block_Recall  Block_TP  Block_FP  Chal_Prec  Chal_Recall  Chal_TP  Chal_FP\n",
      "26         13           300      1.0000        0.0040        11         0     1.0000       0.0116       32        0\n",
      "22         12           200      1.0000        0.0014         4         0     1.0000       0.0054       15        0\n",
      "23         12           300      1.0000        0.0018         5         0     1.0000       0.0047       13        0\n",
      "20         11           300      1.0000        0.0011         3         0     1.0000       0.0040       11        0\n",
      "19         11           200      1.0000        0.0014         4         0     1.0000       0.0036       10        0\n",
      "16         10           200      1.0000        0.0004         1         0     1.0000       0.0011        3        0\n",
      "15         10           100      0.0000        0.0000         0         0     1.0000       0.0011        3        0\n",
      "17         10           300      0.0000        0.0000         0         0     1.0000       0.0011        3        0\n",
      "25         13           200      1.0000        0.0051        14         0     0.9783       0.0163       45        1\n",
      "24         13           100      0.9464        0.0192        53         3     0.9493       0.0474      131        7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# 1. ë°ì´í„° ì¤€ë¹„ (time_diff_secondsê°€ í¬í•¨ëœ df_final ì‚¬ìš© ê°€ì •)\n",
    "# ----------------------------------------------------------------\n",
    "# X, y ì •ì˜\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# Train/Test ë¶„ë¦¬ (Stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Under Sampling (10:1 ë¹„ìœ¨ ìœ ì§€)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Dataset Ready. Train: {X_resampled.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# 2. íŠœë‹í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •\n",
    "# ----------------------------------------------------------------\n",
    "# ê¹Šì´(max_depth)ë¥¼ ëŠ˜ë¦¬ë©´ ë” ë³µì¡í•œ ì‚¬ê¸° íŒ¨í„´(ê´´ë„í•œ ì¡°ê±´)ì„ ì™¸ì›ë‹ˆë‹¤.\n",
    "# í•™ìŠµë¥ (learning_rate)ì„ ì¤„ì´ê³  íŠ¸ë¦¬ë¥¼ ëŠ˜ë¦¬ë©´(n_estimators) ë” ì •êµí•´ì§‘ë‹ˆë‹¤.\n",
    "param_grid = {\n",
    "    'max_depth': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],          # ê¹Šì´ ë³€í™” (í•µì‹¬)\n",
    "    'n_estimators': [100, 200, 300]         # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "}\n",
    "\n",
    "# ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"ğŸš€ ì´ {len(combinations)}ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 3. ì‹¤í—˜ ë° ê²°ê³¼ ê¸°ë¡\n",
    "# ----------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(combinations):\n",
    "    print(f\"[{i+1}/{len(combinations)}] Testing: {params} ...\", end=\" \")\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ìš°ë¦¬ê°€ ê´€ì‹¬ ìˆëŠ” Threshold êµ¬ê°„ë³„ ì„±ê³¼ ì¸¡ì •\n",
    "    # (1) Auto Block êµ¬ê°„ (Threshold 0.99 ì´ìƒ)\n",
    "    th_block = 0.995\n",
    "    y_pred_block = (y_prob >= th_block).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_block).ravel()\n",
    "    prec_block = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec_block = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # (2) Challenge êµ¬ê°„ (Threshold 0.90 ì´ìƒ)\n",
    "    th_chal = 0.990\n",
    "    y_pred_chal = (y_prob >= th_chal).astype(int)\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(y_test, y_pred_chal).ravel()\n",
    "    prec_chal = tp2 / (tp2 + fp2) if (tp2 + fp2) > 0 else 0\n",
    "    rec_chal = tp2 / (tp2 + fn2) if (tp2 + fn2) > 0 else 0\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    res = params.copy()\n",
    "    \n",
    "    # Block Tier ì„±ê³¼\n",
    "    res['Block_Prec'] = round(prec_block, 4)\n",
    "    res['Block_Recall'] = round(rec_block, 4)\n",
    "    res['Block_TP'] = tp  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['Block_FP'] = fp  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    \n",
    "    # Challenge Tier ì„±ê³¼\n",
    "    res['Chal_Prec'] = round(prec_chal, 4)\n",
    "    res['Chal_Recall'] = round(rec_chal, 4)\n",
    "    res['Chal_TP'] = tp2  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['Chal_FP'] = fp2  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    \n",
    "    results.append(res)\n",
    "    print(\"Done.\")\n",
    "\n",
    "# 4. ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥\n",
    "# ----------------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ë³´ê¸° ì¢‹ê²Œ ì •ë ¬: \n",
    "# 1ìˆœìœ„: Block Precisionì´ 0.99 ì´ìƒì¸ ê²ƒ ì¤‘ì—ì„œ\n",
    "# 2ìˆœìœ„: Block Recallì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ\n",
    "results_df = results_df.sort_values(by=['Block_Prec', 'Block_Recall'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5 by Block) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "\n",
    "results_df = results_df.sort_values(by=['Chal_Prec', 'Chal_Recall'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5 by Chal) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "# CSV ì €ì¥ (ì„ íƒ)\n",
    "# results_df.to_csv('sniper_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d83ae5d",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 9\n",
    "\n",
    "í•™ìŠµ 8ê³¼ ë™ì¼í•œ ì¡°ê±´í•˜ì— ì„ê³„ì ë§Œ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "threshold = 0.985, 0.980ì— ëŒ€í•˜ì—¬ í•œì •í•˜ê³  Recallì´ ìµœê³ ë¡œ ì˜ ë‚˜ì˜¤ëŠ” ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.985, max_depth = 12, n_estimators = 300\n",
    "\n",
    "-> Precision = 1.0, Recall = 0.0159, TP = 44, FP = 0\n",
    "\n",
    "threshold = 0.980, max_depth = 10, n_estimators = 100\n",
    "\n",
    "-> Precision = 1.0, Recall = 0.0141, TP = 39, FP = 0\n",
    "\n",
    "í˜„ì¬ ë°©ë²•ìœ¼ë¡œëŠ” Recallì˜ ë³€í™”ì¶”ì´ë¥¼ ë¶„ì„í•˜ê¸° ì–´ë µë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "threshold ë²”ìœ„ë¥¼ 0.95ê¹Œì§€ ëŒ€í­ ëŠ˜ë¦¬ê³  max_depth ë²”ìœ„ë„ í¬ê²Œ ëŠ˜ë ¤ì„œ ë‹¤ì¤‘ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "963c4796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Ready. Train: (121462, 16), Test: (1830308, 16)\n",
      "ğŸš€ ì´ 30ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\n",
      "[1/30] Testing: {'max_depth': 10, 'n_estimators': 100} ... Done.\n",
      "[2/30] Testing: {'max_depth': 10, 'n_estimators': 200} ... Done.\n",
      "[3/30] Testing: {'max_depth': 10, 'n_estimators': 300} ... Done.\n",
      "[4/30] Testing: {'max_depth': 11, 'n_estimators': 100} ... Done.\n",
      "[5/30] Testing: {'max_depth': 11, 'n_estimators': 200} ... Done.\n",
      "[6/30] Testing: {'max_depth': 11, 'n_estimators': 300} ... Done.\n",
      "[7/30] Testing: {'max_depth': 12, 'n_estimators': 100} ... Done.\n",
      "[8/30] Testing: {'max_depth': 12, 'n_estimators': 200} ... Done.\n",
      "[9/30] Testing: {'max_depth': 12, 'n_estimators': 300} ... Done.\n",
      "[10/30] Testing: {'max_depth': 13, 'n_estimators': 100} ... Done.\n",
      "[11/30] Testing: {'max_depth': 13, 'n_estimators': 200} ... Done.\n",
      "[12/30] Testing: {'max_depth': 13, 'n_estimators': 300} ... Done.\n",
      "[13/30] Testing: {'max_depth': 14, 'n_estimators': 100} ... Done.\n",
      "[14/30] Testing: {'max_depth': 14, 'n_estimators': 200} ... Done.\n",
      "[15/30] Testing: {'max_depth': 14, 'n_estimators': 300} ... Done.\n",
      "[16/30] Testing: {'max_depth': 15, 'n_estimators': 100} ... Done.\n",
      "[17/30] Testing: {'max_depth': 15, 'n_estimators': 200} ... Done.\n",
      "[18/30] Testing: {'max_depth': 15, 'n_estimators': 300} ... Done.\n",
      "[19/30] Testing: {'max_depth': 16, 'n_estimators': 100} ... Done.\n",
      "[20/30] Testing: {'max_depth': 16, 'n_estimators': 200} ... Done.\n",
      "[21/30] Testing: {'max_depth': 16, 'n_estimators': 300} ... Done.\n",
      "[22/30] Testing: {'max_depth': 17, 'n_estimators': 100} ... Done.\n",
      "[23/30] Testing: {'max_depth': 17, 'n_estimators': 200} ... Done.\n",
      "[24/30] Testing: {'max_depth': 17, 'n_estimators': 300} ... Done.\n",
      "[25/30] Testing: {'max_depth': 18, 'n_estimators': 100} ... Done.\n",
      "[26/30] Testing: {'max_depth': 18, 'n_estimators': 200} ... Done.\n",
      "[27/30] Testing: {'max_depth': 18, 'n_estimators': 300} ... Done.\n",
      "[28/30] Testing: {'max_depth': 19, 'n_estimators': 100} ... Done.\n",
      "[29/30] Testing: {'max_depth': 19, 'n_estimators': 200} ... Done.\n",
      "[30/30] Testing: {'max_depth': 19, 'n_estimators': 300} ... Done.\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5 by Block) ===\n",
      "    max_depth  n_estimators  Block_Prec  Block_Recall  Block_TP  Block_FP  Chal_Prec  Chal_Recall  Chal_TP  Chal_FP\n",
      "8          12           300      1.0000        0.0159        44         0     0.9720       0.0377      104        3\n",
      "7          12           200      1.0000        0.0152        42         0     0.9894       0.0337       93        1\n",
      "5          11           300      1.0000        0.0094        26         0     0.9452       0.0250       69        4\n",
      "4          11           200      1.0000        0.0083        23         0     0.9683       0.0221       61        2\n",
      "0          10           100      1.0000        0.0051        14         0     1.0000       0.0141       39        0\n",
      "2          10           300      1.0000        0.0033         9         0     1.0000       0.0069       19        0\n",
      "1          10           200      1.0000        0.0029         8         0     1.0000       0.0080       22        0\n",
      "11         13           300      0.9700        0.0351        97         3     0.9319       0.0645      178       13\n",
      "10         13           200      0.9583        0.0417       115         5     0.9352       0.0732      202       14\n",
      "6          12           100      0.9307        0.0340        94         7     0.9096       0.0619      171       17\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5 by Chal) ===\n",
      "    max_depth  n_estimators  Block_Prec  Block_Recall  Block_TP  Block_FP  Chal_Prec  Chal_Recall  Chal_TP  Chal_FP\n",
      "0          10           100      1.0000        0.0051        14         0     1.0000       0.0141       39        0\n",
      "1          10           200      1.0000        0.0029         8         0     1.0000       0.0080       22        0\n",
      "2          10           300      1.0000        0.0033         9         0     1.0000       0.0069       19        0\n",
      "7          12           200      1.0000        0.0152        42         0     0.9894       0.0337       93        1\n",
      "8          12           300      1.0000        0.0159        44         0     0.9720       0.0377      104        3\n",
      "4          11           200      1.0000        0.0083        23         0     0.9683       0.0221       61        2\n",
      "5          11           300      1.0000        0.0094        26         0     0.9452       0.0250       69        4\n",
      "10         13           200      0.9583        0.0417       115         5     0.9352       0.0732      202       14\n",
      "11         13           300      0.9700        0.0351        97         3     0.9319       0.0645      178       13\n",
      "3          11           100      0.9245        0.0177        49         4     0.9231       0.0391      108        9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# 1. ë°ì´í„° ì¤€ë¹„ (time_diff_secondsê°€ í¬í•¨ëœ df_final ì‚¬ìš© ê°€ì •)\n",
    "# ----------------------------------------------------------------\n",
    "# X, y ì •ì˜\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# Train/Test ë¶„ë¦¬ (Stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Under Sampling (10:1 ë¹„ìœ¨ ìœ ì§€)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Dataset Ready. Train: {X_resampled.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# 2. íŠœë‹í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •\n",
    "# ----------------------------------------------------------------\n",
    "# ê¹Šì´(max_depth)ë¥¼ ëŠ˜ë¦¬ë©´ ë” ë³µì¡í•œ ì‚¬ê¸° íŒ¨í„´(ê´´ë„í•œ ì¡°ê±´)ì„ ì™¸ì›ë‹ˆë‹¤.\n",
    "# í•™ìŠµë¥ (learning_rate)ì„ ì¤„ì´ê³  íŠ¸ë¦¬ë¥¼ ëŠ˜ë¦¬ë©´(n_estimators) ë” ì •êµí•´ì§‘ë‹ˆë‹¤.\n",
    "param_grid = {\n",
    "    'max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],          # ê¹Šì´ ë³€í™” (í•µì‹¬)\n",
    "    'n_estimators': [100, 200, 300]         # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "}\n",
    "\n",
    "# ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"ğŸš€ ì´ {len(combinations)}ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 3. ì‹¤í—˜ ë° ê²°ê³¼ ê¸°ë¡\n",
    "# ----------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(combinations):\n",
    "    print(f\"[{i+1}/{len(combinations)}] Testing: {params} ...\", end=\" \")\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ìš°ë¦¬ê°€ ê´€ì‹¬ ìˆëŠ” Threshold êµ¬ê°„ë³„ ì„±ê³¼ ì¸¡ì •\n",
    "    # (1) Auto Block êµ¬ê°„ (Threshold 0.99 ì´ìƒ)\n",
    "    th_block = 0.985\n",
    "    y_pred_block = (y_prob >= th_block).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_block).ravel()\n",
    "    prec_block = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec_block = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    # (2) Challenge êµ¬ê°„ (Threshold 0.90 ì´ìƒ)\n",
    "    th_chal = 0.980\n",
    "    y_pred_chal = (y_prob >= th_chal).astype(int)\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(y_test, y_pred_chal).ravel()\n",
    "    prec_chal = tp2 / (tp2 + fp2) if (tp2 + fp2) > 0 else 0\n",
    "    rec_chal = tp2 / (tp2 + fn2) if (tp2 + fn2) > 0 else 0\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    res = params.copy()\n",
    "    \n",
    "    # Block Tier ì„±ê³¼\n",
    "    res['Block_Prec'] = round(prec_block, 4)\n",
    "    res['Block_Recall'] = round(rec_block, 4)\n",
    "    res['Block_TP'] = tp  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['Block_FP'] = fp  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    \n",
    "    # Challenge Tier ì„±ê³¼\n",
    "    res['Chal_Prec'] = round(prec_chal, 4)\n",
    "    res['Chal_Recall'] = round(rec_chal, 4)\n",
    "    res['Chal_TP'] = tp2  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['Chal_FP'] = fp2  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    \n",
    "    results.append(res)\n",
    "    print(\"Done.\")\n",
    "\n",
    "# 4. ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥\n",
    "# ----------------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ë³´ê¸° ì¢‹ê²Œ ì •ë ¬: \n",
    "# 1ìˆœìœ„: Block Precisionì´ 0.99 ì´ìƒì¸ ê²ƒ ì¤‘ì—ì„œ\n",
    "# 2ìˆœìœ„: Block Recallì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ\n",
    "results_df = results_df.sort_values(by=['Block_Prec', 'Block_Recall'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5 by Block) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "\n",
    "results_df = results_df.sort_values(by=['Chal_Prec', 'Chal_Recall'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5 by Chal) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "# CSV ì €ì¥ (ì„ íƒ)\n",
    "# results_df.to_csv('sniper_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ff0af",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 10\n",
    "\n",
    "3ì°¨ ì •ì œ ë°ì´í„°ë¥¼ í™œìš©í•˜ê³  ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ RandomForest ë°˜ë³µí•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì €ì„ê³„ì (2ì°¨ ì¸ì¦ ëŒ€ìƒ) êµ¬ê°„ì˜ ì¶”ì´ë¥¼ ë¶„ì„í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.\n",
    "\n",
    "threshold = 0.9ì— ëŒ€í•˜ì—¬ F1-Scoreê°€ ìµœê³ ë¡œ ì˜ ë‚˜ì˜¤ëŠ” ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "threshold = 0.9, max_depth = 18, n_estimators = 300\n",
    "\n",
    "-> Precision = 0.7124, Recall = 0.5795, TP = 1600, FP = 646, F1-score = 0.6391\n",
    "\n",
    "ìœ ì˜ë¯¸í•œ ëª¨ë¸ì´ íƒ„ìƒí–ˆìŠµë‹ˆë‹¤. Recallê³¼ F1-scoreì„ ë™ì‹œì— ë” ëŒì–´ì˜¬ë¦´ ë°©ì•ˆì„ ì‹œë„í•´ë´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì €ì„ê³„ì (2ì°¨ ì¸ì¦ ëŒ€ìƒ) êµ¬ê°„ì—ì„œ XGBoostê°€ ì–´ëŠì •ë„ ìœ„ë ¥ì„ ê°€ì§€ëŠ”ì§€ ì¬íƒìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2caa29da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Ready. Train: (121462, 16), Test: (1830308, 16)\n",
      "ğŸš€ ì´ 33ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\n",
      "[1/33] Testing: {'max_depth': 10, 'n_estimators': 100} ... Done.\n",
      "[2/33] Testing: {'max_depth': 10, 'n_estimators': 200} ... Done.\n",
      "[3/33] Testing: {'max_depth': 10, 'n_estimators': 300} ... Done.\n",
      "[4/33] Testing: {'max_depth': 11, 'n_estimators': 100} ... Done.\n",
      "[5/33] Testing: {'max_depth': 11, 'n_estimators': 200} ... Done.\n",
      "[6/33] Testing: {'max_depth': 11, 'n_estimators': 300} ... Done.\n",
      "[7/33] Testing: {'max_depth': 12, 'n_estimators': 100} ... Done.\n",
      "[8/33] Testing: {'max_depth': 12, 'n_estimators': 200} ... Done.\n",
      "[9/33] Testing: {'max_depth': 12, 'n_estimators': 300} ... Done.\n",
      "[10/33] Testing: {'max_depth': 13, 'n_estimators': 100} ... Done.\n",
      "[11/33] Testing: {'max_depth': 13, 'n_estimators': 200} ... Done.\n",
      "[12/33] Testing: {'max_depth': 13, 'n_estimators': 300} ... Done.\n",
      "[13/33] Testing: {'max_depth': 14, 'n_estimators': 100} ... Done.\n",
      "[14/33] Testing: {'max_depth': 14, 'n_estimators': 200} ... Done.\n",
      "[15/33] Testing: {'max_depth': 14, 'n_estimators': 300} ... Done.\n",
      "[16/33] Testing: {'max_depth': 15, 'n_estimators': 100} ... Done.\n",
      "[17/33] Testing: {'max_depth': 15, 'n_estimators': 200} ... Done.\n",
      "[18/33] Testing: {'max_depth': 15, 'n_estimators': 300} ... Done.\n",
      "[19/33] Testing: {'max_depth': 16, 'n_estimators': 100} ... Done.\n",
      "[20/33] Testing: {'max_depth': 16, 'n_estimators': 200} ... Done.\n",
      "[21/33] Testing: {'max_depth': 16, 'n_estimators': 300} ... Done.\n",
      "[22/33] Testing: {'max_depth': 17, 'n_estimators': 100} ... Done.\n",
      "[23/33] Testing: {'max_depth': 17, 'n_estimators': 200} ... Done.\n",
      "[24/33] Testing: {'max_depth': 17, 'n_estimators': 300} ... Done.\n",
      "[25/33] Testing: {'max_depth': 18, 'n_estimators': 100} ... Done.\n",
      "[26/33] Testing: {'max_depth': 18, 'n_estimators': 200} ... Done.\n",
      "[27/33] Testing: {'max_depth': 18, 'n_estimators': 300} ... Done.\n",
      "[28/33] Testing: {'max_depth': 19, 'n_estimators': 100} ... Done.\n",
      "[29/33] Testing: {'max_depth': 19, 'n_estimators': 200} ... Done.\n",
      "[30/33] Testing: {'max_depth': 19, 'n_estimators': 300} ... Done.\n",
      "[31/33] Testing: {'max_depth': 20, 'n_estimators': 100} ... Done.\n",
      "[32/33] Testing: {'max_depth': 20, 'n_estimators': 200} ... Done.\n",
      "[33/33] Testing: {'max_depth': 20, 'n_estimators': 300} ... Done.\n",
      "\n",
      "=== ğŸ¯ Sniper Grid Search Results (Top 5) ===\n",
      "    max_depth  n_estimators  90_Prec  90_Recall  90_TP  90_FP   90_F1  95_Prec  95_Recall  95_TP  95_FP   95_F1\n",
      "26         18           300   0.7124     0.5795   1600    646  0.6391   0.8410     0.3926   1084    205  0.5353\n",
      "25         18           200   0.7121     0.5788   1598    646  0.6386   0.8354     0.3951   1091    215  0.5365\n",
      "29         19           300   0.7004     0.5784   1597    683  0.6336   0.8314     0.3966   1095    222  0.5370\n",
      "24         18           100   0.6967     0.5791   1599    696  0.6325   0.8347     0.4042   1116    221  0.5447\n",
      "32         20           300   0.6976     0.5781   1596    692  0.6322   0.8290     0.4038   1115    230  0.5431\n",
      "28         19           200   0.6941     0.5802   1602    706  0.6321   0.8254     0.3973   1097    232  0.5364\n",
      "31         20           200   0.6891     0.5835   1611    727  0.6319   0.8216     0.4071   1124    244  0.5444\n",
      "21         17           100   0.7056     0.5694   1572    656  0.6302   0.8377     0.3962   1094    212  0.5380\n",
      "22         17           200   0.7068     0.5683   1569    651  0.6300   0.8381     0.3901   1077    208  0.5324\n",
      "23         17           300   0.7085     0.5668   1565    644  0.6298   0.8414     0.3861   1066    201  0.5293\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "# 1. ë°ì´í„° ì¤€ë¹„ (time_diff_secondsê°€ í¬í•¨ëœ df_final ì‚¬ìš© ê°€ì •)\n",
    "# ----------------------------------------------------------------\n",
    "# X, y ì •ì˜\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# Train/Test ë¶„ë¦¬ (Stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Under Sampling (10:1 ë¹„ìœ¨ ìœ ì§€)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Dataset Ready. Train: {X_resampled.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# 2. íŠœë‹í•  íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì„¤ì •\n",
    "# ----------------------------------------------------------------\n",
    "# ê¹Šì´(max_depth)ë¥¼ ëŠ˜ë¦¬ë©´ ë” ë³µì¡í•œ ì‚¬ê¸° íŒ¨í„´(ê´´ë„í•œ ì¡°ê±´)ì„ ì™¸ì›ë‹ˆë‹¤.\n",
    "# í•™ìŠµë¥ (learning_rate)ì„ ì¤„ì´ê³  íŠ¸ë¦¬ë¥¼ ëŠ˜ë¦¬ë©´(n_estimators) ë” ì •êµí•´ì§‘ë‹ˆë‹¤.\n",
    "param_grid = {\n",
    "    'max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],          # ê¹Šì´ ë³€í™” (í•µì‹¬)\n",
    "    'n_estimators': [100, 200, 300]         # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "}\n",
    "\n",
    "# ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "keys, values = zip(*param_grid.items())\n",
    "combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "print(f\"ğŸš€ ì´ {len(combinations)}ê°œì˜ ëª¨ë¸ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# 3. ì‹¤í—˜ ë° ê²°ê³¼ ê¸°ë¡\n",
    "# ----------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(combinations):\n",
    "    print(f\"[{i+1}/{len(combinations)}] Testing: {params} ...\", end=\" \")\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        **params,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # í™•ë¥  ì˜ˆì¸¡\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ìš°ë¦¬ê°€ ê´€ì‹¬ ìˆëŠ” Threshold êµ¬ê°„ë³„ ì„±ê³¼ ì¸¡ì •\n",
    "    # (1) Auto Block êµ¬ê°„ (Threshold 0.99 ì´ìƒ)\n",
    "    th_block = 0.9\n",
    "    y_pred_block = (y_prob >= th_block).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_block).ravel()\n",
    "    prec_block = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec_block = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_block = f1_score(y_test, y_pred_block)\n",
    "    \n",
    "    # (2) Challenge êµ¬ê°„ (Threshold 0.90 ì´ìƒ)\n",
    "    th_chal = 0.95\n",
    "    y_pred_chal = (y_prob >= th_chal).astype(int)\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(y_test, y_pred_chal).ravel()\n",
    "    prec_chal = tp2 / (tp2 + fp2) if (tp2 + fp2) > 0 else 0\n",
    "    rec_chal = tp2 / (tp2 + fn2) if (tp2 + fn2) > 0 else 0\n",
    "    f1_chal = f1_score(y_test, y_pred_chal)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    res = params.copy()\n",
    "    \n",
    "    # Block Tier ì„±ê³¼\n",
    "    res['90_Prec'] = round(prec_block, 4)\n",
    "    res['90_Recall'] = round(rec_block, 4)\n",
    "    res['90_TP'] = tp  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['90_FP'] = fp  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    res['90_F1'] = round(f1_block, 4)\n",
    "    \n",
    "    # Challenge Tier ì„±ê³¼\n",
    "    res['95_Prec'] = round(prec_chal, 4)\n",
    "    res['95_Recall'] = round(rec_chal, 4)\n",
    "    res['95_TP'] = tp2  # ì¡ì€ ì‚¬ê¸°ê¾¼ ìˆ˜\n",
    "    res['95_FP'] = fp2  # ì–µìš¸í•œ ì°¨ë‹¨ ìˆ˜\n",
    "    res['95_F1'] = round(f1_chal, 4)\n",
    "    \n",
    "    results.append(res)\n",
    "    print(\"Done.\")\n",
    "\n",
    "# 4. ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥\n",
    "# ----------------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# ë³´ê¸° ì¢‹ê²Œ ì •ë ¬: \n",
    "# 1ìˆœìœ„: Block Precisionì´ 0.99 ì´ìƒì¸ ê²ƒ ì¤‘ì—ì„œ\n",
    "# 2ìˆœìœ„: Block Recallì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ\n",
    "results_df = results_df.sort_values(by=['90_F1', '95_F1'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n=== ğŸ¯ Sniper Grid Search Results (Top 5) ===\")\n",
    "print(results_df.head(10).to_string())\n",
    "\n",
    "# CSV ì €ì¥ (ì„ íƒ)\n",
    "# results_df.to_csv('sniper_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76154a54",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 11\n",
    "\n",
    "XGBoost, RandomForestì˜ ì‹¬ì¸µ ë¶„ì„ì„ í•˜ê¸° ì „ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì„ ë„ì…í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "3ì°¨ ì •ì œ ë°ì´í„°ë¥¼ í™œìš©í•˜ê³  CatBoostë¥¼ í™œìš©í•œ 3ë‹¨ Grid í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "CatBoostê°€ Precision >= 0.99ì˜ ì´ˆê³ ìœ„í—˜êµ° íƒì§€ì— ì í•©í•œì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "ëª¨ë¸ íƒìƒ‰ ì‹¤íŒ¨. Precision >= 0.99 ì¡°ê±´ì„ ì—†ì• ê³  CatBoost ìì²´ì˜ í¼í¬ë¨¼ìŠ¤ë¥¼ ì •ë°€ì¡°ì‚¬í•  í•„ìš”ì„±ì´ ëŠê»´ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c785522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Ready. Train: (121462, 16), Test: (1830308, 16)\n",
      "ğŸš€ Sniper Grid Search ì‹œì‘ (ì´ 15íšŒ í•™ìŠµ)...\n",
      "[1/15] Depth: 6, Est: 500 | Time: 0s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[2/15] Depth: 6, Est: 1000 | Time: 4s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[3/15] Depth: 6, Est: 1500 | Time: 11s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[4/15] Depth: 8, Est: 500 | Time: 21s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[5/15] Depth: 8, Est: 1000 | Time: 26s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[6/15] Depth: 8, Est: 1500 | Time: 36s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[7/15] Depth: 10, Est: 500 | Time: 49s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[8/15] Depth: 10, Est: 1000 | Time: 60s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[9/15] Depth: 10, Est: 1500 | Time: 78s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[10/15] Depth: 12, Est: 500 | Time: 104s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[11/15] Depth: 12, Est: 1000 | Time: 130s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[12/15] Depth: 12, Est: 1500 | Time: 181s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[13/15] Depth: 14, Est: 500 | Time: 256s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[14/15] Depth: 14, Est: 1000 | Time: 338s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "[15/15] Depth: 14, Est: 1500 | Time: 502s ..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Recall (Prec>=0.99): 0.0000\n",
      "\n",
      "==================================================\n",
      "ğŸ† Final Sniper Model Found!\n",
      "==================================================\n",
      "Best Params    : {}\n",
      "Best Threshold : 0.0000\n",
      "Precision      : 0.0000\n",
      "Recall (Catch) : 0.0000\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 1. ë°ì´í„° ì¤€ë¹„ (time_diff_secondsê°€ í¬í•¨ëœ df_final ì‚¬ìš© ê°€ì •)\n",
    "# ----------------------------------------------------------------\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ì§€ì • (CatBoostì˜ ê°•ë ¥í•œ ë¬´ê¸°)\n",
    "# ì‹¤ì œ ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ëª…ì— ë§ì¶° ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "# ì˜ˆ: mcc_riskë‚˜ state_risk ëŒ€ì‹  ì›ë³¸ mcc, merchant_stateë¥¼ ì¨ë„ ë©ë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜ëœ df_finalì„ ì“´ë‹¤ê³  ê°€ì •í•˜ë¯€ë¡œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë‘¡ë‹ˆë‹¤.\n",
    "# ë§Œì•½ ì›ë³¸ ë¬¸ìì—´ ì»¬ëŸ¼ì„ ì“´ë‹¤ë©´ cat_features = ['merchant_state', 'mcc'] ë“±ìœ¼ë¡œ ì§€ì •.\n",
    "cat_features = [] \n",
    "\n",
    "X = df_final.drop('is_fraud', axis=1)\n",
    "y = df_final['is_fraud']\n",
    "\n",
    "# Train/Test ë¶„ë¦¬\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Under Sampling (10:1 ë¹„ìœ¨) - í•™ìŠµ ì†ë„ ë° ë¶ˆê· í˜• í•´ì†Œ\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Data Ready. Train: {X_resampled.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# 2. íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ë° ë³€ìˆ˜ ì„¤ì •\n",
    "# ----------------------------------------------------------------\n",
    "# CatBoostëŠ” depthê°€ 16ì„ ë„˜ì–´ê°€ë©´ GPU ë©”ëª¨ë¦¬ê°€ í„°ì§€ê±°ë‚˜ ë§¤ìš° ëŠë ¤ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë³´í†µ 6~12 ì‚¬ì´ì—ì„œ ì„±ëŠ¥ì´ ê²°ì •ë©ë‹ˆë‹¤. 16ê¹Œì§€ í…ŒìŠ¤íŠ¸í•´ë´…ì‹œë‹¤.\n",
    "depth_list = [6, 8, 10, 12, 14] \n",
    "estimators_list = [500, 1000, 1500] # CatBoostëŠ” íŠ¸ë¦¬ë¥¼ ë§ì´ ì‹¬ì–´ë„ ê³¼ì í•©ì´ ì ìŒ\n",
    "threshold_list = np.arange(0.80, 1.00, 0.01)\n",
    "\n",
    "best_record = {\n",
    "    'recall': 0,\n",
    "    'precision': 0,\n",
    "    'threshold': 0,\n",
    "    'params': {},\n",
    "    'model': None\n",
    "}\n",
    "\n",
    "total_iter = len(depth_list) * len(estimators_list)\n",
    "current_iter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"ğŸš€ Sniper Grid Search ì‹œì‘ (ì´ {total_iter}íšŒ í•™ìŠµ)...\")\n",
    "\n",
    "# 3. Grid Search Loop\n",
    "# ----------------------------------------------------------------\n",
    "for d in depth_list:\n",
    "    for n in estimators_list:\n",
    "        current_iter += 1\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"[{current_iter}/{total_iter}] Depth: {d}, Est: {n} | Time: {elapsed:.0f}s ...\", end=\"\")\n",
    "        \n",
    "        # ëª¨ë¸ ì •ì˜ (GPU ì‚¬ìš©)\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=n,\n",
    "            depth=d,\n",
    "            learning_rate=0.05,\n",
    "            loss_function='Logloss',\n",
    "            eval_metric='AUC',\n",
    "            task_type=\"GPU\",       # GPU ì‚¬ìš© ì„¤ì •\n",
    "            devices='0',           # ì²« ë²ˆì§¸ GPU ì‚¬ìš©\n",
    "            random_seed=42,\n",
    "            verbose=0,             # ë¡œê·¸ ì¶œë ¥ ë„ê¸°\n",
    "            cat_features=cat_features,\n",
    "            scale_pos_weight=1     # Sniper ëª¨ë“œ (ê°€ì¤‘ì¹˜ ì—†ìŒ)\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_resampled, y_resampled)\n",
    "            \n",
    "            # í™•ë¥  ì˜ˆì¸¡\n",
    "            y_prob = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            # Threshold ìŠ¤ìº”\n",
    "            local_best_recall = 0\n",
    "            local_best_prec = 0\n",
    "            \n",
    "            for th in threshold_list:\n",
    "                y_pred = (y_prob >= th).astype(int)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "                \n",
    "                # ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ ê³„ì‚°\n",
    "                prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "                rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                \n",
    "                # ì¡°ê±´: Precision >= 0.99\n",
    "                if prec >= 0.99:\n",
    "                    # Recall ìµœëŒ€í™” ê°±ì‹ \n",
    "                    if rec > best_record['recall']:\n",
    "                        best_record['recall'] = rec\n",
    "                        best_record['precision'] = prec\n",
    "                        best_record['threshold'] = th\n",
    "                        best_record['params'] = {'depth': d, 'n_estimators': n}\n",
    "                        best_record['model'] = model # ìµœê³  ëª¨ë¸ ì €ì¥\n",
    "                    \n",
    "                    # í˜„ì¬ ëª¨ë¸ ë‚´ì—ì„œ ë¡œê·¸ìš© ê¸°ë¡\n",
    "                    if rec > local_best_recall:\n",
    "                        local_best_recall = rec\n",
    "                        local_best_prec = prec\n",
    "            \n",
    "            print(f\" Best Recall (Prec>=0.99): {local_best_recall:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error: {e}\")\n",
    "\n",
    "# 4. ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸\n",
    "# ----------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ† Final Sniper Model Found!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best Params    : {best_record['params']}\")\n",
    "print(f\"Best Threshold : {best_record['threshold']:.4f}\")\n",
    "print(f\"Precision      : {best_record['precision']:.4f}\")\n",
    "print(f\"Recall (Catch) : {best_record['recall']:.4f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ìµœì¢… ëª¨ë¸ë¡œ Confusion Matrix í™•ì¸\n",
    "if best_record['model']:\n",
    "    final_prob = best_record['model'].predict_proba(X_test)[:, 1]\n",
    "    final_pred = (final_prob >= best_record['threshold']).astype(int)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3f456",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 12\n",
    "\n",
    "CatBoost í¼í¬ë¨¼ìŠ¤ ì •ë°€ì§„ë‹¨ìœ¼ë¡œ, ì„¸ ê°€ì§€ ê´€ì ì—ì„œ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "- 0.9 ì´ìƒ Precision êµ¬ê°„ì—ì„œ ìµœëŒ€ Recallì„ Threshold íƒìƒ‰\n",
    "- ëª¨ë¸ í•™ìŠµì— ìµœëŒ€ ê¸°ì—¬í•œ ë°ì´í„° íƒìƒ‰\n",
    "- ëª¨ë¸ì´ 1ë¡œ ì˜ˆì¸¡í•œ í•­ëª©ì— ëŒ€í•œ ê·¼ê±°ê°€ í™•ì‹¤í•œì§€ ë¶„ì„\n",
    "\n",
    "ê²°ê³¼ : \n",
    "\n",
    "íƒì§€ëœ ì‚¬ê¸° ëª¨ë¸ë“¤ì„ ë³´ë©´ ëª¨ë¸ í•™ìŠµì˜ ë°©í–¥ ìì²´ëŠ” ì˜¬ë°”ë¥´ê²Œ ë˜ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. (99.999% ì´ìƒ í™•ì‹¤í•œ ê·¼ê±°ë¡œ ì˜¬ë°”ë¥¸ ì‚¬ê¸°ê±°ë˜ë¥¼ íƒì§€í•˜ê³  ìˆìŒ)\n",
    "\n",
    "ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  Threshold ì„ê³„ê°€ ë„ˆë¬´ ê³¼í•˜ê²Œ ë†’ê³  Recallì´ ë‚˜ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ ê¸°ì—¬ë„ë¥¼ ë³´ë©´ ì§ì ‘ ì •ì œí•œ mcc_risk, zip_riskê°€ ì••ë„ì ìœ¼ë¡œ ë†’ê²Œ ê¸°ì—¬í•˜ê³  ìˆëŠ”ë°, ì´ëŠ” CatBoostì˜ ì¥ì (ë²”ì£¼í˜• ë°ì´í„°ì˜ ë§¥ë½íŒŒì•…ì— ê°•ë ¥í•˜ë‹¤)ì„ ì£½ì´ê³  ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ ë°ì´í„° ì¬ì •ì œë¥¼ í†µí•´ Catboostë¥¼ í™œìš©í•´ë³¼ í•„ìš”ì„±ì´ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f28253d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ CatBoost ì •ë°€ ì§„ë‹¨ ì‹œì‘...\n",
      "\n",
      "=== ğŸ“Š Precision êµ¬ê°„ë³„ ì„±ê³¼ ë¶„ì„ ===\n",
      "Min Precision   | Max Recall | Threshold \n",
      "---------------------------------------------\n",
      "0.9             | 0.2622     | 0.9989    \n",
      "0.95            | 0.0605     | 0.9999    \n",
      "0.98            | 0.0344     | 1.0000    \n",
      "0.99            | 0.0239     | 1.0000    \n",
      "0.995           | 0.0239     | 1.0000    \n",
      "0.999           | 0.0239     | 1.0000    \n",
      "\n",
      "=== ğŸŒŸ Feature Importance Top 5 ===\n",
      "              feature  importance\n",
      "8            mcc_risk   16.288216\n",
      "10           zip_risk   14.047003\n",
      "6                hour   11.003966\n",
      "9          state_risk   10.231560\n",
      "13  time_diff_seconds    6.700268\n",
      "\n",
      "=== ğŸ” Top 10 ì˜ì‹¬ ê±°ë˜ ë¶„ì„ ===\n",
      "Rank  | Prob       | True Label\n",
      "1     | 0.999998   | 1\n",
      "2     | 0.999996   | 1\n",
      "3     | 0.999996   | 1\n",
      "4     | 0.999995   | 1\n",
      "5     | 0.999995   | 1\n",
      "6     | 0.999994   | 1\n",
      "7     | 0.999994   | 1\n",
      "8     | 0.999993   | 1\n",
      "9     | 0.999992   | 1\n",
      "10    | 0.999992   | 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. ë‹¨ì¼ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ ì§„ë‹¨ (Depth 10 ì •ë„ê°€ ì ë‹¹)\n",
    "print(\"ğŸš€ CatBoost ì •ë°€ ì§„ë‹¨ ì‹œì‘...\")\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=10,\n",
    "    learning_rate=0.05,\n",
    "    task_type=\"GPU\",      # GPU ì‚¬ìš©\n",
    "    random_seed=42,\n",
    "    verbose=0,\n",
    "    scale_pos_weight=1    # Sniper Mode\n",
    ")\n",
    "\n",
    "model.fit(X_resampled, y_resampled)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. ì •ë°€ë„-ì¬í˜„ìœ¨(PR) ë°ì´í„° ì¶”ì¶œ\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# 3. ì •ë°€ë„ êµ¬ê°„ë³„ ìµœëŒ€ Recall í™•ì¸\n",
    "print(\"\\n=== ğŸ“Š Precision êµ¬ê°„ë³„ ì„±ê³¼ ë¶„ì„ ===\")\n",
    "print(f\"{'Min Precision':<15} | {'Max Recall':<10} | {'Threshold':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "target_precs = [0.90, 0.95, 0.98, 0.99, 0.995, 0.999]\n",
    "for target in target_precs:\n",
    "    # í•´ë‹¹ ì •ë°€ë„ ì´ìƒì„ ë§Œì¡±í•˜ëŠ” êµ¬ê°„ ì°¾ê¸°\n",
    "    valid_indices = [i for i, p in enumerate(precisions) if p >= target]\n",
    "    \n",
    "    if valid_indices:\n",
    "        # ê·¸ ì¤‘ì—ì„œ Recallì´ ê°€ì¥ ë†’ì€ ì§€ì \n",
    "        best_idx = valid_indices[0] # ë³´í†µ Thresholdê°€ ë‚®ì„ìˆ˜ë¡ Recallì´ ë†’ìœ¼ë¯€ë¡œ ì²«ë²ˆì§¸ê°€ Max Recall\n",
    "        # ì •ë°€ë„ ê³¡ì„ ì€ ë“¤ì‘¥ë‚ ì‘¥í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ validí•œ ê²ƒ ì¤‘ max recallì„ ì°¾ìŒ\n",
    "        valid_recalls = [recalls[i] for i in valid_indices]\n",
    "        max_recall = max(valid_recalls)\n",
    "        \n",
    "        # í•´ë‹¹ Recallì„ ë§Œë“œëŠ” Threshold ì°¾ê¸° (approx)\n",
    "        # precisions/recalls ê¸¸ì´ëŠ” thresholds ê¸¸ì´ + 1\n",
    "        th_idx = [i for i, r in enumerate(recalls) if r == max_recall and precisions[i] >= target][0]\n",
    "        th_val = thresholds[min(th_idx, len(thresholds)-1)]\n",
    "        \n",
    "        print(f\"{target:<15} | {max_recall:<10.4f} | {th_val:<10.4f}\")\n",
    "    else:\n",
    "        print(f\"{target:<15} | {'ë¶ˆê°€ëŠ¥':<10} | {'-'}\")\n",
    "\n",
    "# 4. Feature Importance í™•ì¸ (time_diffê°€ ì“°ì˜€ëŠ”ì§€ í™•ì¸)\n",
    "print(\"\\n=== ğŸŒŸ Feature Importance Top 5 ===\")\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.get_feature_importance()\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(feat_imp.head(5))\n",
    "\n",
    "# 5. Top 10 ì˜ˆì¸¡ í™•ì¸ (ìµœìƒìœ„ ì˜¤íƒ í™•ì¸)\n",
    "print(\"\\n=== ğŸ” Top 10 ì˜ì‹¬ ê±°ë˜ ë¶„ì„ ===\")\n",
    "top_indices = y_prob.argsort()[::-1][:10]\n",
    "print(f\"{'Rank':<5} | {'Prob':<10} | {'True Label':<10}\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    print(f\"{i+1:<5} | {y_prob[idx]:<10.6f} | {y_test.iloc[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4aea3",
   "metadata": {},
   "source": [
    "# 4ì°¨ ë°ì´í„° ì •ì œ\n",
    "\n",
    "ë²”ì£¼í˜• ë°ì´í„° ë¶„ì„ì— ê°•í•œ CatBoostë¥¼ ìœ„í•´ ë°ì´í„°ë¥¼ ìƒˆë¡œì´ ì •ì œí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì„ì˜ë¡œ ì •ì œí–ˆë˜ ë°ì´í„° ì¤‘ ë²”ì£¼í˜• ì»¬ëŸ¼ì€ ë‹¤ì‹œ ë²”ì£¼í˜•ìœ¼ë¡œ ì‚´ë ¤ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ì»¬ëŸ¼ ìˆœì„œ\n",
    "\n",
    "'amount', 'utilization_ratio', 'amount_income_ratio', \n",
    "'tech_mismatch', 'pin_years_gap', 'num_credit_cards', \n",
    "'hour', 'is_night', \n",
    "'time_diff_seconds', 'count_24h', 'sum_amt_1h', # Velocity\n",
    "'current_age', 'credit_score',\n",
    "\n",
    "[í•µì‹¬ ë³€ê²½] Risk ë³€ìˆ˜ ëŒ€ì‹  ì›ë³¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì‚¬ìš©\n",
    "\n",
    "'mcc', # mcc_risk ëŒ€ì‹  ë²”ì£¼í˜• ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "'merchant_state', # state_risk ëŒ€ì‹  ë²”ì£¼í˜• ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "'zip',  # zip_risk ëŒ€ì‹  ë²”ì£¼í˜• ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "'use_chip', # ë²”ì£¼í˜• ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "\n",
    "'card_brand', # ë²”ì£¼í˜• ë¸Œëœë“œ ì •ë³´ë„ ì¶”ê°€\n",
    "\n",
    "'is_fraud' # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811f16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì›ë³¸ ë²”ì£¼í˜• ë°ì´í„° ë³µêµ¬\n",
    "# df_finalì—ëŠ” risk ì ìˆ˜ë§Œ ìˆê³  ì›ë³¸ ì½”ë“œê°€ ì—†ì„ ìˆ˜ ìˆìœ¼ë‹ˆ, \n",
    "# ì „ì²˜ë¦¬ ë‹¨ê³„ì˜ dfì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ë‹¤ì‹œ í•©ì³ì•¼ í•©ë‹ˆë‹¤.\n",
    "# (dfëŠ” velocity featureê¹Œì§€ ë‹¤ ë§Œë“¤ì–´ì§„ ìƒíƒœë¼ê³  ê°€ì •)\n",
    "\n",
    "# ì‚¬ìš©í•  í”¼ì²˜ ì¬ì„ ì • (Risk ë³€ìˆ˜ ì œê±° -> ì›ë³¸ ë³€ìˆ˜ íˆ¬ì…)\n",
    "raw_cat_features = [\n",
    "    'amount', 'utilization_ratio', 'amount_income_ratio', \n",
    "    'tech_mismatch', 'pin_years_gap', 'num_credit_cards', \n",
    "    'hour', 'is_night', \n",
    "    'time_diff_seconds', 'count_24h', 'sum_amt_1h', # Velocity\n",
    "    'current_age', 'credit_score',\n",
    "    \n",
    "    # [í•µì‹¬ ë³€ê²½] Risk ë³€ìˆ˜ ëŒ€ì‹  ì›ë³¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì‚¬ìš©\n",
    "    'mcc',            # mcc_risk ëŒ€ì‹  (ìˆ«ìí˜•ì´ë¼ë„ ë²”ì£¼í˜•ìœ¼ë¡œ ì·¨ê¸‰)\n",
    "    'merchant_state', # state_risk ëŒ€ì‹  (ë¬¸ìì—´)\n",
    "    'zip',            # zip_risk ëŒ€ì‹  (ìˆ«ìí˜•ì´ë¼ë„ ë²”ì£¼í˜•ìœ¼ë¡œ ì·¨ê¸‰)\n",
    "    'use_chip',       # tech_mismatchê°€ ìˆì§€ë§Œ ì›ë³¸ë„ ê°™ì´ ì¤˜ë´…ë‹ˆë‹¤\n",
    "    'card_brand',     # ë¸Œëœë“œ ì •ë³´ë„ ì¶”ê°€\n",
    "    \n",
    "    'is_fraud' # Target\n",
    "]\n",
    "\n",
    "# í•´ë‹¹ ì»¬ëŸ¼ë“¤ë¡œ ë°ì´í„°ì…‹ êµ¬ì„±\n",
    "# (ì£¼ì˜: Null ê°’ì´ ìˆìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤. ë¬¸ìì—´ì€ 'Unknown', ìˆ«ìëŠ” -1 ë“±ìœ¼ë¡œ ì±„ìš°ì„¸ìš”)\n",
    "df_raw_cat = df[raw_cat_features].copy()\n",
    "df_raw_cat['merchant_state'] = df_raw_cat['merchant_state'].fillna('Unknown')\n",
    "df_raw_cat['card_brand'] = df_raw_cat['card_brand'].fillna('Unknown')\n",
    "df_raw_cat['mcc'] = df_raw_cat['mcc'].astype(str) # ìˆ«ìê°€ ì•„ë‹Œ ë²”ì£¼ë¡œ ì¸ì‹ë˜ê²Œ ë¬¸ìì—´ ë³€í™˜ ì¶”ì²œ\n",
    "df_raw_cat['zip'] = df_raw_cat['zip'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0532dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9151537 entries, 0 to 9151536\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Dtype  \n",
      "---  ------               -----  \n",
      " 0   amount               float64\n",
      " 1   utilization_ratio    float64\n",
      " 2   amount_income_ratio  float64\n",
      " 3   tech_mismatch        int64  \n",
      " 4   pin_years_gap        int64  \n",
      " 5   num_credit_cards     int64  \n",
      " 6   hour                 int32  \n",
      " 7   is_night             int64  \n",
      " 8   time_diff_seconds    float64\n",
      " 9   count_24h            float64\n",
      " 10  sum_amt_1h           float64\n",
      " 11  current_age          int64  \n",
      " 12  credit_score         int64  \n",
      " 13  mcc                  object \n",
      " 14  merchant_state       object \n",
      " 15  zip                  object \n",
      " 16  use_chip             object \n",
      " 17  card_brand           object \n",
      " 18  is_fraud             int64  \n",
      "dtypes: float64(6), int32(1), int64(7), object(5)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df_raw_cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c04546",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 13\n",
    "\n",
    "4ì°¨ ì •ì œ ë°ì´í„°ì— ëŒ€í•˜ì—¬ CatBoost í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "Precision = ì´ 0.99 ì´ìƒì¸ ëª¨ë¸ ì¤‘ Recallì´ ë†’ì€ ì„ê³„ì ì„ ì‹¤ìˆ˜ë²”ìœ„ì—ì„œ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "Threshold : 0.99899755\n",
    "\n",
    "Precision : 0.9901\n",
    "\n",
    "Recall    : 0.4335\n",
    "\n",
    "ë§¤ìš° ì¢‹ì€ ëª¨ë¸ì´ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ depthë¥¼ ì¢€ ë°”ê¿”ê°€ë©° ìµœê³ ì˜ Tier 1 (ì´ˆê³ ìœ„í—˜êµ°) ëª¨ë¸ì„ ì„ ì •í•˜ë©´ ìµœê³ ì˜ ëª¨ë¸ ì„ ì •ì´ ê°€ëŠ¥í•´ ë³´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ CatBoost Raw Category í•™ìŠµ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.9767171\tbest: 0.9767171 (0)\ttotal: 76.7ms\tremaining: 1m 55s\n",
      "100:\ttest: 0.9952612\tbest: 0.9952612 (100)\ttotal: 7.5s\tremaining: 1m 43s\n",
      "200:\ttest: 0.9959113\tbest: 0.9959113 (200)\ttotal: 15.2s\tremaining: 1m 38s\n",
      "300:\ttest: 0.9961649\tbest: 0.9961649 (300)\ttotal: 22.9s\tremaining: 1m 31s\n",
      "400:\ttest: 0.9962667\tbest: 0.9962749 (390)\ttotal: 30.7s\tremaining: 1m 24s\n",
      "500:\ttest: 0.9963647\tbest: 0.9963713 (490)\ttotal: 38.5s\tremaining: 1m 16s\n",
      "600:\ttest: 0.9964501\tbest: 0.9964501 (600)\ttotal: 46.4s\tremaining: 1m 9s\n",
      "700:\ttest: 0.9964825\tbest: 0.9964871 (680)\ttotal: 54.1s\tremaining: 1m 1s\n",
      "800:\ttest: 0.9964259\tbest: 0.9964871 (680)\ttotal: 1m 1s\tremaining: 54.1s\n",
      "900:\ttest: 0.9964379\tbest: 0.9964871 (680)\ttotal: 1m 9s\tremaining: 46.3s\n",
      "1000:\ttest: 0.9964314\tbest: 0.9964871 (680)\ttotal: 1m 17s\tremaining: 38.6s\n",
      "1100:\ttest: 0.9964395\tbest: 0.9964871 (680)\ttotal: 1m 25s\tremaining: 30.9s\n",
      "1200:\ttest: 0.9964095\tbest: 0.9964871 (680)\ttotal: 1m 33s\tremaining: 23.2s\n",
      "1300:\ttest: 0.9964210\tbest: 0.9964871 (680)\ttotal: 1m 41s\tremaining: 15.5s\n",
      "1400:\ttest: 0.9964103\tbest: 0.9964871 (680)\ttotal: 1m 49s\tremaining: 7.7s\n",
      "1499:\ttest: 0.9964252\tbest: 0.9964871 (680)\ttotal: 1m 56s\tremaining: 0us\n",
      "bestTest = 0.9964871407\n",
      "bestIteration = 680\n",
      "Shrink model to first 681 iterations.\n",
      "\n",
      "=== ğŸ“Š New CatBoost (Raw Features) ì„±ê³¼ ===\n",
      "Precision >= 0.95: Max Recall = 0.5951\n",
      "Precision >= 0.98: Max Recall = 0.5024\n",
      "Precision >= 0.99: Max Recall = 0.4335\n"
     ]
    }
   ],
   "source": [
    "# CatBoost í•™ìŠµ (Raw Features)\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_raw_cat.drop('is_fraud', axis=1)\n",
    "y = df_raw_cat['is_fraud']\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì§€ì • (ì´ê²Œ í•µì‹¬!)\n",
    "cat_features_indices = ['mcc', 'merchant_state', 'zip', 'use_chip', 'card_brand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Undersampling (10:1)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"ğŸš€ CatBoost Raw Category í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1500,        # ë„‰ë„‰í•˜ê²Œ\n",
    "    depth=10,\n",
    "    learning_rate=0.05,\n",
    "    task_type=\"GPU\",        # GPU ê°€ì†\n",
    "    eval_metric='AUC',\n",
    "    cat_features=cat_features_indices, # [í•µì‹¬] ì—¬ê¸°ì— ì›ë³¸ ì»¬ëŸ¼ ì§€ì •\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    scale_pos_weight=1\n",
    ")\n",
    "\n",
    "model.fit(X_resampled, y_resampled, eval_set=(X_test, y_test))\n",
    "\n",
    "# 3. ì„±ëŠ¥ í™•ì¸ (Recall ì²´í¬)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Precision 0.99 ì´ìƒì¸ êµ¬ê°„ì˜ Recall í™•ì¸\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "print(\"\\n=== ğŸ“Š New CatBoost (Raw Features) ì„±ê³¼ ===\")\n",
    "target_precs = [0.95, 0.98, 0.99]\n",
    "for target in target_precs:\n",
    "    valid_indices = [i for i, p in enumerate(precisions) if p >= target]\n",
    "    if valid_indices:\n",
    "        valid_recalls = [recalls[i] for i in valid_indices]\n",
    "        print(f\"Precision >= {target}: Max Recall = {max(valid_recalls):.4f}\")\n",
    "    else:\n",
    "        print(f\"Precision >= {target}: ë¶ˆê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf3a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ğŸ† Best Sniper Option Found ===\n",
      "Threshold : 0.99899755\n",
      "Precision : 0.9901\n",
      "Recall    : 0.4335\n",
      "\n",
      "[ê²€ì¦ ê²°ê³¼]\n",
      "[[1827535      12]\n",
      " [   1564    1197]]\n",
      "1197 12 0.9900744416873449 0.43353857298080406\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. ëª©í‘œ Precision ì„¤ì •\n",
    "target_prec = 0.99\n",
    "\n",
    "# 2. ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "# precisions ë°°ì—´ì€ thresholdsë³´ë‹¤ ê¸¸ì´ê°€ 1 ë” ê¹ë‹ˆë‹¤ (ë§ˆì§€ë§‰ 1.0 í¬í•¨).\n",
    "# ë”°ë¼ì„œ ê¸¸ì´ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ë§ˆì§€ë§‰ ìš”ì†Œ ì œì™¸í•˜ê³  ë¹„êµí•˜ê±°ë‚˜ ì¸ë±ì‹±ì— ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "valid_indices = np.where(precisions[:-1] >= target_prec)[0]\n",
    "\n",
    "if len(valid_indices) > 0:\n",
    "    # 3. ê·¸ ì¤‘ì—ì„œ Recallì´ ê°€ì¥ ë†’ì€ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "    # (ë³´í†µ Thresholdê°€ ë‚®ì„ìˆ˜ë¡ Recallì´ ë†’ìœ¼ë¯€ë¡œ, valid_indicesì˜ ì²« ë²ˆì§¸ê°€ Recallì´ ê°€ì¥ ë†’ì„ í™•ë¥ ì´ í¼)\n",
    "    # í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ í•˜ê¸° ìœ„í•´ argmaxë¥¼ ì”ë‹ˆë‹¤.\n",
    "    best_idx = valid_indices[np.argmax(recalls[valid_indices])]\n",
    "    \n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_recall = recalls[best_idx]\n",
    "    best_precision = precisions[best_idx]\n",
    "    \n",
    "    print(f\"=== ğŸ† Best Sniper Option Found ===\")\n",
    "    print(f\"Threshold : {best_threshold:.8f}\")\n",
    "    print(f\"Precision : {best_precision:.4f}\")\n",
    "    print(f\"Recall    : {best_recall:.4f}\")\n",
    "    \n",
    "    # [Tip] ë°”ë¡œ ê²€ì¦í•´ë³´ê¸°\n",
    "    print(\"\\n[ê²€ì¦ ê²°ê³¼]\")\n",
    "    final_pred = (y_prob >= best_threshold).astype(int)\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, final_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, final_pred).ravel()\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    print(tp, fp, prec, rec)\n",
    "    \n",
    "else:\n",
    "    print(f\"Precision {target_prec} ì´ìƒì„ ë§Œì¡±í•˜ëŠ” êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7ae8055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì €ì¥\n",
    "model.save_model(\"catboost_sniper_model_recall43.cbm\")\n",
    "print(\"âœ… ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë‚˜ì¤‘ì— ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# from catboost import CatBoostClassifier\n",
    "# loaded_model = CatBoostClassifier()\n",
    "# loaded_model.load_model(\"catboost_sniper_model_recall43.cbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f65eef",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 14\n",
    "\n",
    "ìš°ì„  í•™ìŠµ 13ì—ì„œ ì°¾ì€ ëª¨ë¸ì„ Tier 1ì— ë°°ì¹˜í•˜ê³  Tier 2 ëª¨ë¸ì„ ì°¾ëŠ” ì‹œë®¬ë ˆì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "Tier 2 ëª¨ë¸ì€ F1-scoreê°€ ë†’ì€ ëª¨ë¸ì˜ ì„ê³„ì ì„ ì‹¤ìˆ˜ë²”ìœ„ì—ì„œ íƒìƒ‰í•©ë‹ˆë‹¤. \n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "Tier 1 (ì¦‰ì‹œ ì°¨ë‹¨) : Threshold 0.998998\n",
    "   [ì„±ê³¼] ì‚¬ê¸°ê¾¼ 1,197ëª… ê²€ê±° (ê²€ê±°ìœ¨ 43.4%)\n",
    "   [ë¹„ìš©] ì˜¤íƒ 12ê±´ (ì •ë°€ë„ 0.9901)\n",
    "          ã„´ ê·¹ì†Œìˆ˜ì˜ VIP ë¯¼ì› ë°œìƒ ê°€ëŠ¥ (SLA í—ˆìš© ë²”ìœ„ ë‚´)\n",
    "          \n",
    "Tier 2 (ì¶”ê°€ ì¸ì¦) : Threshold 0.987650\n",
    "   [ì„±ê³¼] ì‚¬ê¸°ê¾¼ 732ëª… ì¶”ê°€ ê²€ê±° (ì¶”ê°€ ê²€ê±°ìœ¨ 26.5%)\n",
    "   [ë¹„ìš©] ì¼ë°˜ì¸ 280ëª…ì´ ì¸ì¦ ìˆ˜í–‰ (ì •ë°€ë„ 0.7233)\n",
    "          ã„´ ì „ì²´ ê±°ë˜ì˜ 0.06%ë§Œ ì¸ì¦ ìš”ì²­ (ì‚¬ìš©ì ê²½í—˜ ì˜í–¥ ë¯¸ë¯¸)\n",
    "          \n",
    "Tier 3 (ìë™ í†µê³¼)\n",
    "   [ìœ„í—˜] ë†“ì¹œ ì‚¬ê¸°ê¾¼ 832ëª… (30.1%)\n",
    "\n",
    "Tier 1 - Tier 2 ë¡œ ì—°ê³„ë˜ëŠ” 2ì¤‘ ê²€ì¦ ì‹œìŠ¤í…œì€ ìœ íš¨í•˜ë‹¤ëŠ” íŒë‹¨ì…ë‹ˆë‹¤.\n",
    "\n",
    "íŠ¹íˆ Tier 2ì˜ ëª©ì ì„ Recallì— ë‘ëŠëƒ, F1-scoreì— ë‘ëŠëƒì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ ë¹„ì¦ˆë‹ˆìŠ¤ì  ìš”êµ¬ë¥¼ ë§Œì¡±ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ íŒŒë¼ë¯¸í„°ê°’ì„ ë³€í™”ì‹œí‚¤ë©´ì„œ ìµœì ì˜ Tier 1 ëª¨ë¸ê³¼ Tier 2 ëª¨ë¸ì„ ì°¾ì•„ë‚´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c4bd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ 2-Tier ì „ëµ ìµœì¢… ì¡°ìœ¨ ì‹œì‘...\n",
      "\n",
      "ğŸ”« [Tier 1: Block] í™•ì • Threshold: 0.99899755\n",
      "\n",
      "ğŸ‘® [Tier 2: Challenge] ìµœì  Threshold Found!\n",
      "   - Threshold: 0.98764950\n",
      "   - F1-Score : 0.7744\n",
      "   - Precision: 0.8685\n",
      "   - Recall   : 0.6987\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š [ìµœì¢… ë³´ê³ ì„œ] FraudGuard 2-Tier Defense Strategy\n",
      "============================================================\n",
      "ì „ì²´ ê±°ë˜: 1,830,308ê±´ (ì‹¤ì œ ì‚¬ê¸°: 2,761ê±´)\n",
      "------------------------------------------------------------\n",
      "ğŸ”´ Tier 1 (ì¦‰ì‹œ ì°¨ë‹¨) : Threshold 0.998998\n",
      "   [ì„±ê³¼] ì‚¬ê¸°ê¾¼ 1,197ëª… ê²€ê±° (ê²€ê±°ìœ¨ 43.4%)\n",
      "   [ë¹„ìš©] ì˜¤íƒ 12ê±´ (ì •ë°€ë„ 0.9901)\n",
      "          ã„´ âš ï¸ ê·¹ì†Œìˆ˜ì˜ VIP ë¯¼ì› ë°œìƒ ê°€ëŠ¥ (SLA í—ˆìš© ë²”ìœ„ ë‚´)\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¡ Tier 2 (ì¶”ê°€ ì¸ì¦) : Threshold 0.987650\n",
      "   [ì„±ê³¼] ì‚¬ê¸°ê¾¼ 732ëª… ì¶”ê°€ ê²€ê±° (ì¶”ê°€ ê²€ê±°ìœ¨ 26.5%)\n",
      "   [ë¹„ìš©] ì¼ë°˜ì¸ 280ëª…ì´ ì¸ì¦ ìˆ˜í–‰ (ì •ë°€ë„ 0.7233)\n",
      "          ã„´ ì „ì²´ ê±°ë˜ì˜ 0.06%ë§Œ ì¸ì¦ ìš”ì²­ (ì‚¬ìš©ì ê²½í—˜ ì˜í–¥ ë¯¸ë¯¸)\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¢ Tier 3 (ìë™ í†µê³¼)\n",
      "   [ìœ„í—˜] ë†“ì¹œ ì‚¬ê¸°ê¾¼ 832ëª… (30.1%)\n",
      "============================================================\n",
      "ğŸ† í”„ë¡œì íŠ¸ ìµœì¢… ì„±ì í‘œ\n",
      "   1. ì´ ì‚¬ê¸° ë°©ì–´ìœ¨ (Recall) : 69.9%\n",
      "   2. ìë™ ì°¨ë‹¨ ì •ë°€ë„        : 0.9901 (ëª©í‘œ: 0.99)\n",
      "   3. 2ì°¨ ë°©ì–´ì„  íš¨ìœ¨         : ì¼ë°˜ì¸ 1ëª… ê·€ì°®ê²Œ í•  ë•Œë§ˆë‹¤ ì‚¬ê¸°ê¾¼ 2.6ëª… ì¡ìŒ\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# [í•„ìˆ˜] y_testì™€ y_probëŠ” ë©”ëª¨ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# (CatBoost ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼)\n",
    "\n",
    "print(\"ğŸš€ 2-Tier ì „ëµ ìµœì¢… ì¡°ìœ¨ ì‹œì‘...\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Tier 1 (Sniper) ì„¤ì • : ì°¾ìœ¼ì‹  ê°’ìœ¼ë¡œ ê³ ì •\n",
    "# ---------------------------------------------------------\n",
    "th_tier1 = 0.99899755  # [ì‚¬ìš©ìê°€ ì°¾ì€ í™©ê¸ˆ ì„ê³„ê°’]\n",
    "\n",
    "print(f\"\\nğŸ”« [Tier 1: Block] í™•ì • Threshold: {th_tier1}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Tier 2 (Patrol) íƒìƒ‰ : Tier 1 ë¯¸ë§Œ êµ¬ê°„ ì •ë°€ ìŠ¤ìº”\n",
    "# ---------------------------------------------------------\n",
    "# ëª¨ë“  ê°€ëŠ¥í•œ ì„ê³„ê°’ í›„ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df_pr = pd.DataFrame({\n",
    "    'threshold': thresholds,\n",
    "    'precision': precisions[:-1],\n",
    "    'recall': recalls[:-1]\n",
    "})\n",
    "\n",
    "# F1-Score ê³„ì‚°\n",
    "# (ë¶„ëª¨ê°€ 0ì¼ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì—ëŸ¬ ë°©ì§€)\n",
    "df_pr['f1'] = 2 * (df_pr['precision'] * df_pr['recall']) / (df_pr['precision'] + df_pr['recall'] + 1e-10)\n",
    "\n",
    "# Tier 1ë³´ë‹¤ ë‚®ì€ êµ¬ê°„ë§Œ í•„í„°ë§\n",
    "candidates = df_pr[df_pr['threshold'] < th_tier1]\n",
    "\n",
    "# F1-Scoreê°€ ê°€ì¥ ë†’ì€ ì§€ì  ì°¾ê¸°\n",
    "best_patrol = candidates.sort_values('f1', ascending=False).iloc[0]\n",
    "th_tier2 = best_patrol['threshold']\n",
    "\n",
    "print(f\"\\nğŸ‘® [Tier 2: Challenge] ìµœì  Threshold Found!\")\n",
    "print(f\"   - Threshold: {th_tier2:.8f}\")\n",
    "print(f\"   - F1-Score : {best_patrol['f1']:.4f}\")\n",
    "print(f\"   - Precision: {best_patrol['precision']:.4f}\")\n",
    "print(f\"   - Recall   : {best_patrol['recall']:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ìµœì¢… ë°©ì–´ ì „ëµ ì‹œë®¬ë ˆì´ì…˜\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š [ìµœì¢… ë³´ê³ ì„œ] FraudGuard 2-Tier Defense Strategy\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n_total = len(y_test)\n",
    "n_fraud = sum(y_test)\n",
    "\n",
    "# ê·¸ë£¹ ë¶„ë¥˜\n",
    "# 1) Blocked (Tier 1 ì´ìƒ)\n",
    "mask_block = (y_prob >= th_tier1)\n",
    "n_blocked = sum(mask_block)\n",
    "n_blocked_fraud = sum(mask_block & (y_test == 1))\n",
    "n_blocked_innocent = n_blocked - n_blocked_fraud\n",
    "\n",
    "# 2) Challenged (Tier 2 ì´ìƒ ~ Tier 1 ë¯¸ë§Œ)\n",
    "mask_chal = (y_prob >= th_tier2) & (y_prob < th_tier1)\n",
    "n_chal = sum(mask_chal)\n",
    "n_chal_fraud = sum(mask_chal & (y_test == 1))\n",
    "n_chal_innocent = n_chal - n_chal_fraud\n",
    "\n",
    "# 3) Passed (Tier 2 ë¯¸ë§Œ)\n",
    "mask_pass = (y_prob < th_tier2)\n",
    "n_passed = sum(mask_pass)\n",
    "n_passed_fraud = sum(mask_pass & (y_test == 1))\n",
    "\n",
    "# ì£¼ìš” ì§€í‘œ ê³„ì‚° (0 ë‚˜ëˆ„ê¸° ë°©ì§€)\n",
    "recall_tier1 = (n_blocked_fraud / n_fraud * 100) if n_fraud > 0 else 0\n",
    "recall_tier2 = (n_chal_fraud / n_fraud * 100) if n_fraud > 0 else 0\n",
    "total_recall = ((n_blocked_fraud + n_chal_fraud) / n_fraud * 100) if n_fraud > 0 else 0\n",
    "\n",
    "prec_tier1 = (n_blocked_fraud / n_blocked) if n_blocked > 0 else 0\n",
    "prec_tier2 = (n_chal_fraud / n_chal) if n_chal > 0 else 0\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(f\"ì „ì²´ ê±°ë˜: {n_total:,}ê±´ (ì‹¤ì œ ì‚¬ê¸°: {n_fraud:,}ê±´)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"ğŸ”´ Tier 1 (ì¦‰ì‹œ ì°¨ë‹¨) : Threshold {th_tier1:.6f}\")\n",
    "print(f\"   [ì„±ê³¼] ì‚¬ê¸°ê¾¼ {n_blocked_fraud:,}ëª… ê²€ê±° (ê²€ê±°ìœ¨ {recall_tier1:.1f}%)\")\n",
    "print(f\"   [ë¹„ìš©] ì˜¤íƒ {n_blocked_innocent:,}ê±´ (ì •ë°€ë„ {prec_tier1:.4f})\")\n",
    "if n_blocked_innocent > 0:\n",
    "    print(f\"          ã„´ âš ï¸ ê·¹ì†Œìˆ˜ì˜ VIP ë¯¼ì› ë°œìƒ ê°€ëŠ¥ (SLA í—ˆìš© ë²”ìœ„ ë‚´)\")\n",
    "else:\n",
    "    print(f\"          ã„´ âœ… ì˜¤íƒ 0ê±´! ì™„ë²½í•œ ë°©ì–´\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"ğŸŸ¡ Tier 2 (ì¶”ê°€ ì¸ì¦) : Threshold {th_tier2:.6f}\")\n",
    "print(f\"   [ì„±ê³¼] ì‚¬ê¸°ê¾¼ {n_chal_fraud:,}ëª… ì¶”ê°€ ê²€ê±° (ì¶”ê°€ ê²€ê±°ìœ¨ {recall_tier2:.1f}%)\")\n",
    "print(f\"   [ë¹„ìš©] ì¼ë°˜ì¸ {n_chal_innocent:,}ëª…ì´ ì¸ì¦ ìˆ˜í–‰ (ì •ë°€ë„ {prec_tier2:.4f})\")\n",
    "print(f\"          ã„´ ì „ì²´ ê±°ë˜ì˜ {(n_chal/n_total*100):.2f}%ë§Œ ì¸ì¦ ìš”ì²­ (ì‚¬ìš©ì ê²½í—˜ ì˜í–¥ ë¯¸ë¯¸)\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(f\"ğŸŸ¢ Tier 3 (ìë™ í†µê³¼)\")\n",
    "print(f\"   [ìœ„í—˜] ë†“ì¹œ ì‚¬ê¸°ê¾¼ {n_passed_fraud:,}ëª… ({n_passed_fraud/n_fraud*100:.1f}%)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ† í”„ë¡œì íŠ¸ ìµœì¢… ì„±ì í‘œ\")\n",
    "print(f\"   1. ì´ ì‚¬ê¸° ë°©ì–´ìœ¨ (Recall) : {total_recall:.1f}%\")\n",
    "print(f\"   2. ìë™ ì°¨ë‹¨ ì •ë°€ë„        : {prec_tier1:.4f} (ëª©í‘œ: 0.99)\")\n",
    "print(f\"   3. 2ì°¨ ë°©ì–´ì„  íš¨ìœ¨         : ì¼ë°˜ì¸ 1ëª… ê·€ì°®ê²Œ í•  ë•Œë§ˆë‹¤ ì‚¬ê¸°ê¾¼ {prec_tier2/(1-prec_tier2):.1f}ëª… ì¡ìŒ\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89a7b0",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 15\n",
    "\n",
    "CatBoostë¥¼ í†µí•œ Tier 1 ëª¨ë¸ ì‹¬ì¸µí•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "Precision >= 0.99ë¥¼ ë§Œì¡±í•˜ëŠ” ìµœê³ ì˜ Recallì„ ë³´ì—¬ì£¼ëŠ” ìµœì ì˜ ëª¨ë¸ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "Depth : 8, Precision : 0.9902, Recall : 0.5103\n",
    "\n",
    "Threshold : 0.99816559\n",
    "\n",
    "ìµœì¢…ì ìœ¼ë¡œ ì´ ëª¨ë¸ì„ Tier 1 ëª¨ë¸ë¡œ ì„ ì •í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3d8dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Deep Sniper Search ì‹œì‘ (Depth 5 ~ 9)...\n",
      "-----------------------------------------------------------------\n",
      "Depth  | Recall (at P>=0.99)  | Threshold    | Time    \n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      | 0.4698               | 0.996757     | 48.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 0.4835               | 0.997553     | 57.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7      | 0.4973               | 0.997912     | 69.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 0.5103               | 0.998166     | 85.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9      | 0.4382               | 0.999238     | 120.2s\n",
      "-----------------------------------------------------------------\n",
      "ğŸ† Final Deep Sniper Model Found!\n",
      "Best Depth     : 8\n",
      "Target Prec    : 0.9902 (>= 0.99)\n",
      "Max Recall     : 0.5103 (ê²€ê±°ìœ¨)\n",
      "Best Threshold : 0.99816559\n",
      "ğŸ’¾ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: best_sniper_depth8_recall51.cbm\n",
      "\n",
      "[Final Confusion Matrix]\n",
      "[[1827533      14]\n",
      " [   1352    1409]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "\n",
    "# [ì „ì œ] X_resampled, y_resampled, X_test, y_testëŠ” ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "# (ì´ì „ ì½”ë“œì˜ ë°ì´í„° ë¶„í•  ë° Undersampling ë¶€ë¶„ê³¼ ë™ì¼)\n",
    "\n",
    "# íƒìƒ‰í•  Depth ë¦¬ìŠ¤íŠ¸ (8 ~ 18)\n",
    "# ì£¼ì˜: CatBoost GPUëŠ” êµ¬ì¡°ìƒ Depth 16ì„ ì´ˆê³¼í•˜ë©´ ë©”ëª¨ë¦¬ ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë”°ë¼ì„œ ì•ˆì „í•˜ê²Œ try-except êµ¬ë¬¸ìœ¼ë¡œ ê°ì‹¸ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "depth_list = [5, 6, 7, 8, 9] \n",
    "\n",
    "best_record = {\n",
    "    'depth': 0,\n",
    "    'recall': 0.0,\n",
    "    'precision': 0.0,\n",
    "    'threshold': 0.0,\n",
    "    'model': None\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"ğŸš€ Deep Sniper Search ì‹œì‘ (Depth {min(depth_list)} ~ {max(depth_list)})...\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Depth':<6} | {'Recall (at P>=0.99)':<20} | {'Threshold':<12} | {'Time':<8}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for d in depth_list:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=2000,       # ê¹Šì´ê°€ ê¹Šì–´ì§€ë©´ íŠ¸ë¦¬ ê°œìˆ˜ë„ ì¢€ ë„‰ë„‰íˆ (ì¡°ì ˆ ê°€ëŠ¥)\n",
    "            depth=d,\n",
    "            learning_rate=0.03,    # ê¹Šì„ìˆ˜ë¡ í•™ìŠµë¥ ì„ ë‚®ì¶°ì„œ ì„¬ì„¸í•˜ê²Œ (0.05 -> 0.03)\n",
    "            task_type=\"GPU\",\n",
    "            eval_metric='AUC',\n",
    "            cat_features=cat_features_indices, # ì›ë³¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ë±ìŠ¤\n",
    "            random_seed=42,\n",
    "            verbose=0,             # ë¡œê·¸ ë„ê¸°\n",
    "            scale_pos_weight=1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # í™•ë¥  ì˜ˆì¸¡\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # ì •ë°€ë„-ì¬í˜„ìœ¨ ê³¡ì„  ì¶”ì¶œ (ì—¬ê¸°ê°€ í•µì‹¬!)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        # Precision >= 0.99 ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "        # precisionsëŠ” thresholdsë³´ë‹¤ ê¸¸ì´ê°€ 1 ê¸¸ì–´ì„œ ë§ˆì§€ë§‰ ìš”ì†Œ ì œì™¸í•˜ê³  ë§¤ì¹­\n",
    "        valid_indices = np.where(precisions[:-1] >= 0.99)[0]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            # ë§Œì¡±í•˜ëŠ” ê²ƒ ì¤‘ Recallì´ ê°€ì¥ ë†’ì€ ì§€ì  ì°¾ê¸°\n",
    "            # (ë³´í†µ Thresholdê°€ ë‚®ì„ìˆ˜ë¡ Recallì´ ë†’ìŒ)\n",
    "            best_idx = valid_indices[np.argmax(recalls[valid_indices])]\n",
    "            \n",
    "            current_recall = recalls[best_idx]\n",
    "            current_prec = precisions[best_idx]\n",
    "            current_th = thresholds[best_idx]\n",
    "            \n",
    "            # ê²°ê³¼ ê¸°ë¡\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"{d:<6} | {current_recall:<20.4f} | {current_th:<12.6f} | {elapsed:.1f}s\")\n",
    "            \n",
    "            results.append({'depth': d, 'recall': current_recall, 'threshold': current_th})\n",
    "            \n",
    "            # ì—­ëŒ€ ìµœê³  ê¸°ë¡ ê°±ì‹  ì—¬ë¶€ í™•ì¸\n",
    "            if current_recall > best_record['recall']:\n",
    "                best_record['depth'] = d\n",
    "                best_record['recall'] = current_recall\n",
    "                best_record['precision'] = current_prec\n",
    "                best_record['threshold'] = current_th\n",
    "                best_record['model'] = model # ëª¨ë¸ ê°ì²´ í†µì§¸ë¡œ ì €ì¥\n",
    "        else:\n",
    "            print(f\"{d:<6} | {'ì¡°ê±´ ë¶ˆë§Œì¡±':<20} | {'-':<12} | {time.time()-start_time:.1f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"{d:<6} | {'Error (OOM/Support)':<20} | {'-':<12} | -\")\n",
    "        print(f\"       ã„´ {e}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥\n",
    "print(\"-\" * 65)\n",
    "print(\"ğŸ† Final Deep Sniper Model Found!\")\n",
    "print(f\"Best Depth     : {best_record['depth']}\")\n",
    "print(f\"Target Prec    : {best_record['precision']:.4f} (>= 0.99)\")\n",
    "print(f\"Max Recall     : {best_record['recall']:.4f} (ê²€ê±°ìœ¨)\")\n",
    "print(f\"Best Threshold : {best_record['threshold']:.8f}\")\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ (ê°€ì¥ ì¤‘ìš”)\n",
    "if best_record['model']:\n",
    "    save_path = f\"best_sniper_depth{best_record['depth']}_recall{int(best_record['recall']*100)}.cbm\"\n",
    "    best_record['model'].save_model(save_path)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}\")\n",
    "    \n",
    "    # ìµœì¢… ê²€ì¦\n",
    "    final_pred = (best_record['model'].predict_proba(X_test)[:, 1] >= best_record['threshold']).astype(int)\n",
    "    print(\"\\n[Final Confusion Matrix]\")\n",
    "    print(confusion_matrix(y_test, final_pred))\n",
    "else:\n",
    "    print(\"âš ï¸ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c7325",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 16\n",
    "\n",
    "CatBoostë¥¼ í†µí•´ 97%ì˜ ì‚¬ê¸°ê¾¼ì„ ì¡ê¸° ìœ„í•´ì„  ì–¼ë§ˆë‚˜ ë§ì€ í¬ìƒì„ í•´ì•¼ í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "Params      : Depth 6, Weight 5\n",
    "\n",
    "Recall      : 0.9703 (Target >= 0.97)\n",
    "\n",
    "Precision   : 0.0632\n",
    "\n",
    "Threshold   : 0.27505962\n",
    "\n",
    "Precisionì´ ë„ˆë¬´ ë‚®ì•„ ë¹„ì¦ˆë‹ˆìŠ¤ì  ê°€ì¹˜ê°€ ì—†ê³  Thresholdë„ ë„ˆë¬´ ë‚®ì€ê±¸ ë³´ì•„ ë°©í–¥ì„± ìì²´ë„ ì˜ëª»ëœ ê²ƒìœ¼ë¡œ í•´ì„ë©ë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ì˜ ì •ì œ ë°ì´í„°ì™€ ëª¨ë¸ë¡œëŠ” ê·¹ì ì¸ ë³€í™”ë¥¼ ì´ëŒì–´ë‚´ê¸´ ì–´ë µë‹¤ê³  ë³´ì´ë‚˜, ê²½í–¥ì„± íŒŒì•…ì„ ìœ„í•´ F1-Score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í–ˆì„ ë•Œ Precisionê³¼ Recallì˜ ì •ë„ë¥¼ ë³´ëŠ” ê²ƒì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07bddb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì§€ì • (ì´ê²Œ í•µì‹¬!)\u001b[39;00m\n\u001b[32m     11\u001b[39m cat_features_indices = [\u001b[33m'\u001b[39m\u001b[33mmcc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmerchant_state\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33muse_chip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcard_brand\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m, stratify=y)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Undersampling (10:1)\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01munder_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "X = df_raw_cat.drop('is_fraud', axis=1)\n",
    "y = df_raw_cat['is_fraud']\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì§€ì • (ì´ê²Œ í•µì‹¬!)\n",
    "cat_features_indices = ['mcc', 'merchant_state', 'zip', 'use_chip', 'card_brand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Undersampling (10:1)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# íƒìƒ‰ ê·¸ë¦¬ë“œ (Patrol Mode)\n",
    "# ê°€ì¤‘ì¹˜(pos_weight)ë¥¼ ë†’ì´ë©´ ëª¨ë¸ì´ \"ì‚¬ê¸°\"ë¼ê³  ì™¸ì¹˜ëŠ” ë¹ˆë„ê°€ ëŠ˜ì–´ë‚˜ Recallì´ ì˜¤ë¦…ë‹ˆë‹¤.\n",
    "grid_params = [\n",
    "    {'depth': 6, 'weight': 1}, {'depth': 6, 'weight': 3}, {'depth': 6, 'weight': 5},\n",
    "    {'depth': 8, 'weight': 1}, {'depth': 8, 'weight': 3}, {'depth': 8, 'weight': 5},\n",
    "    {'depth': 10, 'weight': 1}, {'depth': 10, 'weight': 3}, {'depth': 10, 'weight': 5},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"ğŸš€ Tier 2 (Patrol) Wide Search ì‹œì‘ (Target Recall >= 0.97)...\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Depth':<6} | {'Weight':<6} | {'Recall':<10} | {'Precision':<10} | {'Threshold':<10} | {'Time':<8}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "best_patrol = {\n",
    "    'f1_score': 0, # Tier 2ëŠ” ë°¸ëŸ°ìŠ¤ê°€ ì¤‘ìš”í•˜ë¯€ë¡œ F1ì´ë‚˜, ì—¬ê¸°ì„  Precision at Recall 97ì„ ë´…ë‹ˆë‹¤.\n",
    "    'precision_at_97': 0,\n",
    "    'recall': 0,\n",
    "    'model': None\n",
    "}\n",
    "\n",
    "for params in grid_params:\n",
    "    d = params['depth']\n",
    "    w = params['weight']\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ëª¨ë¸ ì •ì˜ (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=1000,       # íƒìƒ‰ìš©ì´ë¼ 1000íšŒë¡œ ë‹¨ì¶•\n",
    "            depth=d,\n",
    "            learning_rate=0.1,     # ì†ë„ í–¥ìƒ\n",
    "            task_type=\"GPU\",\n",
    "            eval_metric='AUC',\n",
    "            cat_features=cat_features_indices,\n",
    "            random_seed=42,\n",
    "            verbose=0,\n",
    "            scale_pos_weight=w     # [í•µì‹¬] ì‚¬ê¸° ë°ì´í„° ê°€ì¤‘ì¹˜\n",
    "        )\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # ì˜ˆì¸¡\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # PR Curve ê³„ì‚°\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        # ëª©í‘œ: Recall >= 0.97 ì¸ ì§€ì  ì¤‘ Precision ìµœëŒ€ê°’ ì°¾ê¸°\n",
    "        # recallsëŠ” ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ë˜ì–´ ìˆìŒ (1.0 -> 0.0)\n",
    "        # 0.97 ì´ìƒì¸ êµ¬ê°„ ì°¾ê¸°\n",
    "        valid_indices = np.where(recalls[:-1] >= 0.97)[0]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            # Recall 0.97ì„ ë§Œì¡±í•˜ëŠ” êµ¬ê°„ ì¤‘ì—ì„œ Precisionì´ ê°€ì¥ ë†’ì€ ì§€ì \n",
    "            # (ë³´í†µì€ Recallì´ 0.97ì— ê°€ê¹Œìš¸ìˆ˜ë¡(Thresholdê°€ ë†’ì„ìˆ˜ë¡) Precisionì´ ë†’ìŒ)\n",
    "            best_idx = valid_indices[np.argmax(precisions[valid_indices])]\n",
    "            \n",
    "            target_recall = recalls[best_idx]\n",
    "            target_prec = precisions[best_idx]\n",
    "            target_th = thresholds[best_idx]\n",
    "            \n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"{d:<6} | {w:<6} | {target_recall:<10.4f} | {target_prec:<10.4f} | {target_th:<10.6f} | {elapsed:.1f}s\")\n",
    "            \n",
    "            # ìµœê³  ê¸°ë¡ ê°±ì‹  (Recall 97% ì¡°ê±´ í•˜ì—ì„œ Precisionì´ ë†’ì€ ìˆœ)\n",
    "            if target_prec > best_patrol['precision_at_97']:\n",
    "                best_patrol['precision_at_97'] = target_prec\n",
    "                best_patrol['recall'] = target_recall\n",
    "                best_patrol['threshold'] = target_th\n",
    "                best_patrol['params'] = params\n",
    "                best_patrol['model'] = model\n",
    "        else:\n",
    "            print(f\"{d:<6} | {w:<6} | {'Recall 97% ë¶ˆê°€':<20} | {time.time()-start_time:.1f}s\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼\n",
    "print(\"-\" * 75)\n",
    "if best_patrol['model']:\n",
    "    print(\"ğŸ† Best Tier 2 Model Candidate Found!\")\n",
    "    print(f\"Params      : Depth {best_patrol['params']['depth']}, Weight {best_patrol['params']['weight']}\")\n",
    "    print(f\"Recall      : {best_patrol['recall']:.4f} (Target >= 0.97)\")\n",
    "    print(f\"Precision   : {best_patrol['precision_at_97']:.4f}\")\n",
    "    print(f\"Threshold   : {best_patrol['threshold']:.8f}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥ (ì„ì‹œ)\n",
    "    best_patrol['model'].save_model(\"temp_tier2_candidate.cbm\")\n",
    "else:\n",
    "    print(\"âš ï¸ Recall 97%ë¥¼ ë‹¬ì„±í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê°€ì¤‘ì¹˜(Weight)ë¥¼ ë” ë†’ì—¬ì•¼ í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38038c45",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 17\n",
    "\n",
    "CatBoostë¥¼ í†µí•´ F1-Scoreê°€ ê°€ì¥ ë†’ì€ êµ¬ê°„ì„ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ Recallì´ 97%ê°€ ì•„ë‹Œ 90% ì´ìƒìœ¼ë¡œ ì¡ì•˜ì„ ë• ì–´ë–¤ ê²½í–¥ì„ ë³´ì¼ì§€ ê°™ì´ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "Params      : Depth 6, Weight 1\n",
    "\n",
    "Max F1      : 0.7873\n",
    "\n",
    "Recall      : 0.7121\n",
    "\n",
    "Precision   : 0.8804\n",
    "\n",
    "Threshold   : 0.98042169\n",
    "\n",
    "\n",
    "Recall 90% ê°•ì œ ì‹œ ì˜ˆìƒ ì„±ì :\n",
    "   - Precision : 0.2289\n",
    "   - Threshold : 0.540976\n",
    "\n",
    "í˜„ ìƒí™©ì—ì„œ 90% ì´ìƒì˜ ê·¹ì ì¸ Recallì„ ëŒì–´ë‚´ê¸´ ì–´ë µë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "358131b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Tier 2 (Patrol) F1-Score Search ì‹œì‘...\n",
      "-------------------------------------------------------------------------------------\n",
      "Depth  | Weight | Max F1     | Recall     | Precision  | Threshold  | Time    \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 1      | 0.7873     | 0.7121     | 0.8804     | 0.980422   | 43.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 3      | 0.7771     | 0.7001     | 0.8731     | 0.990942   | 44.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 1      | 0.7843     | 0.7110     | 0.8744     | 0.988051   | 65.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 3      | 0.7822     | 0.6983     | 0.8889     | 0.994440   | 66.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10     | 1      | 0.7738     | 0.7088     | 0.8520     | 0.994151   | 125.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10     | 3      | 0.7707     | 0.6860     | 0.8793     | 0.998135   | 127.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12     | 1      | 0.7621     | 0.6940     | 0.8452     | 0.997377   | 308.0s\n",
      "-------------------------------------------------------------------------------------\n",
      "ğŸ† Best Tier 2 Model (Balanced) Found!\n",
      "Params      : Depth 6, Weight 1\n",
      "Max F1      : 0.7873\n",
      "Recall      : 0.7121\n",
      "Precision   : 0.8804\n",
      "Threshold   : 0.98042169\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: best_tier2_depth6_f1_78.cbm\n",
      "\n",
      "ğŸ” [ì‹¬ì¸µ ë¶„ì„] Recall 90% ê°•ì œ ì‹œ ì˜ˆìƒ ì„±ì :\n",
      "   - Precision : 0.2289\n",
      "   - Threshold : 0.540976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "\n",
    "# [ì „ì œ] X_resampled, y_resampled, X_test, y_test ì¤€ë¹„ë¨\n",
    "# [ì „ì œ] cat_features_indices ì •ì˜ë¨\n",
    "\n",
    "# íƒìƒ‰ ê·¸ë¦¬ë“œ\n",
    "# ê°€ì¤‘ì¹˜ë¥¼ ë„ˆë¬´ ë†’ì´ë©´(5 ì´ìƒ) ì •ë°€ë„ê°€ ë§ê°€ì§€ë‹ˆ 1~3 ìœ„ì£¼ë¡œ ë³´ê³ , \n",
    "# ê¹Šì´ë„ ë‹¤ì–‘í•˜ê²Œ ë´…ë‹ˆë‹¤.\n",
    "grid_params = [\n",
    "    {'depth': 6, 'weight': 1}, {'depth': 6, 'weight': 3}, \n",
    "    {'depth': 8, 'weight': 1}, {'depth': 8, 'weight': 3}, \n",
    "    {'depth': 10, 'weight': 1}, {'depth': 10, 'weight': 3},\n",
    "    {'depth': 12, 'weight': 1} # ê¹Šì€ ëª¨ë¸ í•˜ë‚˜ ì¶”ê°€\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"ğŸš€ Tier 2 (Patrol) F1-Score Search ì‹œì‘...\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"{'Depth':<6} | {'Weight':<6} | {'Max F1':<10} | {'Recall':<10} | {'Precision':<10} | {'Threshold':<10} | {'Time':<8}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "best_patrol = {\n",
    "    'f1': 0,\n",
    "    'recall': 0,\n",
    "    'precision': 0,\n",
    "    'threshold': 0,\n",
    "    'params': {},\n",
    "    'model': None\n",
    "}\n",
    "\n",
    "for params in grid_params:\n",
    "    d = params['depth']\n",
    "    w = params['weight']\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=1500,       # ì¶©ë¶„í•œ í•™ìŠµ\n",
    "            depth=d,\n",
    "            learning_rate=0.05,    # ì •ë°€ë„ í–¥ìƒì„ ìœ„í•´ 0.1 -> 0.05ë¡œ ë³µê·€\n",
    "            task_type=\"GPU\",\n",
    "            eval_metric='AUC',\n",
    "            cat_features=cat_features_indices,\n",
    "            random_seed=42,\n",
    "            verbose=0,\n",
    "            scale_pos_weight=w\n",
    "        )\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # PR Curve\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        # F1 Score ê³„ì‚° (ëª¨ë“  ì„ê³„ê°’ì— ëŒ€í•´)\n",
    "        # ë¶„ëª¨ 0 ë°©ì§€\n",
    "        denom = precisions[:-1] + recalls[:-1]\n",
    "        denom[denom == 0] = 1 \n",
    "        f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / denom\n",
    "        \n",
    "        # Max F1 ì§€ì  ì°¾ê¸°\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        \n",
    "        max_f1 = f1_scores[best_idx]\n",
    "        best_recall = recalls[best_idx]\n",
    "        best_prec = precisions[best_idx]\n",
    "        best_th = thresholds[best_idx]\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"{d:<6} | {w:<6} | {max_f1:<10.4f} | {best_recall:<10.4f} | {best_prec:<10.4f} | {best_th:<10.6f} | {elapsed:.1f}s\")\n",
    "        \n",
    "        results.append({\n",
    "            'depth': d, 'weight': w, 'f1': max_f1, \n",
    "            'recall': best_recall, 'precision': best_prec, 'threshold': best_th\n",
    "        })\n",
    "        \n",
    "        # ìµœê³  ê¸°ë¡ ê°±ì‹  (F1 ê¸°ì¤€)\n",
    "        if max_f1 > best_patrol['f1']:\n",
    "            best_patrol['f1'] = max_f1\n",
    "            best_patrol['recall'] = best_recall\n",
    "            best_patrol['precision'] = best_prec\n",
    "            best_patrol['threshold'] = best_th\n",
    "            best_patrol['params'] = params\n",
    "            best_patrol['model'] = model\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# ê²°ê³¼ ì •ë ¬ ë° ì¶œë ¥\n",
    "print(\"-\" * 85)\n",
    "if best_patrol['model']:\n",
    "    print(\"ğŸ† Best Tier 2 Model (Balanced) Found!\")\n",
    "    print(f\"Params      : Depth {best_patrol['params']['depth']}, Weight {best_patrol['params']['weight']}\")\n",
    "    print(f\"Max F1      : {best_patrol['f1']:.4f}\")\n",
    "    print(f\"Recall      : {best_patrol['recall']:.4f}\")\n",
    "    print(f\"Precision   : {best_patrol['precision']:.4f}\")\n",
    "    print(f\"Threshold   : {best_patrol['threshold']:.8f}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    save_path = f\"best_tier2_depth{best_patrol['params']['depth']}_f1_{int(best_patrol['f1']*100)}.cbm\"\n",
    "    best_patrol['model'].save_model(save_path)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "    \n",
    "    # ì¶”ê°€ ë¶„ì„: Recall 90% ì´ìƒì¼ ë•Œì˜ Precision í™•ì¸ (Jackpot ê°€ëŠ¥ì„± ì²´í¬)\n",
    "    # í˜„ì¬ ìµœê³  ëª¨ë¸ë¡œ ë‹¤ì‹œ ì˜ˆì¸¡\n",
    "    final_prob = best_patrol['model'].predict_proba(X_test)[:, 1]\n",
    "    p, r, t = precision_recall_curve(y_test, final_prob)\n",
    "    \n",
    "    # Recall 0.9 ê·¼ì²˜ ì°¾ê¸°\n",
    "    idx_90 = np.where(r[:-1] >= 0.90)[0]\n",
    "    if len(idx_90) > 0:\n",
    "        # ê·¸ ì¤‘ Precision ìµœëŒ€ê°’\n",
    "        best_idx_90 = idx_90[np.argmax(p[idx_90])]\n",
    "        print(f\"\\nğŸ” [ì‹¬ì¸µ ë¶„ì„] Recall 90% ê°•ì œ ì‹œ ì˜ˆìƒ ì„±ì :\")\n",
    "        print(f\"   - Precision : {p[best_idx_90]:.4f}\")\n",
    "        print(f\"   - Threshold : {t[best_idx_90]:.6f}\")\n",
    "    else:\n",
    "        print(\"\\nğŸ” Recall 90% ë„ë‹¬ ë¶ˆê°€ëŠ¥\")\n",
    "else:\n",
    "    print(\"âš ï¸ ëª¨ë¸ íƒìƒ‰ ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7448e6c3",
   "metadata": {},
   "source": [
    "# 5ì°¨ ë°ì´í„° ì •ì œ\n",
    "\n",
    "IsolationForestë¥¼ ì´ìš©í•´ \"ì´ìƒì¹˜\"ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì—¬ ëª¨ë¸ì´ í•™ìŠµí•˜ëŠ” ë° ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ ë°ì´í„°ë¥¼ ì •ì œí•©ë‹ˆë‹¤.\n",
    "\n",
    "ì¶”ê°€ëœ 'anomaly_score'ì»¬ëŸ¼ì€ ìˆ˜ì¹˜ê°€ ë†’ì„ìˆ˜ë¡ \"íŠ¹ì´í•œ\" ê±°ë˜ë¼ëŠ” ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd4df89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Isolation Forest (Anomaly Detector) í•™ìŠµ ì‹œì‘...\n",
      "âœ… Anomaly Score ìƒì„± ì™„ë£Œ! (Mean: -0.0812, Max: 0.2725)\n",
      "   ã„´ ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ 'íŠ¹ì´í•œ ê±°ë˜'ì…ë‹ˆë‹¤.\n",
      "New Dataset Ready: (121462, 19) (anomaly_score included)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Isolation Forestìš© ë°ì´í„° ì¤€ë¹„ (ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì‚¬ìš©)\n",
    "# ë²”ì£¼í˜•(ë¬¸ìì—´)ì€ ì›-í•« ì¸ì½”ë”© ì—†ì´ëŠ” IsoForestì—ì„œ ì“°ê¸° í˜ë“œë¯€ë¡œ, \n",
    "# ê°•ë ¥í•œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜(Velocity, Amount ë“±)ë§Œ ì¶”ë ¤ì„œ ì´ìƒì¹˜ë¥¼ ì¡ìŠµë‹ˆë‹¤.\n",
    "iso_features = [\n",
    "    'amount', 'utilization_ratio', 'amount_income_ratio', \n",
    "    'time_diff_seconds', 'count_24h', 'sum_amt_1h',\n",
    "    'pin_years_gap', 'current_age', 'credit_score'\n",
    "]\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (Isolation ForestëŠ” NaNì„ ì‹«ì–´í•¨)\n",
    "# df_raw_catì€ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì…ë‹ˆë‹¤.\n",
    "X_iso = df_raw_cat[iso_features].fillna(0)\n",
    "\n",
    "print(\"ğŸš€ Isolation Forest (Anomaly Detector) í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "# 2. ëª¨ë¸ í•™ìŠµ (ë¹„ì§€ë„ í•™ìŠµì´ë¯€ë¡œ yê°’ í•„ìš” ì—†ìŒ)\n",
    "# contamination='auto'ë¡œ ë‘ë©´ ì•Œì•„ì„œ íŒë‹¨í•©ë‹ˆë‹¤.\n",
    "iso_model = IsolationForest(\n",
    "    n_estimators=100, \n",
    "    max_samples='auto', \n",
    "    contamination='auto', \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ì£¼ì˜: Data Leakage ë°©ì§€ë¥¼ ìœ„í•´ ì›ì¹™ì ìœ¼ë¡œëŠ” Train setì—ë§Œ fit í•´ì•¼ í•˜ì§€ë§Œ,\n",
    "# ì´ìƒì¹˜ íƒì§€ëŠ” ì „ì²´ ë¶„í¬ë¥¼ ì•„ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë¯€ë¡œ ì „ì²´ì— ëŒ€í•´ ì ìˆ˜ë¥¼ ë§¤ê¸°ëŠ” ê²½ìš°ë„ ë§ìŠµë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” ì—„ë°€í•¨ì„ ìœ„í•´ fitì€ ì „ì²´ ë°ì´í„°ì˜ ì¼ë¶€(ë˜ëŠ” Train)ë¡œ í•˜ê³  scoreëŠ” ì „ì²´ì— ë§¤ê¹ë‹ˆë‹¤.\n",
    "iso_model.fit(X_iso)\n",
    "\n",
    "# 3. Anomaly Score ì¶”ì¶œ (ì´ê²ƒì´ ìƒˆë¡œìš´ Featureê°€ ë©ë‹ˆë‹¤!)\n",
    "# decision_function: ë‚®ì„ìˆ˜ë¡ ì´ìƒì¹˜(Anomaly), ë†’ì„ìˆ˜ë¡ ì •ìƒ\n",
    "# ìš°ë¦¬ëŠ” \"ì´ìƒí• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜\"ê°€ ì¢‹ìœ¼ë¯€ë¡œ ë¶€í˜¸ë¥¼ ë°˜ëŒ€ë¡œ ë’¤ì§‘ìŠµë‹ˆë‹¤.\n",
    "anomaly_scores = -iso_model.decision_function(X_iso)\n",
    "\n",
    "# ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "df_raw_cat['anomaly_score'] = anomaly_scores\n",
    "\n",
    "print(f\"âœ… Anomaly Score ìƒì„± ì™„ë£Œ! (Mean: {anomaly_scores.mean():.4f}, Max: {anomaly_scores.max():.4f})\")\n",
    "print(\"   ã„´ ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ 'íŠ¹ì´í•œ ê±°ë˜'ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# ì´ì œ ìƒˆë¡œìš´ Featureê°€ ì¶”ê°€ëœ df_raw_catìœ¼ë¡œ ë‹¤ì‹œ ë°ì´í„°ì…‹ ë¶„í• \n",
    "# -----------------------------------------------------------\n",
    "X = df_raw_cat.drop('is_fraud', axis=1)\n",
    "y = df_raw_cat['is_fraud']\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "cat_features_indices = ['mcc', 'merchant_state', 'zip', 'use_chip', 'card_brand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Undersampling ë‹¤ì‹œ ìˆ˜í–‰ (ìƒˆë¡œìš´ ì»¬ëŸ¼ í¬í•¨)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"New Dataset Ready: {X_resampled.shape} (anomaly_score included)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f89e5",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 18\n",
    "\n",
    "\"ì´ìƒ ì²™ë„\"ë¥¼ ì¶”ê°€í•œ ë°ì´í„° ì¦ê°• ì „ëµ CatBoost í•™ìŠµ\n",
    "\n",
    "Depth  | Max F1     | Recall     | Precision  | Threshold  | Rec@0.9   \n",
    "\n",
    "6      | 0.7869     | 0.6961     | 0.9049     | 0.984723   | 0.2249\n",
    "\n",
    "8      | 0.7787     | 0.7117     | 0.8596     | 0.986265   | 0.2124\n",
    "\n",
    "10     | 0.7730     | 0.7048     | 0.8558     | 0.994004   | 0.2083\n",
    "\n",
    "í° ë³€í™”ëŠ” ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì•Œê³ ë¦¬ì¦˜ êµì²´ê°€ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57dbd7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Tier 2 (Patrol + Anomaly Score) Search ì‹œì‘...\n",
      "-------------------------------------------------------------------------------------\n",
      "Depth  | Weight | Max F1     | Recall     | Precision  | Threshold  | Rec@0.9   \n",
      "-------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 1      | 0.7869     | 0.6961     | 0.9049     | 0.984723   | 0.2249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 1      | 0.7787     | 0.7117     | 0.8596     | 0.986265   | 0.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10     | 1      | 0.7730     | 0.7048     | 0.8558     | 0.994004   | 0.2083\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# ì•„ê¹Œì™€ ë™ì¼í•œ ê·¸ë¦¬ë“œì§€ë§Œ, ë°ì´í„°(X)ê°€ ì—…ê·¸ë ˆì´ë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "grid_params = [\n",
    "    {'depth': 6, 'weight': 1}, \n",
    "    {'depth': 8, 'weight': 1}, \n",
    "    {'depth': 10, 'weight': 1} \n",
    "]\n",
    "\n",
    "print(\"ğŸš€ Tier 2 (Patrol + Anomaly Score) Search ì‹œì‘...\")\n",
    "print(\"-\" * 85)\n",
    "print(f\"{'Depth':<6} | {'Weight':<6} | {'Max F1':<10} | {'Recall':<10} | {'Precision':<10} | {'Threshold':<10} | {'Rec@0.9':<10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "for params in grid_params:\n",
    "    d = params['depth']\n",
    "    w = params['weight']\n",
    "    \n",
    "    try:\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=1500,\n",
    "            depth=d,\n",
    "            learning_rate=0.05,\n",
    "            task_type=\"GPU\",\n",
    "            eval_metric='AUC',\n",
    "            cat_features=cat_features_indices, # ì›ë³¸ ë²”ì£¼í˜• + anomaly_score(ìˆ˜ì¹˜í˜•) ìë™ ì²˜ë¦¬\n",
    "            random_seed=42,\n",
    "            verbose=0,\n",
    "            scale_pos_weight=w\n",
    "        )\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # F1 Max ì§€ì  ì°¾ê¸°\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        denom = precisions[:-1] + recalls[:-1]\n",
    "        denom[denom == 0] = 1 \n",
    "        f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / denom\n",
    "        \n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        \n",
    "        # Recall 90% ì¼ë•Œ Precision í™•ì¸ (Rec@0.9)\n",
    "        idx_90 = np.where(recalls[:-1] >= 0.90)[0]\n",
    "        prec_at_90 = precisions[idx_90[np.argmax(precisions[idx_90])]] if len(idx_90) > 0 else 0\n",
    "        \n",
    "        print(f\"{d:<6} | {w:<6} | {f1_scores[best_idx]:<10.4f} | {recalls[best_idx]:<10.4f} | {precisions[best_idx]:<10.4f} | {thresholds[best_idx]:<10.6f} | {prec_at_90:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016fe37",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 19\n",
    "\n",
    "Soft Votingì„ í†µí•œ CatBoost, RandomForest, LogisticRegressionì˜ ì•™ìƒë¸” í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì„œë¡œ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ì˜ íŒë‹¨ê²°ê³¼ë¥¼ ì¡°í•©í•œ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì´ F1-scoreì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "[Max F1 Score Point]\n",
    "   - F1-Score : 0.1252\n",
    "   - Recall   : 0.1181\n",
    "   - Precision: 0.1332\n",
    "   - Threshold: 0.910567\n",
    "\n",
    "[Target Check] Recall 90% ì§€ì \n",
    "   - Precision: 0.0044\n",
    "   - Threshold: 0.292928\n",
    "\n",
    "ì•„ì£¼ ì¢‹ì§€ ëª»í•œ ê²°ê³¼ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤. ë°ì´í„°ì— ëŒ€í•œ ì‹œê°ì„ ì´ˆê¸°í™” í•  ì‹œì ì´ ì˜¨ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc3a84d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Operation Trinity (Ensemble Voting) ì‹œì‘...\n",
      "   ã„´ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì‚¬ìš© (14ê°œ) for RF/LR compatibility\n",
      "ğŸ§¹ ë°ì´í„° ì •ì œ ì¤‘ (Removing Inf/NaN)...\n",
      "âœ… ì •ì œ ì™„ë£Œ. ë‹¤ì‹œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "ğŸš€ Operation Trinity (Ensemble Voting) ì¬ì‹œì‘...\n",
      "--------------------------------------------------\n",
      "ğŸ“Š Trinity Ensemble ê²°ê³¼ ë¶„ì„\n",
      "--------------------------------------------------\n",
      "ğŸ† Best Balance Point (Max F1)\n",
      "   - F1-Score : 0.1252\n",
      "   - Recall   : 0.1181\n",
      "   - Precision: 0.1332\n",
      "   - Threshold: 0.910567\n",
      "\n",
      "ğŸ” [Target Check] Recall 90% ì§€ì \n",
      "   - Precision: 0.0044\n",
      "   - Threshold: 0.292928\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# [ì „ì œ] X_resampled, y_resampled, X_test, y_test ì¤€ë¹„ë¨\n",
    "# (df_raw_cat ê¸°ë°˜, anomaly_score í¬í•¨)\n",
    "\n",
    "print(\"ğŸš€ Operation Trinity (Ensemble Voting) ì‹œì‘...\")\n",
    "\n",
    "# 1. ê°œë³„ ëª¨ë¸ ì •ì˜\n",
    "# (1) CatBoost (ìš°ë¦¬ê°€ ì¼ë˜ ê·¸ ëª¨ë¸)\n",
    "clf1 = CatBoostClassifier(\n",
    "    iterations=1000, depth=8, learning_rate=0.05,\n",
    "    cat_features=cat_features_indices,\n",
    "    verbose=0, random_seed=42,\n",
    "    scale_pos_weight=3 # Recallì„ ìœ„í•´ ê°€ì¤‘ì¹˜ë¥¼ ì¤Œ\n",
    ")\n",
    "\n",
    "# (2) RandomForest (CatBoostì™€ ì •ë°˜ëŒ€ ì„±í–¥: Bagging)\n",
    "# RFëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ë°”ë¡œ ëª» ë°›ìœ¼ë¯€ë¡œ, ì›-í•« ì¸ì½”ë”©ì´ í•„ìš”í•˜ì§€ë§Œ \n",
    "# ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì“°ê±°ë‚˜, CatBoostê°€ ì²˜ë¦¬í•œ ë°ì´í„°ë¥¼ ì“°ë©´ ì¢‹ê² ì§€ë§Œ\n",
    "# sklearn RFëŠ” ë¬¸ìì—´ì„ ëª» ë°›ìœ¼ë¯€ë¡œ, ì¼ë‹¨ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì œì™¸í•˜ê±°ë‚˜ ì¸ì½”ë”©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# -> [ê¸´ê¸‰] RFì™€ LRì„ ìœ„í•´ ë¬¸ìì—´ ì»¬ëŸ¼ì„ ì œì™¸í•˜ê³  ìˆ˜ì¹˜í˜•ë§Œ ì“°ëŠ” ì „ëµìœ¼ë¡œ ê°‘ë‹ˆë‹¤.\n",
    "#    (ì–´ì°¨í”¼ anomaly_scoreì™€ velocityê°€ í•µì‹¬ì´ë¯€ë¡œ)\n",
    "\n",
    "numeric_cols = X_resampled.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"   ã„´ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì‚¬ìš© ({len(numeric_cols)}ê°œ) for RF/LR compatibility\")\n",
    "\n",
    "# ìˆ˜ì¹˜í˜• ë°ì´í„°ì…‹ ë³„ë„ ìƒì„±\n",
    "X_res_num = X_resampled[numeric_cols]\n",
    "X_test_num = X_test[numeric_cols]\n",
    "\n",
    "# (1-Revised) CatBoostë„ ê³µí‰í•˜ê²Œ ìˆ˜ì¹˜í˜•ë§Œ (ì´ë¯¸ ê°•ë ¥í•¨)\n",
    "clf1 = CatBoostClassifier(\n",
    "    iterations=1000, depth=8, learning_rate=0.05,\n",
    "    verbose=0, random_seed=42, scale_pos_weight=3\n",
    ")\n",
    "\n",
    "# (2) RandomForest\n",
    "clf2 = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=12, \n",
    "    n_jobs=-1, random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "# (3) Logistic Regression (ë‹¨ìˆœ ì„ í˜• ë¶„ë¦¬, ê³¼ì í•© ë°©ì§€)\n",
    "clf3 = LogisticRegression(\n",
    "    solver='liblinear', random_state=42, class_weight='balanced'\n",
    ")\n",
    "\n",
    "# 2. Voting Classifier ì •ì˜ (Soft Voting)\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('cat', clf1), ('rf', clf2), ('lr', clf3)],\n",
    "    voting='soft', weights=[2, 1, 1] # CatBoostì— 2ë°° ì‹ ë¢°\n",
    ")\n",
    "\n",
    "# [Bug Fix] ë¬´í•œëŒ€(inf) ë° ê²°ì¸¡ì¹˜(NaN) ì œê±°\n",
    "# RandomForestì™€ LogisticRegressionì„ ìœ„í•´ í•„ìˆ˜ì ì¸ ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "print(\"ğŸ§¹ ë°ì´í„° ì •ì œ ì¤‘ (Removing Inf/NaN)...\")\n",
    "\n",
    "# 1. ë¬´í•œëŒ€(inf)ë¥¼ NaNìœ¼ë¡œ ë³€í™˜\n",
    "X_res_num = X_res_num.replace([np.inf, -np.inf], np.nan)\n",
    "X_test_num = X_test_num.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 2. NaNì„ 0ìœ¼ë¡œ ì±„ì›€ (ë˜ëŠ” í‰ê· ê°’ìœ¼ë¡œ ì±„ì›Œë„ ë¨)\n",
    "# ì—¬ê¸°ì„œëŠ” 0ìœ¼ë¡œ ì±„ìš°ëŠ” ê²ƒì´ 'ì •ë³´ ì—†ìŒ'ì„ í‘œí˜„í•˜ê¸°ì— ì•ˆì „í•¨\n",
    "X_res_num = X_res_num.fillna(0)\n",
    "X_test_num = X_test_num.fillna(0)\n",
    "\n",
    "print(\"âœ… ì •ì œ ì™„ë£Œ. ë‹¤ì‹œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. í•™ìŠµ ì¬ì‹œë„ (Trinity Ensemble)\n",
    "# -------------------------------------------------------\n",
    "print(\"ğŸš€ Operation Trinity (Ensemble Voting) ì¬ì‹œì‘...\")\n",
    "eclf.fit(X_res_num, y_resampled)\n",
    "\n",
    "# 4. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_prob = eclf.predict_proba(X_test_num)[:, 1]\n",
    "\n",
    "# PR Curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# 5. ì„±ê³¼ ë¶„ì„\n",
    "print(\"-\" * 50)\n",
    "print(\"ğŸ“Š Trinity Ensemble ê²°ê³¼ ë¶„ì„\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# (1) Max F1 ì§€ì \n",
    "denom = precisions[:-1] + recalls[:-1]\n",
    "denom[denom == 0] = 1 \n",
    "f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / denom\n",
    "\n",
    "best_idx = np.argmax(f1_scores)\n",
    "print(f\"ğŸ† Best Balance Point (Max F1)\")\n",
    "print(f\"   - F1-Score : {f1_scores[best_idx]:.4f}\")\n",
    "print(f\"   - Recall   : {recalls[best_idx]:.4f}\")\n",
    "print(f\"   - Precision: {precisions[best_idx]:.4f}\")\n",
    "print(f\"   - Threshold: {thresholds[best_idx]:.6f}\")\n",
    "\n",
    "# (2) Recall 90% ì§€ì  ê°•ì œ í™•ì¸\n",
    "idx_90 = np.where(recalls[:-1] >= 0.90)[0]\n",
    "if len(idx_90) > 0:\n",
    "    # 90% ì´ìƒì¸ ê²ƒë“¤ ì¤‘ Precisionì´ ê°€ì¥ ë†’ì€ ì§€ì \n",
    "    best_idx_90 = idx_90[np.argmax(precisions[idx_90])]\n",
    "    print(f\"\\nğŸ” [Target Check] Recall 90% ì§€ì \")\n",
    "    print(f\"   - Precision: {precisions[best_idx_90]:.4f}\")\n",
    "    print(f\"   - Threshold: {thresholds[best_idx_90]:.6f}\")\n",
    "else:\n",
    "    print(\"\\nğŸ” Recall 90% ë„ë‹¬ ë¶ˆê°€ëŠ¥\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321adbff",
   "metadata": {},
   "source": [
    "# 6ì°¨ ë°ì´í„° ì •ì œ\n",
    "\n",
    "ë°ì´í„°ì˜ ì°¨ì›ì„ ì¤„ì´ëŠ”ë° ì§‘ì¤‘í•˜ì—¬ ìµœëŒ€í•œ í•µì‹¬ ì •ë³´ë§Œ ë‚¨ê¸°ëŠ” ë°©í–¥ìœ¼ë¡œ ì •ì œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d20cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading Raw Data...\n",
      "â³ Cleaning Data...\n",
      "â³ Merging Data...\n",
      "â³ Engineering Features...\n",
      "âœ… New Dataset Ready: (8914963, 14)\n",
      "   amount  utilization_ratio  mcc_risk  zip_risk  merchant_state_risk  \\\n",
      "0   66.00           0.001947  0.000134       0.0             0.000139   \n",
      "1   94.58           0.002790  0.000134       0.0             0.000139   \n",
      "2   19.20           0.000566  0.000181       0.0             0.000139   \n",
      "3   49.64           0.001464  0.000817       0.0             0.000168   \n",
      "4   16.20           0.000478  0.000181       0.0             0.000168   \n",
      "\n",
      "   tech_mismatch  pin_years_gap  time_diff_seconds  count_24h  hour  is_night  \\\n",
      "0              1              5           999999.0        1.0     7         0   \n",
      "1              1              5              600.0        2.0     7         0   \n",
      "2              1              5            15480.0        3.0    11         0   \n",
      "3              1              5            23040.0        4.0    17         0   \n",
      "4              1              5            62640.0        3.0    11         0   \n",
      "\n",
      "   current_age  credit_score  is_fraud  \n",
      "0           58           727         0  \n",
      "1           58           727         0  \n",
      "2           58           727         0  \n",
      "3           58           727         0  \n",
      "4           58           727         0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ (ê²½ë¡œëŠ” ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
    "print(\"â³ Loading Raw Data...\")\n",
    "# transactions_dataëŠ” ë¡œì»¬ì— ìˆëŠ” ì›ë³¸ íŒŒì¼ì„ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "trans = pd.read_csv('data/transactions_data.csv') \n",
    "users = pd.read_csv('data/users_data.csv')\n",
    "cards = pd.read_csv('data/cards_data.csv')\n",
    "labels = pd.read_csv('data/train_fraud_labels.csv')\n",
    "\n",
    "# 2. ê¸°ì´ˆ ì •ì œ (Cleaning)\n",
    "def clean_currency(x):\n",
    "    if isinstance(x, str):\n",
    "        return float(x.replace('$', '').replace(',', ''))\n",
    "    return x\n",
    "\n",
    "print(\"â³ Cleaning Data...\")\n",
    "# ê¸ˆì•¡ ê´€ë ¨ ì»¬ëŸ¼ ì •ì œ\n",
    "users['yearly_income'] = users['yearly_income'].apply(clean_currency)\n",
    "cards['credit_limit'] = cards['credit_limit'].apply(clean_currency)\n",
    "trans['amount'] = trans['amount'].apply(clean_currency)\n",
    "trans['amount'] = trans['amount'].abs() # ì ˆëŒ€ê°’ ì²˜ë¦¬\n",
    "\n",
    "# ë‚ ì§œ ë³€í™˜\n",
    "trans['date_obj'] = pd.to_datetime(trans['date'])\n",
    "\n",
    "# 3. ë°ì´í„° ë³‘í•© (Merging)\n",
    "print(\"â³ Merging Data...\")\n",
    "# Trans + Labels (Target)\n",
    "df = pd.merge(trans, labels, on='id', how='inner')\n",
    "# Target ë³€í™˜ (Yes/No -> 1/0)\n",
    "df['is_fraud'] = df['target'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "df = df.drop(columns=['target'])\n",
    "\n",
    "# + Users (client_id)\n",
    "users = users.rename(columns={'id':'client_id'})\n",
    "df = pd.merge(df, users, on='client_id', how='left')\n",
    "\n",
    "# + Cards (card_id)\n",
    "cards = cards.rename(columns={'id':'card_id'})\n",
    "df = pd.merge(df, cards, on=['card_id', 'client_id'], how='left')\n",
    "\n",
    "# 4. Feature Engineering (Reloaded)\n",
    "print(\"â³ Engineering Features...\")\n",
    "\n",
    "# [Feature 1] MCC & Zip Risk (Target Encoding) - â˜… í•µì‹¬ ë¶€í™œ\n",
    "# ë²”ì£¼í˜• ë°ì´í„°ë¥¼ 'ì‚¬ê¸° í™•ë¥ ' ì ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "for col in ['mcc', 'zip', 'merchant_state']:\n",
    "    # ê²°ì¸¡ì¹˜ëŠ” ë³„ë„ ì¹´í…Œê³ ë¦¬ë¡œ\n",
    "    df[col] = df[col].fillna('Unknown')\n",
    "    # Train ë°ì´í„° ê¸°ì¤€ì˜ Risk Map ìƒì„± (Data Leakage ì£¼ì˜: ì—¬ê¸°ì„  ì „ì²´ë¡œ ê°„ì†Œí™”)\n",
    "    risk_map = df.groupby(col)['is_fraud'].mean()\n",
    "    df[f'{col}_risk'] = df[col].map(risk_map)\n",
    "    # ì²˜ìŒ ë³´ëŠ” ê°’ì€ í‰ê· ìœ¼ë¡œ ëŒ€ì²´\n",
    "    df[f'{col}_risk'] = df[f'{col}_risk'].fillna(df['is_fraud'].mean())\n",
    "\n",
    "# [Feature 2] Tech Mismatch (ì‘ì„±ìë‹˜ ì˜ê²¬ ë°˜ì˜)\n",
    "df['use_chip'] = df['use_chip'].fillna('Unknown')\n",
    "df['has_chip'] = df['has_chip'].fillna('Unknown')\n",
    "\n",
    "def check_tech_mismatch(row):\n",
    "    if row['use_chip'] == 'Online Transaction':\n",
    "        return 0\n",
    "    # ì¹©ì´ ìˆëŠ”ë°(YES) êµ³ì´ ê¸ì—ˆë‹¤(Swipe)? -> ë³µì œ ì˜ì‹¬\n",
    "    if row['has_chip'] == 'YES' and row['use_chip'] == 'Swipe Transaction':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['tech_mismatch'] = df.apply(check_tech_mismatch, axis=1)\n",
    "\n",
    "# [Feature 3] Financial Context (ë¹„ìœ¨ ì •ë³´)\n",
    "# credit_limitê°€ 0ì´ê±°ë‚˜ ê²°ì¸¡ì¹˜ë©´ 1ë¡œ ëŒ€ì²´í•˜ì—¬ ì—ëŸ¬ ë°©ì§€\n",
    "df['credit_limit'] = df['credit_limit'].replace(0, 1).fillna(1)\n",
    "df['utilization_ratio'] = df['amount'] / df['credit_limit']\n",
    "\n",
    "# [Feature 4] Velocity (ì†ë„ ì •ë³´) - â˜… ì„±ëŠ¥ì˜ í•µì‹¬\n",
    "# ë°˜ë“œì‹œ ì‹œê°„ìˆœ ì •ë ¬ í›„ ê³„ì‚°\n",
    "df = df.sort_values(['card_id', 'date_obj'])\n",
    "\n",
    "# ì§ì „ ê±°ë˜ì™€ì˜ ì‹œê°„ ì°¨ì´ (Seconds)\n",
    "df['time_diff_seconds'] = df.groupby('card_id')['date_obj'].diff().dt.total_seconds()\n",
    "df['time_diff_seconds'] = df['time_diff_seconds'].fillna(999999) # ì²« ê±°ë˜ ì²˜ë¦¬\n",
    "\n",
    "# ì§€ë‚œ 24ì‹œê°„ ê±°ë˜ íšŸìˆ˜ (Rolling Count)\n",
    "# rolling ì—°ì‚°ì„ ìœ„í•´ ì¸ë±ìŠ¤ ì„¤ì •\n",
    "df_sorted = df.set_index('date_obj').sort_index()\n",
    "count_24h = df_sorted.groupby('card_id')['amount'].rolling('24h').count().reset_index()\n",
    "# ì¤‘ë³µ ì¸ë±ìŠ¤ ì²˜ë¦¬ (ë™ì‹œê°„ëŒ€ ê±°ë˜)\n",
    "count_24h = count_24h.drop_duplicates(subset=['card_id', 'date_obj'])\n",
    "count_24h.columns = ['card_id', 'date_obj', 'count_24h']\n",
    "\n",
    "# ì›ë³¸ì— ë³‘í•©\n",
    "df = pd.merge(df, count_24h, on=['card_id', 'date_obj'], how='left')\n",
    "\n",
    "# [Feature 5] Additional Context\n",
    "df['hour'] = df['date_obj'].dt.hour\n",
    "df['is_night'] = df['hour'].apply(lambda x: 1 if 0 <= x < 6 else 0)\n",
    "current_year = df['date_obj'].dt.year.max()\n",
    "df['pin_years_gap'] = current_year - df['year_pin_last_changed']\n",
    "\n",
    "# 5. ìµœì¢… ì»¬ëŸ¼ ì„ íƒ (Final Selection)\n",
    "features = [\n",
    "    # (1) í•µì‹¬ ìˆ˜ì¹˜\n",
    "    'amount', 'utilization_ratio',\n",
    "    \n",
    "    # (2) ì¤‘ìš” ë²”ì£¼í˜• Risk (ë¶€í™œ!)\n",
    "    'mcc_risk', 'zip_risk', 'merchant_state_risk',\n",
    "    \n",
    "    # (3) ê¸°ìˆ ì /í–‰ë™ íŒ¨í„´\n",
    "    'tech_mismatch', 'pin_years_gap',\n",
    "    'time_diff_seconds', 'count_24h',\n",
    "    \n",
    "    # (4) ì‹œê°„/í™˜ê²½\n",
    "    'hour', 'is_night',\n",
    "    \n",
    "    # (5) ì‚¬ìš©ì ì •ë³´ (ë³´ì¡°)\n",
    "    'current_age', 'credit_score', # ë‚˜ì´ì™€ ì‹ ìš©ì ìˆ˜ëŠ” ê¸°ë³¸ ë² ì´ìŠ¤ë¼ì¸\n",
    "    \n",
    "    # (6) ì •ë‹µ\n",
    "    'is_fraud'\n",
    "]\n",
    "\n",
    "df_reloaded = df[features].copy()\n",
    "\n",
    "# ë¬´í•œëŒ€/ê²°ì¸¡ì¹˜ ìµœì¢… ì œê±° (ì•ˆì „ì¥ì¹˜)\n",
    "df_reloaded = df_reloaded.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "print(f\"âœ… New Dataset Ready: {df_reloaded.shape}\")\n",
    "print(df_reloaded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5599c4a0",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 20\n",
    "\n",
    "6ì°¨ ì •ì œ ë°ì´í„°ë¥¼ í†µí•œ RandomForestì˜ ë°˜ë³µí•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì°¨ì›ì„ í¬ê²Œ ì¤„ì—¬ ì¤‘ìš”ì •ë³´ë§Œ ë‚¨ê²¼ì„ ë•Œ ë‚®ì€ ì„ê³„ì ì—ì„œ CatBoostë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì´ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "í˜„ì¬ ë°ì´í„°ì…‹ì—ëŠ” CatBoostê°€ ê°€ì¥ ì í•©í•˜ë©°, ì¶”ê°€ì ì¸ ë°ì´í„° ìˆ˜ì§‘ì´ë‚˜ ì™„ì „íˆ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜(ëª¨ë¸)ì„ ì°¾ì§€ ì•ŠëŠ” ì´ìƒ ë”ì´ìƒì˜ ì„±ëŠ¥ í–¥ìƒì€ ì–´ë µë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "CatBoostë¥¼ í†µí•´ ìµœì¢… Tier-2 ëª¨ë¸ì„ ì œì‘í•´ì•¼ í•œë‹¤ëŠ” ê²°ë¡ ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b840653a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Data Split & Undersampling...\n",
      "   ã„´ Train Shape: (117326, 13)\n",
      "   ã„´ Test Shape : (1782993, 13)\n",
      "\n",
      "ğŸš€ RandomForest Patrol Search ì‹œì‘...\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "Depth  | N_Est  | Weight     | Max F1     | Recall     | Precision  | Threshold  | Rec@0.9   \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "5      | 100    | None       | 0.3382     | 0.5120     | 0.2525     | 0.685776   | 0.0682\n",
      "10     | 100    | None       | 0.5489     | 0.4745     | 0.6511     | 0.879641   | 0.1129\n",
      "15     | 100    | None       | 0.6414     | 0.6035     | 0.6844     | 0.887161   | 0.1565\n",
      "20     | 200    | None       | 0.6483     | 0.5956     | 0.7112     | 0.904500   | 0.1786\n",
      "5      | 100    | balanced   | 0.2600     | 0.4629     | 0.1808     | 0.929965   | 0.0485\n",
      "10     | 100    | balanced   | 0.3523     | 0.4842     | 0.2769     | 0.969561   | 0.0845\n",
      "15     | 100    | balanced   | 0.4627     | 0.4640     | 0.4614     | 0.972220   | 0.1051\n",
      "20     | 200    | balanced   | 0.5274     | 0.5023     | 0.5551     | 0.951386   | 0.1304\n",
      "15     | 100    | {0: 1, 1:  | 0.5131     | 0.5030     | 0.5236     | 0.955028   | 0.1241\n",
      "20     | 200    | {0: 1, 1:  | 0.5463     | 0.5263     | 0.5680     | 0.931766   | 0.1486\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "ğŸ† Best RandomForest Model Found!\n",
      "Model Info : Depth20_Est200_WNone\n",
      "Max F1     : 0.6483\n",
      "Rec@0.9    : 0.1786 (Recall 90%ì¼ ë•Œ ì •ë°€ë„)\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: best_rf_f1_64.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 1. ë°ì´í„° ì¤€ë¹„ (df_reloadedê°€ ë©”ëª¨ë¦¬ì— ìˆë‹¤ê³  ê°€ì •)\n",
    "print(\"â³ Data Split & Undersampling...\")\n",
    "\n",
    "X = df_reloaded.drop('is_fraud', axis=1)\n",
    "y = df_reloaded['is_fraud']\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Undersampling (RandomForest ì†ë„ í–¥ìƒ ë° ë¶ˆê· í˜• í•´ì†Œ í•„ìˆ˜)\n",
    "# 10:1 ë¹„ìœ¨ (Normal:Fraud = 10:1)\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"   ã„´ Train Shape: {X_resampled.shape}\")\n",
    "print(f\"   ã„´ Test Shape : {X_test.shape}\")\n",
    "\n",
    "# 2. íƒìƒ‰ ê·¸ë¦¬ë“œ ì„¤ì •\n",
    "grid_params = [\n",
    "    # (1) ê¸°ë³¸ ë°¸ëŸ°ìŠ¤\n",
    "    {'n_est': 100, 'depth': 5, 'weight': None},\n",
    "    {'n_est': 100, 'depth': 10, 'weight': None},\n",
    "    {'n_est': 100, 'depth': 15, 'weight': None},\n",
    "    {'n_est': 200, 'depth': 20, 'weight': None},\n",
    "    \n",
    "    # (2) Balanced (ìë™ ê°€ì¤‘ì¹˜)\n",
    "    {'n_est': 100, 'depth': 5, 'weight': 'balanced'},\n",
    "    {'n_est': 100, 'depth': 10, 'weight': 'balanced'},\n",
    "    {'n_est': 100, 'depth': 15, 'weight': 'balanced'},\n",
    "    {'n_est': 200, 'depth': 20, 'weight': 'balanced'},\n",
    "    \n",
    "    # (3) Custom Weight (Recall ê°•ì œ ë¶€ìŠ¤íŒ…)\n",
    "    {'n_est': 100, 'depth': 15, 'weight': {0:1, 1:5}},\n",
    "    {'n_est': 200, 'depth': 20, 'weight': {0:1, 1:5}},\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ RandomForest Patrol Search ì‹œì‘...\")\n",
    "print(\"-\" * 110)\n",
    "print(f\"{'Depth':<6} | {'N_Est':<6} | {'Weight':<10} | {'Max F1':<10} | {'Recall':<10} | {'Precision':<10} | {'Threshold':<10} | {'Rec@0.9':<10}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "best_rf = {\n",
    "    'f1': 0,\n",
    "    'prec_at_90': 0,\n",
    "    'model': None,\n",
    "    'description': \"\"\n",
    "}\n",
    "\n",
    "for params in grid_params:\n",
    "    d = params['depth']\n",
    "    n = params['n_est']\n",
    "    w = params['weight']\n",
    "    w_str = str(w) if w is not None else \"None\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ëª¨ë¸ ì •ì˜\n",
    "        # n_jobs=-1ë¡œ ë³‘ë ¬ ì²˜ë¦¬ í•„ìˆ˜ (RFëŠ” CPU 100% ì‚¬ìš©)\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n,\n",
    "            max_depth=d,\n",
    "            class_weight=w,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # ì˜ˆì¸¡ (í™•ë¥ )\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # PR Curve ê³„ì‚°\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        # (1) Max F1 ì§€ì  ì°¾ê¸°\n",
    "        denom = precisions[:-1] + recalls[:-1]\n",
    "        denom[denom == 0] = 1 \n",
    "        f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / denom\n",
    "        \n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        \n",
    "        max_f1 = f1_scores[best_idx]\n",
    "        best_recall = recalls[best_idx]\n",
    "        best_prec = precisions[best_idx]\n",
    "        best_th = thresholds[best_idx]\n",
    "        \n",
    "        # (2) Recall 90% ì§€ì ì˜ Precision í™•ì¸ (Jackpot Check)\n",
    "        idx_90 = np.where(recalls[:-1] >= 0.90)[0]\n",
    "        if len(idx_90) > 0:\n",
    "            # 90% ì´ìƒì¸ êµ¬ê°„ ì¤‘ Precisionì´ ê°€ì¥ ë†’ì€ ê³³\n",
    "            best_idx_90 = idx_90[np.argmax(precisions[idx_90])]\n",
    "            prec_at_90 = precisions[best_idx_90]\n",
    "        else:\n",
    "            prec_at_90 = 0.0\n",
    "            \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        # ì¶œë ¥\n",
    "        print(f\"{d:<6} | {n:<6} | {w_str[:10]:<10} | {max_f1:<10.4f} | {best_recall:<10.4f} | {best_prec:<10.4f} | {best_th:<10.6f} | {prec_at_90:.4f}\")\n",
    "        \n",
    "        # ìµœê³  ëª¨ë¸ ì €ì¥ (F1 ê¸°ì¤€, í˜¹ì€ Rec@0.9 ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥)\n",
    "        if max_f1 > best_rf['f1']:\n",
    "            best_rf['f1'] = max_f1\n",
    "            best_rf['prec_at_90'] = prec_at_90\n",
    "            best_rf['model'] = model\n",
    "            best_rf['description'] = f\"Depth{d}_Est{n}_W{w_str}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì €ì¥\n",
    "print(\"-\" * 110)\n",
    "if best_rf['model']:\n",
    "    print(\"ğŸ† Best RandomForest Model Found!\")\n",
    "    print(f\"Model Info : {best_rf['description']}\")\n",
    "    print(f\"Max F1     : {best_rf['f1']:.4f}\")\n",
    "    print(f\"Rec@0.9    : {best_rf['prec_at_90']:.4f} (Recall 90%ì¼ ë•Œ ì •ë°€ë„)\")\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥ (Joblib ì‚¬ìš©)\n",
    "    filename = f\"best_rf_f1_{int(best_rf['f1']*100)}.pkl\"\n",
    "    joblib.dump(best_rf['model'], filename)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filename}\")\n",
    "else:\n",
    "    print(\"âš ï¸ íƒìƒ‰ ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca508f9d",
   "metadata": {},
   "source": [
    "# í•™ìŠµ 21\n",
    "\n",
    "4ì°¨ ì •ì œ ë°ì´í„°ë¥¼ ë‹¤ì‹œ í™œìš©í•˜ì—¬ CatBoost ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "17ì°¨ í•™ìŠµì˜ ê³ ë„í™”ë¡œ, ìµœê³ ì˜ F1-scoreë¥¼ ë³´ì´ëŠ” ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë™ì‹œì— Recall 0.9ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ìµœì„ ì˜ Preciseê°’ì´ ì–¼ë§ˆì¸ì§€ë„ ê²€ì‚¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "17ì°¨ í•™ìŠµì˜ ê²°ê³¼ë¡œ ì˜ˆì¸¡í•œ, F1-scoreì˜ ìµœê³ ì ì´ ì¡´ì¬í•˜ëŠ” depth êµ¬ê°„ì„ ì´˜ì´˜í•˜ê²Œ ìƒˆë¡œ ì •ì˜í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "learning rateë¥¼ ì¶”ê°€ë¡œ ì¡°ì ˆí•˜ì—¬ ìµœì„ ì˜ ëª¨ë¸ì„ íƒìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "\n",
    "Depth : 6, Learning Rate : 0.07\n",
    "\n",
    "Max F1 : 0.7911, Recall : 0.7186, Precision : 0.8798\n",
    "\n",
    "Recallì´ 0.9ì¼ ë•Œì˜ Precision : 0.2380, Threshold : 0.56802705\n",
    "\n",
    "ë‹¤ì–‘í•œ ëª¨ë¸ ì¤‘, ìµœëŒ“ê°’ì˜ F1-Scoreë¥¼ ê°€ì§€ë©´ì„œ ë™ì‹œì— Recall=0.9ì¼ ë•Œë„ ê°€ì¥ ì¢‹ì€ Precisionì„ ë³´ì—¬ì£¼ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìµœì¢…ì ìœ¼ë¡œ ì´ ëª¨ë¸ì„ Tier 2 ëª¨ë¸ë¡œ ì„ ì •í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Final Tier 2 Optimization (Depth 4-8, LR Tuning) ì‹œì‘...\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Depth  | LR     | Max F1     | Recall     | Precision  | Threshold  | Rec@0.9    | Time    \n",
      "-----------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4      | 0.03   | 0.7774     | 0.6968     | 0.8789     | 0.974565   | 0.1937     | 38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4      | 0.05   | 0.7816     | 0.7189     | 0.8563     | 0.969758   | 0.2123     | 31.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4      | 0.07   | 0.7849     | 0.7117     | 0.8749     | 0.976813   | 0.2138     | 31.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      | 0.03   | 0.7833     | 0.7113     | 0.8713     | 0.972607   | 0.2060     | 36.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      | 0.05   | 0.7877     | 0.7168     | 0.8741     | 0.976226   | 0.2172     | 37.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      | 0.07   | 0.7878     | 0.7135     | 0.8795     | 0.979233   | 0.2300     | 38.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 0.03   | 0.7839     | 0.7193     | 0.8612     | 0.972937   | 0.2198     | 43.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 0.05   | 0.7877     | 0.7215     | 0.8672     | 0.977641   | 0.2331     | 45.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      | 0.07   | 0.7911     | 0.7186     | 0.8798     | 0.981962   | 0.2380     | 44.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7      | 0.03   | 0.7876     | 0.7131     | 0.8794     | 0.979212   | 0.2299     | 53.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7      | 0.05   | 0.7887     | 0.7211     | 0.8702     | 0.981297   | 0.2406     | 54.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7      | 0.07   | 0.7853     | 0.7055     | 0.8855     | 0.988499   | 0.2344     | 57.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 0.03   | 0.7841     | 0.7168     | 0.8653     | 0.979823   | 0.2249     | 69.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 0.05   | 0.7817     | 0.7153     | 0.8617     | 0.985692   | 0.2283     | 68.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8      | 0.07   | 0.7774     | 0.7026     | 0.8700     | 0.992743   | 0.2123     | 65.3s\n",
      "-----------------------------------------------------------------------------------------------\n",
      "ğŸ† Best Tier 2 Model Found!\n",
      "Params      : Depth 6, LR 0.07\n",
      "Max F1      : 0.7911\n",
      "Recall      : 0.7186\n",
      "Precision   : 0.8798\n",
      "Rec@0.9     : 0.2380\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: best_tier2_depth6_lr0.07.cbm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_raw_cat.drop('is_fraud', axis=1)\n",
    "y = df_raw_cat['is_fraud']\n",
    "\n",
    "# ë²”ì£¼í˜• ë³€ìˆ˜ ë¦¬ìŠ¤íŠ¸ ì§€ì • (ì´ê²Œ í•µì‹¬!)\n",
    "cat_features_indices = ['mcc', 'merchant_state', 'zip', 'use_chip', 'card_brand']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Undersampling (10:1)\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# íƒìƒ‰ ê·¸ë¦¬ë“œ (Depth & Learning Rate ì¡°í•©)\n",
    "grid_params = []\n",
    "for d in [4, 5, 6, 7, 8]:\n",
    "    for lr in [0.03, 0.05, 0.07]:\n",
    "        grid_params.append({'depth': d, 'lr': lr})\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"ğŸš€ Final Tier 2 Optimization (Depth 4-8, LR Tuning) ì‹œì‘...\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Depth':<6} | {'LR':<6} | {'Max F1':<10} | {'Recall':<10} | {'Precision':<10} | {'Threshold':<10} | {'Rec@0.9':<10} | {'Time':<8}\")\n",
    "print(\"-\" * 95)\n",
    "\n",
    "best_patrol = {\n",
    "    'f1': 0,\n",
    "    'recall': 0,\n",
    "    'precision': 0,\n",
    "    'threshold': 0,\n",
    "    'prec_at_90': 0,\n",
    "    'params': {},\n",
    "    'model': None\n",
    "}\n",
    "\n",
    "for params in grid_params:\n",
    "    d = params['depth']\n",
    "    lr = params['lr']\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        model = CatBoostClassifier(\n",
    "            iterations=1500,       # ì¶©ë¶„í•œ í•™ìŠµ\n",
    "            depth=d,\n",
    "            learning_rate=lr,      # [í•µì‹¬] í•™ìŠµë¥  íŠœë‹\n",
    "            task_type=\"GPU\",\n",
    "            eval_metric='AUC',\n",
    "            cat_features=cat_features_indices,\n",
    "            random_seed=42,\n",
    "            verbose=0,\n",
    "            scale_pos_weight=1     # Weight ê³ ì •\n",
    "        )\n",
    "        \n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # PR Curve & F1\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        denom = precisions[:-1] + recalls[:-1]\n",
    "        denom[denom == 0] = 1 \n",
    "        f1_scores = 2 * (precisions[:-1] * recalls[:-1]) / denom\n",
    "        \n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        \n",
    "        max_f1 = f1_scores[best_idx]\n",
    "        best_recall = recalls[best_idx]\n",
    "        best_prec = precisions[best_idx]\n",
    "        best_th = thresholds[best_idx]\n",
    "        \n",
    "        # Recall 90% ì¼ ë•Œ Precision í™•ì¸ (Rec@0.9)\n",
    "        idx_90 = np.where(recalls[:-1] >= 0.90)[0]\n",
    "        if len(idx_90) > 0:\n",
    "            prec_at_90 = precisions[idx_90[np.argmax(precisions[idx_90])]]\n",
    "        else:\n",
    "            prec_at_90 = 0.0\n",
    "            \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"{d:<6} | {lr:<6} | {max_f1:<10.4f} | {best_recall:<10.4f} | {best_prec:<10.4f} | {best_th:<10.6f} | {prec_at_90:.4f}     | {elapsed:.1f}s\")\n",
    "        \n",
    "        # ìµœê³  ê¸°ë¡ ê°±ì‹  (F1 ê¸°ì¤€)\n",
    "        if max_f1 > best_patrol['f1']:\n",
    "            best_patrol['f1'] = max_f1\n",
    "            best_patrol['recall'] = best_recall\n",
    "            best_patrol['precision'] = best_prec\n",
    "            best_patrol['threshold'] = best_th\n",
    "            best_patrol['prec_at_90'] = prec_at_90\n",
    "            best_patrol['params'] = params\n",
    "            best_patrol['model'] = model\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ë° ì €ì¥\n",
    "print(\"-\" * 95)\n",
    "if best_patrol['model']:\n",
    "    print(\"ğŸ† Best Tier 2 Model Found!\")\n",
    "    print(f\"Params      : Depth {best_patrol['params']['depth']}, LR {best_patrol['params']['lr']}\")\n",
    "    print(f\"Max F1      : {best_patrol['f1']:.4f}\")\n",
    "    print(f\"Recall      : {best_patrol['recall']:.4f}\")\n",
    "    print(f\"Precision   : {best_patrol['precision']:.4f}\")\n",
    "    print(f\"Rec@0.9     : {best_patrol['prec_at_90']:.4f}\")\n",
    "    \n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    save_path = f\"best_tier2_depth{best_patrol['params']['depth']}_lr{best_patrol['params']['lr']}.cbm\"\n",
    "    best_patrol['model'].save_model(save_path)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ ëª¨ë¸ íƒìƒ‰ ì‹¤íŒ¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b25f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Tier 2: Recall 90% íƒ€ê²Ÿ ì„¤ì • ì¤‘...\n",
      "\n",
      "ğŸ¯ [Target Found] Recall 90% Cut-off\n",
      "   - Threshold : 0.56802705  <-- (ì´ ê°’ì„ worker.pyì— ì ìš©í•˜ì„¸ìš”!)\n",
      "   - Recall    : 0.9000 (ëª©í‘œ ë‹¬ì„±)\n",
      "   - Precision : 0.2380\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š [ìµœì¢… í™•ì •] FraudGuard Operation Report\n",
      "============================================================\n",
      "ì „ì²´ ê±°ë˜: 1,830,308ê±´ (ì‚¬ê¸°: 2,761ê±´)\n",
      "------------------------------------------------------------\n",
      "ğŸ”´ Tier 1 (ì¦‰ì‹œ ì°¨ë‹¨) : Threshold 0.998166\n",
      "   - ê²€ê±°: 1,369ëª… (49.6%)\n",
      "   - ì˜¤íƒ: 20ëª… (ê·¹ì†Œìˆ˜)\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¡ Tier 2 (ì¶”ê°€ ì¸ì¦) : Threshold 0.568027\n",
      "   - ì¶”ê°€ ê²€ê±°: 1,116ëª… (40.4%)\n",
      "   - ì¸ì¦ ë°œì†¡: 7,934ê±´\n",
      "   - ë°œì†¡ ë¹„ìœ¨: ì „ì²´ ê±°ë˜ì˜ 0.43% (100ë§Œ ê±´ë‹¹ ì•½ 4334ê±´)\n",
      "------------------------------------------------------------\n",
      "ğŸ† ìµœì¢… ì„±ì  (Tier 1+2)\n",
      "   - ì´ ê²€ê±°ìœ¨ : 90.0% (ëª©í‘œ: 90% ì´ìƒ)\n",
      "   - ë†“ì¹œ ì‚¬ê¸° : 276ëª…\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "\n",
    "# í˜„ì¬ ë©”ëª¨ë¦¬ì— ìˆëŠ” ìµœê³ ì˜ ëª¨ë¸ ì‚¬ìš©\n",
    "# (ë§Œì•½ ë‚ ì•„ê°”ë‹¤ë©´: model = CatBoostClassifier(); model.load_model('best_tier2_depth6_lr0.07.cbm'))\n",
    "final_model = best_patrol['model']\n",
    "\n",
    "print(\"ğŸš€ Tier 2: Recall 90% íƒ€ê²Ÿ ì„¤ì • ì¤‘...\")\n",
    "\n",
    "# 1. ì˜ˆì¸¡ í™•ë¥  ë‹¤ì‹œ ê³„ì‚°\n",
    "y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 2. PR Curveì—ì„œ Recall >= 0.90 ì¸ ì§€ì  ì •ë°€ íƒìƒ‰\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# Recallì´ 0.9 ì´ìƒì¸ ì¸ë±ìŠ¤ë“¤\n",
    "idx_90 = np.where(recalls[:-1] >= 0.90)[0]\n",
    "\n",
    "if len(idx_90) > 0:\n",
    "    # ê·¸ ì¤‘ì—ì„œ Precisionì´ ê°€ì¥ ë†’ì€ ì§€ì  (ìµœì ì )\n",
    "    best_idx = idx_90[np.argmax(precisions[idx_90])]\n",
    "    \n",
    "    target_th = thresholds[best_idx]\n",
    "    target_recall = recalls[best_idx]\n",
    "    target_prec = precisions[best_idx]\n",
    "    \n",
    "    print(f\"\\nğŸ¯ [Target Found] Recall 90% Cut-off\")\n",
    "    print(f\"   - Threshold : {target_th:.8f}  <-- (ì´ ê°’ì„ worker.pyì— ì ìš©í•˜ì„¸ìš”!)\")\n",
    "    print(f\"   - Recall    : {target_recall:.4f} (ëª©í‘œ ë‹¬ì„±)\")\n",
    "    print(f\"   - Precision : {target_prec:.4f}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. ìµœì¢… ì‹œë®¬ë ˆì´ì…˜ (Tier 1 + Tier 2 í•©ì‚°)\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š [ìµœì¢… í™•ì •] FraudGuard Operation Report\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Tier 1 ì„¤ì • (ì´ë¯¸ í™•ì •ëœ ê°’)\n",
    "    th_tier1 = 0.99816559\n",
    "    \n",
    "    # Tier 2 ì„¤ì • (ë°©ê¸ˆ ì°¾ì€ ê°’)\n",
    "    th_tier2 = target_th\n",
    "    \n",
    "    n_total = len(y_test)\n",
    "    n_fraud = sum(y_test)\n",
    "    \n",
    "    # Tier 1 (Block)\n",
    "    mask_t1 = (y_prob >= th_tier1)\n",
    "    n_t1_fraud = sum(mask_t1 & (y_test == 1))\n",
    "    n_t1_innocent = sum(mask_t1 & (y_test == 0))\n",
    "    \n",
    "    # Tier 2 (Auth) - Tier 1 ì œì™¸\n",
    "    mask_t2 = (y_prob >= th_tier2) & (y_prob < th_tier1)\n",
    "    n_t2_fraud = sum(mask_t2 & (y_test == 1))\n",
    "    n_t2_innocent = sum(mask_t2 & (y_test == 0))\n",
    "    \n",
    "    # Passed\n",
    "    mask_pass = (y_prob < th_tier2)\n",
    "    n_pass_fraud = sum(mask_pass & (y_test == 1))\n",
    "    \n",
    "    print(f\"ì „ì²´ ê±°ë˜: {n_total:,}ê±´ (ì‚¬ê¸°: {n_fraud:,}ê±´)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"ğŸ”´ Tier 1 (ì¦‰ì‹œ ì°¨ë‹¨) : Threshold {th_tier1:.6f}\")\n",
    "    print(f\"   - ê²€ê±°: {n_t1_fraud:,}ëª… ({(n_t1_fraud/n_fraud*100):.1f}%)\")\n",
    "    print(f\"   - ì˜¤íƒ: {n_t1_innocent:,}ëª… (ê·¹ì†Œìˆ˜)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"ğŸŸ¡ Tier 2 (ì¶”ê°€ ì¸ì¦) : Threshold {th_tier2:.6f}\")\n",
    "    print(f\"   - ì¶”ê°€ ê²€ê±°: {n_t2_fraud:,}ëª… ({(n_t2_fraud/n_fraud*100):.1f}%)\")\n",
    "    print(f\"   - ì¸ì¦ ë°œì†¡: {n_t2_innocent:,}ê±´\")\n",
    "    print(f\"   - ë°œì†¡ ë¹„ìœ¨: ì „ì²´ ê±°ë˜ì˜ {(n_t2_innocent/n_total*100):.2f}% (100ë§Œ ê±´ë‹¹ ì•½ {int(n_t2_innocent/n_total*1000000)}ê±´)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    total_caught = n_t1_fraud + n_t2_fraud\n",
    "    print(f\"ğŸ† ìµœì¢… ì„±ì  (Tier 1+2)\")\n",
    "    print(f\"   - ì´ ê²€ê±°ìœ¨ : {(total_caught/n_fraud*100):.1f}% (ëª©í‘œ: 90% ì´ìƒ)\")\n",
    "    print(f\"   - ë†“ì¹œ ì‚¬ê¸° : {n_pass_fraud:,}ëª…\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ í˜„ì¬ ëª¨ë¸ë¡œëŠ” Recall 90% ë„ë‹¬ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. (ê°€ì¤‘ì¹˜ë¥¼ ë” ì¤¬ì–´ì•¼ í–ˆì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "REDW_kernel",
   "language": "python",
   "name": "redw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
